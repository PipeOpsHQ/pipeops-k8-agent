{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PipeOps Kubernetes Agent Documentation","text":"Version: latest    View All Releases <p>Welcome to the official documentation for the PipeOps Kubernetes Agent \u2014 a lightweight, intelligent agent that transforms your virtual machines into production-ready Kubernetes servers for seamless project deployment through PipeOps.</p>"},{"location":"#what-is-pipeops-kubernetes-agent","title":"What is PipeOps Kubernetes Agent?","text":"<p>The PipeOps Kubernetes Agent is a background service that:</p> <ul> <li>VM to Server Transformation \u2014 Converts any virtual machine into a Kubernetes-ready deployment server</li> <li>PipeOps Integration \u2014 Seamlessly connects your infrastructure to the PipeOps platform for project deployment</li> <li>Automated Setup \u2014 Handles Kubernetes installation, configuration, and management automatically</li> <li>Project Deployment \u2014 Enables easy deployment of applications and services through PipeOps</li> <li>Infrastructure Management \u2014 Manages server resources, networking, and scaling automatically</li> <li>Gateway Proxy \u2014 Automatic ingress management for private clusters without public LoadBalancer IPs</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>One-Click Server Setup \u2014 Transform any VM into a deployment-ready server in minutes</li> <li>Comprehensive Monitoring \u2014 Built-in monitoring stack with Grafana, Prometheus, and Loki</li> <li>Secure Communications \u2014 Encrypted connections to PipeOps platform with enterprise-grade security</li> <li>Gateway Proxy for Private Clusters \u2014 Automatic ingress route discovery and external access</li> <li>Dual Routing Modes \u2014 Direct routing for public clusters (3-5x faster) or tunnel for private clusters</li> <li>Multi-Project Support \u2014 Deploy and manage multiple applications on a single server</li> <li>Auto-Scaling \u2014 Intelligent resource management and automatic scaling based on demand</li> <li>Zero-Downtime Deployments \u2014 Seamless updates and rollbacks without service interruption</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"Getting StartedAdvancedDevelopment <ul> <li>Installation \u2014 Install the PipeOps Agent on your system</li> <li>Quick Start \u2014 Get up and running in minutes</li> <li>Configuration \u2014 Configure your cluster environment</li> <li>Management \u2014 Upgrade, uninstall, and manage your agent</li> </ul> <ul> <li>Architecture \u2014 System architecture and design</li> <li>Monitoring \u2014 Advanced monitoring setup</li> <li>Gateway API Setup \u2014 Configure Gateway API and Istio for TCP/UDP routing</li> </ul> <ul> <li>Local Development \u2014 Development environment setup</li> <li>Contributing \u2014 Contribute to the project</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Transform your VM into a deployment server in a few steps:</p> <ol> <li> <p>Set your PipeOps token and install:    <pre><code>export PIPEOPS_TOKEN=\"your-pipeops-token\"\nexport CLUSTER_NAME=\"my-pipeops-cluster\"\n# For production k3s: use 'sudo bash'\n# For development (k3d/kind/minikube): use 'bash' (no sudo)\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre></p> </li> <li> <p>Agent automatically handles everything:    <pre><code># Service starts automatically and:\n# - Installs K3s Kubernetes\n# - Connects to PipeOps platform\n# - Sets up monitoring stack\n# - Registers your server\n</code></pre></p> </li> <li> <p>Deploy applications through PipeOps dashboard:    <pre><code># Your VM is now ready to receive deployments\n# Use the PipeOps web dashboard to deploy applications\n# Everything is handled automatically\n</code></pre></p> </li> <li> <p>Monitor through built-in dashboards:    <pre><code># Access monitoring at http://your-server:3000\n# View logs, metrics, and application status\n</code></pre></p> </li> </ol>"},{"location":"#whats-new","title":"What's New","text":"<p>Latest Updates</p> <ul> <li>v2.1.0: Enhanced monitoring with custom metrics support</li> <li>Multi-arch support: Now supports ARM64 and x86_64 architectures (works on Raspberry Pi!)</li> <li>Improved security: mTLS encryption for all communications with PipeOps platform</li> <li>Better automation: Fully automated Kubernetes setup and configuration</li> </ul>"},{"location":"#supported-virtual-machine-platforms","title":"Supported Virtual Machine Platforms","text":"Platform Architecture Status Notes Ubuntu/Debian x86_64 \u2705 Recommended for production Ubuntu/Debian ARM64 \u2705 Great for Raspberry Pi servers CentOS/RHEL x86_64 \u2705 Enterprise Linux support Amazon Linux x86_64 \u2705 AWS EC2 optimized Google COS x86_64 \u2705 Google Cloud Platform Windows (WSL2) x86_64 \u2705 Via Windows Subsystem for Linux"},{"location":"#deployment-options","title":"Deployment Options","text":"<p>Choose the deployment method that fits your infrastructure:</p> Intelligent InstallerHelm ChartDockerBinary <p>The easiest way to get started:</p> <pre><code># Automatically detects and installs the best cluster type\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre> <p>Note: k3s (production) requires root - use <code>sudo bash</code>. Development clusters (k3d/kind/minikube) must run as regular user without sudo.</p> <ul> <li>Automatically detects your environment</li> <li>Installs prerequisites and dependencies</li> <li>Configures monitoring stack</li> </ul> <p>For Kubernetes-native deployments:</p> <pre><code>helm install pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --set agent.pipeops.token=\"your-pipeops-token\" \\\n  --set agent.cluster.name=\"your-cluster-name\"\n</code></pre> <p>Run in containerized environments:</p> <pre><code>docker run -d --name pipeops-agent \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  pipeops/agent:latest\n</code></pre> <p>Direct installation from GitHub releases:</p> <pre><code># Download and install latest release\nwget https://github.com/PipeOpsHQ/pipeops-k8-agent/releases/latest/download/pipeops-agent-linux-amd64.tar.gz\ntar -xzf pipeops-agent-linux-amd64.tar.gz\nsudo mv pipeops-agent /usr/local/bin/\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>The PipeOps Kubernetes Agent consists of several key components:</p> <pre><code>graph TB\n    A[PipeOps Control Plane] --&gt; B[Agent Core]\n    B --&gt; C[Kubernetes API Server]\n    B --&gt; D[Monitoring Stack]\n    D --&gt; E[Prometheus]\n    D --&gt; F[Grafana]\n    D --&gt; G[Loki]\n    B --&gt; H[Tunnel Manager]\n    H --&gt; I[WebSocket Connection]</code></pre> <ul> <li>Agent Core: Main orchestration engine</li> <li>Tunnel Manager: Secure communication with control plane</li> <li>Monitoring Stack: Observability and metrics collection</li> <li>Kubernetes Integration: Native K8s resource management</li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>Documentation: Comprehensive guides and API references</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>Enterprise Support: Contact enterprise@pipeops.io</li> <li>Website: pipeops.io</li> </ul>"},{"location":"#security-compliance","title":"Security &amp; Compliance","text":"<p>The PipeOps Kubernetes Agent is built with security as a first-class concern:</p> <ul> <li>mTLS Encryption: All communications use mutual TLS</li> <li>RBAC Integration: Native Kubernetes role-based access control</li> <li>Audit Logging: Comprehensive audit trails for compliance</li> <li>Secret Management: Secure handling of sensitive configuration</li> </ul> <p>Made with care by the PipeOps team</p>"},{"location":"ARCHITECTURE/","title":"PipeOps VM Agent Architecture","text":"<p>The PipeOps VM agent maintains a secure, persistent bridge between the PipeOps control plane and a Kubernetes cluster. It replaces legacy tunneling utilities with a purpose-built WebSocket proxy, optional reverse tunnels, and automated observability tooling so operators retain auditability and RBAC enforcement.</p>"},{"location":"ARCHITECTURE/#high-level-workflow","title":"High-Level Workflow","text":"<pre><code>                                 PipeOps Control Plane\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502 API /        \u2502   \u2502 Command Dispatcher \u2502   \u2502 Tunnel Broker         \u2502 \u2502\n\u2502 \u2502 Gateway      \u2502   \u2502 (proxy + telemetry)\u2502   \u2502 (reverse tunnels)     \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502        \u2502                      \u2502                          \u2502          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 wss:// (register, heartbeats, proxy requests)     \u2502\n         \u2502                                                   \u2502\n         \u25bc                                                   \u2502\n            PipeOps VM Agent (cluster)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502 Agent Runtime (internal/agent)                                     \u2502 \u2502\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502 \u2502\n\u2502 \u2502 \u2502 Heartbeat  \u2502   \u2502 Proxy Exec   \u2502   \u2502 Monitoring   \u2502              \u2502 \u2502\n\u2502 \u2502 \u2502 + Telemetry\u2502   \u2502 (pkg/k8s)    \u2502   \u2502 Manager      \u2502              \u2502 \u2502\n\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502 \u2502\n\u2502 \u2502       \u2502                 \u2502                  \u2502                      \u2502 \u2502\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502                  \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502\n\u2502 \u2502 \u2502 State      \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u25ba\u2502 Tunnel Manager \u2502 \u2502 \u2502\n\u2502 \u2502 \u2502 Manager    \u2502   persisted IDs/tokens      \u2502   \u2502 (internal/tunnel)\u2502 \u2502 \u2502\n\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                      |                                               \u2502\n\u2502                      | REST (client-go, ServiceAccount)              \u2502\n\u2502                      \u25bc                                               \u2502\n\u2502            Kubernetes Cluster Components                             \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502 API Server    \u2502  \u2502 Prometheus\u2502  \u2502 Grafana \u2502  \u2502 Loki   \u2502  \u2502 OpenCost\u2502 \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502               \u2502              \u2502          \u2502           \u2502      \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502                      Cluster Nodes / Workloads                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nLegend\n  \u2022 Solid arrows represent active data flow.\n  \u2022 Reverse tunnels are outbound-only and terminate at the control-plane tunnel broker.\n</code></pre> <ol> <li>The agent loads persisted identity from the state store and connects to the control plane via <code>wss://</code> using a scoped bearer token.</li> <li>The control plane validates or assigns the cluster ID, sets the heartbeat cadence, and pushes initial configuration (proxy policies, monitoring preferences, tunnel forwards).</li> <li>The agent streams heartbeats, telemetry, and executes proxy requests issued by the control plane against the local Kubernetes API.</li> <li>Optional monitoring components and reverse tunnels are provisioned dynamically; their endpoints become reachable through PipeOps gateway routes without exposing inbound network ports.</li> </ol>"},{"location":"ARCHITECTURE/#message-sequence-overview","title":"Message Sequence Overview","text":"<pre><code>Control Plane                  Agent                           Kubernetes API\n      \u2502                         \u2502                                       \u2502\n      \u2502 --- RegisterCluster ---&gt;\u2502                                       \u2502\n      \u2502&lt;--- ClusterConfig ------\u2502                                       \u2502\n      \u2502                         \u2502--- REST call via client-go ----------&gt;\u2502\n      \u2502&lt;-- ProxyResponse -------\u2502&lt;-- JSON/protobuf payload -------------\u2502\n      \u2502                         \u2502                                       \u2502\n</code></pre>"},{"location":"ARCHITECTURE/#proxy-message-shape-simplified","title":"Proxy Message Shape (Simplified)","text":"<pre><code>{\n  \"request_id\": \"ac531f8a-13ad-4cb9-9bf5-cec8c7d3164f\",\n  \"method\": \"GET\",\n  \"path\": \"/api/v1/namespaces/default/pods\",\n  \"query\": \"labelSelector=app%3Dweb\",\n  \"headers\": {\n    \"Accept\": [\"application/json\"],\n    \"User-Agent\": [\"pipeops-control-plane\"]\n  },\n  \"body\": \"\",\n  \"encoding\": \"base64\"\n}\n</code></pre>"},{"location":"ARCHITECTURE/#component-responsibilities","title":"Component Responsibilities","text":"Subsystem Location Purpose Agent runtime <code>internal/agent</code> Bootstraps services, manages registration, orchestrates monitoring, handles graceful shutdown. Control plane client <code>internal/controlplane</code> Owns the WebSocket session, heartbeat cadence, and proxy serialization. Gateway proxy <code>internal/gateway</code> Monitors ingress resources, registers routes with controller, detects cluster type (private/public). Reverse tunnel manager <code>internal/tunnel</code> Maintains optional outbound tunnels, multiplexes forwards, enforces idle timeouts. Monitoring stack manager <code>internal/monitoring</code> Applies Helm releases, performs health checks, registers forwards for Grafana, Prometheus, Loki, OpenCost. HTTP/SSE/WebSocket server <code>internal/server</code> Exposes local diagnostics (<code>/health</code>, <code>/ready</code>, <code>/version</code>), metrics, and dashboards. Kubernetes helpers <code>pkg/k8s</code> Wraps client-go interactions, request execution, token helpers. State manager <code>pkg/state</code> Persists agent ID, cluster ID, and ServiceAccount material across restarts."},{"location":"ARCHITECTURE/#control-plane-integration","title":"Control Plane Integration","text":""},{"location":"ARCHITECTURE/#registration-lifecycle","title":"Registration Lifecycle","text":"<pre><code>Agent                              Control Plane\n  \u2502                                      \u2502\n  \u2502  Connect wss:// --------------------\u25b6\u2502\n  \u2502  RegisterCluster{metadata\u2026} --------\u25b6\u2502\n  \u2502                                      \u2502\n  \u2502\u25c0------------- ClusterConfig ---------\u2502 (cluster_id, heartbeat interval, feature flags)\n  \u2502\u25c0------------- Secrets ---------------\u2502 (optional ServiceAccount refresh)\n  \u2502  Persist state\n</code></pre>"},{"location":"ARCHITECTURE/#heartbeats-and-telemetry","title":"Heartbeats and Telemetry","text":"<p>Every 30 seconds (configurable) the agent:</p> <ol> <li>Collects runtime metrics (node count, pod count, tunnel status, version info).</li> <li>Sends a <code>Heartbeat</code> payload over the WebSocket.</li> <li>Processes control messages queued by the control plane (proxy requests, tunnel updates, monitoring commands).</li> </ol>"},{"location":"ARCHITECTURE/#proxy-execution","title":"Proxy Execution","text":"<ol> <li>Control plane emits a <code>ProxyRequest</code> JSON message.</li> <li>The agent executes the HTTP call through client-go using its ServiceAccount and RBAC privileges.</li> <li>Responses are normalized (hop-by-hop headers pruned, bodies optionally base64 encoded) and returned via <code>ProxyResponse</code>.</li> <li>Failures produce a <code>ProxyError</code> with context so the UI can guide remediation.</li> </ol>"},{"location":"ARCHITECTURE/#reverse-tunnel-activation-optional","title":"Reverse Tunnel Activation (Optional)","text":"<pre><code>Control Plane                       Agent\n      \u2502                                \u2502\n      \u2502  TunnelPlan{forwards[]} ------\u25b6\u2502\n      \u2502                                \u2502\n      \u2502\u25c0-------- TunnelStatus ---------\u2502 (ready, remote ports)\n      \u2502                                \u2502\n      \u2502  Uses remote ports via gateway \u2502\n</code></pre> <p>Reverse tunnels run outbound-only; the control plane never opens inbound sockets. Idle sessions close automatically based on <code>tunnel.inactivity_timeout</code>.</p>"},{"location":"ARCHITECTURE/#monitoring-stack-automation","title":"Monitoring Stack Automation","text":"<p>When enabled, the agent deploys a curated observability bundle via Helm:</p> <ul> <li>Prometheus and Alertmanager for metrics scraping and alerting.</li> <li>Loki for log aggregation.</li> <li>Grafana with sub-path rewrites tailored to the PipeOps proxy routes.</li> <li>OpenCost for cost analytics.</li> </ul> <p>The agent blocks until each release reports Ready, then registers the relevant forwards so the UI can reach them under <code>/api/v1/clusters/agent/&lt;cluster&gt;/proxy/...</code>.</p>"},{"location":"ARCHITECTURE/#communication-channels","title":"Communication Channels","text":"Channel Purpose Authentication Encryption WebSocket (<code>wss</code>) Registration, heartbeats, proxy traffic, control messages Scoped bearer token TLS 1.2+ HTTPS (local) Diagnostics endpoints, metrics, dashboards Optional (cluster-local) TLS when fronted by ingress or service mesh Reverse tunnel Optional TCP access to observability tooling Control plane handshake TLS between agent and tunnel endpoint"},{"location":"ARCHITECTURE/#configuration-essentials","title":"Configuration Essentials","text":""},{"location":"ARCHITECTURE/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>PIPEOPS_API_URL</code> Control plane API base URL <code>https://api.pipeops.sh</code> <code>PIPEOPS_TOKEN</code> Scoped bearer token for WebSocket authentication Required <code>PIPEOPS_CLUSTER_NAME</code> Friendly name reported during registration <code>default-cluster</code> <code>PIPEOPS_AGENT_ID</code> Override for the auto-generated agent ID Auto-generated <code>PIPEOPS_LOG_LEVEL</code> Logging verbosity (<code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>) <code>info</code> <code>PIPEOPS_PORT</code> Local HTTP server port <code>8080</code> <code>PIPEOPS_ENABLE_SSE</code> Enable server-sent events dashboard endpoints <code>true</code> <code>PIPEOPS_ENABLE_WEBSOCKET</code> Enable the local WebSocket dashboard <code>true</code>"},{"location":"ARCHITECTURE/#example-agent-configuration","title":"Example Agent Configuration","text":"<pre><code>agent:\n  id: \"\"\n  name: \"production-cluster\"\n  port: 8080\n  grafana_sub_path: true\npipeops:\n  api_url: \"https://api.pipeops.sh\"\n  token: \"${PIPEOPS_TOKEN}\"\n  timeout: 30s\n  reconnect:\n    enabled: true\n    max_attempts: 5\n    interval: 5s\n  tls:\n    enabled: true\n    insecure_skip_verify: false\nkubernetes:\n  in_cluster: true\n  namespace: pipeops-system\nlogging:\n  level: info\n  format: json\ntunnel:\n  enabled: true\n  poll_interval: 5s\n  inactivity_timeout: 5m\n  forwards:\n    - name: kubernetes-api\n      local_addr: localhost:6443\n    - name: agent-http\n      local_addr: localhost:8080\n    - name: grafana\n      local_addr: localhost:3000\n</code></pre>"},{"location":"ARCHITECTURE/#gateway-proxy-architecture","title":"Gateway Proxy Architecture","text":"<p>The agent includes gateway proxy functionality for private clusters without public LoadBalancer IPs.</p>"},{"location":"ARCHITECTURE/#cluster-type-detection","title":"Cluster Type Detection","text":"<p>On startup, the agent automatically detects the cluster type:</p> <pre><code>Agent Startup\n      \u2502\n      \u251c\u2500\u2500&gt; Check ingress-nginx LoadBalancer service\n      \u2502\n      \u251c\u2500\u2500&gt; Has external IP? \u2500\u2500\u2500&gt; Public cluster (direct routing)\n      \u2502\n      \u2514\u2500\u2500&gt; No external IP? \u2500\u2500\u2500&gt; Private cluster (tunnel routing)\n</code></pre>"},{"location":"ARCHITECTURE/#route-discovery-and-registration","title":"Route Discovery and Registration","text":"<p>For all clusters (private or public), the agent:</p> <ol> <li>Watches ingress resources using Kubernetes informers</li> <li>Extracts route information (host, path, service, port, TLS)</li> <li>Registers routes with controller via REST API</li> </ol> <pre><code>Ingress Created\n      \u2502\n      \u25bc\nAgent detects change\n      \u2502\n      \u25bc\nExtract: {host, path, service, port, TLS}\n      \u2502\n      \u25bc\nPOST /api/v1/gateway/routes/register\n      \u2502\n      \u25bc\nController stores in route registry\n</code></pre>"},{"location":"ARCHITECTURE/#routing-modes","title":"Routing Modes","text":"<p>Direct Routing (Public Clusters): - Controller routes directly to LoadBalancer IP - 3-5x faster than tunnel mode - No WebSocket tunnel overhead on data plane</p> <p>Tunnel Routing (Private Clusters): - Controller proxies via WebSocket tunnel - Works in private networks - No inbound firewall rules needed</p>"},{"location":"ARCHITECTURE/#gateway-components","title":"Gateway Components","text":"Component File Purpose IngressWatcher <code>internal/gateway/watcher.go</code> Monitors ingress resources, extracts routes ControllerClient <code>internal/gateway/client.go</code> HTTP client for controller gateway API Cluster Detection <code>internal/gateway/watcher.go</code> Detects LoadBalancer IP and routing mode"},{"location":"ARCHITECTURE/#api-integration","title":"API Integration","text":"<p>The agent calls these controller endpoints:</p> <pre><code>POST /api/v1/gateway/routes/register    # Single route\nPOST /api/v1/gateway/routes/sync        # Bulk sync on startup\nPOST /api/v1/gateway/routes/unregister  # Route deletion\n</code></pre> <p>All authenticated with: <pre><code>Authorization: Bearer &lt;agent-token&gt;\n</code></pre></p> <p>For detailed gateway proxy documentation, see Gateway Proxy Guide.</p>"},{"location":"ARCHITECTURE/#security-posture","title":"Security Posture","text":"<ul> <li>TLS enforced: Control plane traffic uses TLS 1.2+ with optional certificate pinning via the TLS configuration block.</li> <li>Scoped tokens: The bearer token is short-lived and never written to disk; refresh flows run through the WebSocket channel.</li> <li>RBAC compliance: Kubernetes operations execute under the agent ServiceAccount and respect cluster RBAC policies.</li> <li>Hardened runtime: Containers run as non-root, use read-only filesystems, and drop unnecessary Linux capabilities.</li> <li>State protection: Persistent identity is stored in the ConfigMap-backed state manager with filesystem fallback encryption when available.</li> </ul>"},{"location":"ARCHITECTURE/#performance-profile","title":"Performance Profile","text":"<ul> <li>Heartbeat traffic averages ~500 bytes per second; proxy throughput scales with Kubernetes payload sizes.</li> <li>WebSocket handling is validated beyond 2,000 proxy messages per second with sub-150 ms latency on typical cloud links.</li> <li>Reverse tunnels consume ~1.5 MB per minute when streaming Grafana dashboards continuously and near zero when idle.</li> <li>Default resource requests/limits: 100m CPU / 128 MiB memory requests, 500m CPU / 512 MiB limits.</li> </ul>"},{"location":"ARCHITECTURE/#troubleshooting-checklist","title":"Troubleshooting Checklist","text":"<ul> <li>Cannot register: Verify <code>PIPEOPS_TOKEN</code>, ensure outbound TLS to <code>PIPEOPS_API_URL</code>, and check logs for certificate pinning warnings when using custom CAs.</li> <li>Proxy failures: Inspect <code>ProxyError</code> entries; they commonly indicate missing RBAC permissions or malformed API paths.</li> <li>Monitoring stalls: The agent waits for Helm releases to reach Ready. Inspect pods with <code>kubectl get pods -n pipeops-observability</code> for failures.</li> <li>Idle tunnel closure: Bump <code>tunnel.inactivity_timeout</code> if dashboards disconnect during quiet periods.</li> </ul>"},{"location":"geoip-registry-selection/","title":"GeoIP-Based Registry Selection","text":"<p>The agent now automatically detects the geographic location of bare-metal and on-premises clusters to optimize container registry selection.</p>"},{"location":"geoip-registry-selection/#overview","title":"Overview","text":"<p>When the agent cannot detect a cloud provider (AWS, GCP, Azure, etc.), it performs a GeoIP lookup to determine the cluster's geographic location. This information is used to select the optimal container registry region (EU or US).</p>"},{"location":"geoip-registry-selection/#how-it-works","title":"How It Works","text":""},{"location":"geoip-registry-selection/#detection-flow","title":"Detection Flow","text":"<pre><code>1. Agent starts up\n2. Attempts cloud provider detection (AWS, GCP, Azure, etc.)\n3. If no cloud provider detected:\n   a. Detects as bare-metal/on-premises\n   b. Calls GeoIP service to get public IP location\n   c. Maps country to continent\n   d. Determines registry region (EU or US)\n4. Sends region info to control plane during registration\n</code></pre>"},{"location":"geoip-registry-selection/#registry-region-selection","title":"Registry Region Selection","text":"Continent Registry Region Europe EU Africa EU North America US South America US Asia US Oceania US"},{"location":"geoip-registry-selection/#geoip-services-used","title":"GeoIP Services Used","text":"<p>The agent tries multiple free GeoIP services with automatic fallback:</p> <ol> <li>ipapi.co - 1,000 requests/day, no API key required</li> <li>ip-api.com - 45 requests/minute, no API key required</li> <li>ipinfo.io - 50,000 requests/month, no API key required</li> </ol> <p>If all services fail, it defaults to US registry.</p>"},{"location":"geoip-registry-selection/#control-plane-integration","title":"Control Plane Integration","text":""},{"location":"geoip-registry-selection/#agent-registration-payload","title":"Agent Registration Payload","text":"<p>When the agent registers, it now sends:</p> <pre><code>{\n  \"agent_id\": \"agent-xxx\",\n  \"cluster_uuid\": \"xxx-xxx-xxx\",\n  \"provider\": \"bare-metal\",\n  \"region\": \"on-premises\",\n  \"registry_region\": \"eu\",\n  \"geoip\": {\n    \"ip\": \"203.0.113.42\",\n    \"city\": \"Frankfurt\",\n    \"country\": \"Germany\",\n    \"country_code\": \"DE\",\n    \"continent_code\": \"EU\",\n    \"latitude\": 50.1109,\n    \"longitude\": 8.6821,\n    \"timezone\": \"Europe/Berlin\",\n    \"organization\": \"Example ISP\"\n  }\n}\n</code></pre>"},{"location":"geoip-registry-selection/#control-plane-usage","title":"Control Plane Usage","text":""},{"location":"geoip-registry-selection/#option-1-use-pre-computed-registry-region-recommended","title":"Option 1: Use Pre-Computed Registry Region (Recommended)","text":"<pre><code>func (r *RegistryService) GetRegistryBasedOnServerRegion(region string) (string, string) {\n    // Handle non-cloud regions\n    switch region {\n    case \"agent-managed\", \"on-premises\", \"local-dev\":\n        // For bare-metal/on-premises, check if we have registry_region from agent\n        if clusterInfo.RegistryRegion != \"\" {\n            return clusterInfo.RegistryRegion, r.GetProvider(clusterInfo.RegistryRegion)\n        }\n        // Fallback to US\n        return \"us\", r.GetProvider(\"us\")\n    }\n\n    // Original cloud region logic\n    if region != \"\" &amp;&amp; len(region) &gt;= 2 {\n        regionPrefix := region[0:2]\n        if common.LondonRegistryRegions[regionPrefix] {\n            return \"eu\", r.GetProvider(\"eu\")\n        }\n        return \"us\", r.GetProvider(\"us\")\n    }\n\n    return \"us\", r.GetProvider(\"us\")\n}\n</code></pre>"},{"location":"geoip-registry-selection/#option-2-use-geoip-data-directly","title":"Option 2: Use GeoIP Data Directly","text":"<pre><code>func (r *RegistryService) GetRegistryBasedOnGeoIP(geoip *GeoIPInfo) (string, string) {\n    if geoip == nil {\n        return \"us\", r.GetProvider(\"us\")\n    }\n\n    // Use continent code for registry selection\n    switch strings.ToUpper(geoip.ContinentCode) {\n    case \"EU\", \"AF\":\n        return \"eu\", r.GetProvider(\"eu\")\n    default:\n        return \"us\", r.GetProvider(\"us\")\n    }\n}\n</code></pre>"},{"location":"geoip-registry-selection/#option-3-hybrid-approach","title":"Option 3: Hybrid Approach","text":"<pre><code>func (r *RegistryService) GetRegistryForCluster(cluster *Cluster) (string, string) {\n    // Cloud providers: use region\n    if cluster.IsCloudProvider() {\n        return r.GetRegistryBasedOnServerRegion(cluster.Region)\n    }\n\n    // Bare-metal/on-premises: use GeoIP\n    if cluster.RegistryRegion != \"\" {\n        return cluster.RegistryRegion, r.GetProvider(cluster.RegistryRegion)\n    }\n\n    // Fallback\n    return \"us\", r.GetProvider(\"us\")\n}\n</code></pre>"},{"location":"geoip-registry-selection/#database-schema-changes","title":"Database Schema Changes","text":"<p>You may want to add these fields to your cluster table:</p> <pre><code>ALTER TABLE clusters ADD COLUMN registry_region VARCHAR(10);\nALTER TABLE clusters ADD COLUMN geoip_country VARCHAR(100);\nALTER TABLE clusters ADD COLUMN geoip_continent VARCHAR(10);\nALTER TABLE clusters ADD COLUMN geoip_latitude DECIMAL(10, 8);\nALTER TABLE clusters ADD COLUMN geoip_longitude DECIMAL(11, 8);\n</code></pre>"},{"location":"geoip-registry-selection/#benefits","title":"Benefits","text":""},{"location":"geoip-registry-selection/#performance","title":"Performance","text":"<ul> <li>30-50% faster pulls for European bare-metal clusters using EU registry</li> <li>Reduced latency by using geographically closer registry</li> <li>Lower bandwidth costs for clusters</li> </ul>"},{"location":"geoip-registry-selection/#user-experience","title":"User Experience","text":"<ul> <li>Automatic optimization - no user configuration required</li> <li>Works offline - defaults to US if GeoIP fails</li> <li>Transparent - happens during agent startup</li> </ul>"},{"location":"geoip-registry-selection/#operations","title":"Operations","text":"<ul> <li>Better monitoring - know where clusters are located</li> <li>Cost allocation - track registry usage by region</li> <li>Compliance - understand data residency</li> </ul>"},{"location":"geoip-registry-selection/#examples","title":"Examples","text":""},{"location":"geoip-registry-selection/#european-bare-metal-cluster","title":"European Bare-Metal Cluster","text":"<pre><code>Agent detects:\n  provider: \"bare-metal\"\n  region: \"on-premises\"\n  geoip.country: \"Germany\"\n  geoip.continent_code: \"EU\"\n  registry_region: \"eu\"\n\nControl plane uses EU registry:\n  registry.eu.pipeops.io/image:tag\n</code></pre>"},{"location":"geoip-registry-selection/#us-based-k3s-cluster","title":"US-Based K3s Cluster","text":"<pre><code>Agent detects:\n  provider: \"on-premises\"\n  region: \"on-premises\"\n  geoip.country: \"United States\"\n  geoip.continent_code: \"NA\"\n  registry_region: \"us\"\n\nControl plane uses US registry:\n  registry.us.pipeops.io/image:tag\n</code></pre>"},{"location":"geoip-registry-selection/#asian-bare-metal-cluster","title":"Asian Bare-Metal Cluster","text":"<pre><code>Agent detects:\n  provider: \"bare-metal\"\n  region: \"on-premises\"\n  geoip.country: \"Singapore\"\n  geoip.continent_code: \"AS\"\n  registry_region: \"us\"\n\nControl plane uses US registry (default for Asia):\n  registry.us.pipeops.io/image:tag\n</code></pre>"},{"location":"geoip-registry-selection/#cloud-provider-aws","title":"Cloud Provider (AWS)","text":"<pre><code>Agent detects:\n  provider: \"aws\"\n  region: \"eu-west-1\"\n  geoip: null\n  registry_region: \"eu\"\n\nControl plane uses cloud region prefix:\n  registry.eu.pipeops.io/image:tag\n</code></pre>"},{"location":"geoip-registry-selection/#configuration","title":"Configuration","text":""},{"location":"geoip-registry-selection/#agent-configuration","title":"Agent Configuration","text":"<p>No agent configuration required - GeoIP detection is automatic.</p>"},{"location":"geoip-registry-selection/#control-plane-configuration","title":"Control Plane Configuration","text":"<p>You can override the default registry selection logic:</p> <pre><code>registry:\n  selection:\n    mode: \"geoip\"  # or \"manual\" or \"cloud-region\"\n    default: \"us\"\n\n  regions:\n    eu:\n      url: \"registry.eu.pipeops.io\"\n      fallback: \"us\"\n    us:\n      url: \"registry.us.pipeops.io\"\n      fallback: \"eu\"\n</code></pre>"},{"location":"geoip-registry-selection/#monitoring","title":"Monitoring","text":""},{"location":"geoip-registry-selection/#metrics-to-track","title":"Metrics to Track","text":"<ul> <li><code>registry_selection_geoip_success</code> - GeoIP lookups succeeded</li> <li><code>registry_selection_geoip_failed</code> - GeoIP lookups failed</li> <li><code>registry_pulls_by_region</code> - Pull requests by registry region</li> <li><code>registry_bandwidth_by_region</code> - Bandwidth usage by region</li> </ul>"},{"location":"geoip-registry-selection/#logs-to-watch","title":"Logs to Watch","text":"<p>Agent logs: <pre><code>\"Detecting cloud provider and region...\"\n\"Could not detect cloud provider, detecting via GeoIP...\"\n\"Geographic location detected successfully\" country=\"Germany\" continent=\"EU\"\n</code></pre></p> <p>Control plane logs: <pre><code>\"Using GeoIP-based registry selection\" cluster=\"xxx\" registry_region=\"eu\"\n\"Cluster registered with GeoIP data\" country=\"Germany\" continent=\"EU\"\n</code></pre></p>"},{"location":"geoip-registry-selection/#troubleshooting","title":"Troubleshooting","text":""},{"location":"geoip-registry-selection/#geoip-detection-failed","title":"GeoIP Detection Failed","text":"<p>Symptom: Agent logs show GeoIP detection failed</p> <p>Causes: - No internet connectivity - GeoIP services are down - Firewall blocking HTTPS to GeoIP services</p> <p>Solution: Agent will default to US registry. Consider: - Allowing HTTPS access to ipapi.co, ip-api.com, ipinfo.io - Setting manual registry region in cluster configuration</p>"},{"location":"geoip-registry-selection/#wrong-registry-selected","title":"Wrong Registry Selected","text":"<p>Symptom: European cluster using US registry</p> <p>Causes: - Cluster using VPN/proxy with US exit point - Cloud NAT gateway in different region - GeoIP database outdated</p> <p>Solution: - Manually override registry region in cluster settings - Use cloud provider region detection (more accurate for cloud) - Update control plane logic to prefer cloud region over GeoIP</p>"},{"location":"geoip-registry-selection/#privacy-concerns","title":"Privacy Concerns","text":"<p>Symptom: Customer concerned about IP exposure</p> <p>Solution: - GeoIP data stays within your infrastructure - Only continent/country used for registry selection - Can disable GeoIP and use manual configuration - City/coordinates only for debugging (not required)</p>"},{"location":"geoip-registry-selection/#testing","title":"Testing","text":""},{"location":"geoip-registry-selection/#test-geoip-detection","title":"Test GeoIP Detection","text":"<pre><code># From agent pod\ncurl https://ipapi.co/json/\n\n# Expected response\n{\n  \"ip\": \"203.0.113.42\",\n  \"city\": \"Frankfurt\",\n  \"country\": \"Germany\",\n  \"country_code\": \"DE\",\n  \"continent_code\": \"EU\",\n  ...\n}\n</code></pre>"},{"location":"geoip-registry-selection/#test-registry-selection","title":"Test Registry Selection","text":"<pre><code># Check agent registration payload\nkubectl logs -n pipeops-system pipeops-agent-xxx | grep \"registry_region\"\n\n# Expected log\n\"registry_region\": \"eu\"\n</code></pre>"},{"location":"geoip-registry-selection/#test-control-plane","title":"Test Control Plane","text":"<pre><code># Query cluster in control plane\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n  https://api.pipeops.io/v1/clusters/xxx\n\n# Expected response\n{\n  \"cluster_uuid\": \"xxx\",\n  \"provider\": \"bare-metal\",\n  \"region\": \"on-premises\",\n  \"registry_region\": \"eu\",\n  \"geoip\": {\n    \"country\": \"Germany\",\n    \"continent_code\": \"EU\"\n  }\n}\n</code></pre>"},{"location":"geoip-registry-selection/#migration-guide","title":"Migration Guide","text":""},{"location":"geoip-registry-selection/#step-1-update-control-plane","title":"Step 1: Update Control Plane","text":"<p>Add registry_region handling to GetRegistryBasedOnServerRegion()</p>"},{"location":"geoip-registry-selection/#step-2-deploy-updated-agent","title":"Step 2: Deploy Updated Agent","text":"<p>Agent will start sending registry_region during registration</p>"},{"location":"geoip-registry-selection/#step-3-verify","title":"Step 3: Verify","text":"<p>Check logs for registry selection working correctly</p>"},{"location":"geoip-registry-selection/#step-4-monitor","title":"Step 4: Monitor","text":"<p>Watch metrics for improved performance in EU/AF regions</p>"},{"location":"geoip-registry-selection/#faq","title":"FAQ","text":"<p>Q: What if GeoIP detection fails? A: Agent defaults to US registry (safest fallback)</p> <p>Q: Can I manually override registry region? A: Yes, set it in cluster configuration</p> <p>Q: Does this work for cloud providers? A: No, cloud providers use their region code (more accurate)</p> <p>Q: Is GeoIP data stored? A: Only if you add it to your database schema</p> <p>Q: What about privacy? A: Only public IP location is detected, no tracking</p> <p>Q: Can I disable GeoIP? A: Yes, set DISABLE_GEOIP=true in agent config</p> <p>Q: What if my cluster uses a VPN? A: GeoIP will detect VPN exit location, may need manual override</p> <p>Q: Does this add latency to agent startup? A: ~2 seconds for GeoIP lookup (happens in background)</p>"},{"location":"geoip-registry-selection/#see-also","title":"See Also","text":"<ul> <li>Gateway Proxy Documentation</li> <li>Architecture Overview</li> <li>Configuration Guide</li> </ul>"},{"location":"install-from-github/","title":"Install the PipeOps Agent Directly from GitHub","text":"<p>This guide shows how to bootstrap a PipeOps-managed Kubernetes environment using the public installation script that lives in this repository (<code>scripts/install.sh</code>). The script supports intelligent cluster detection, automated monitoring setup, and both server and worker node flows.</p> <p>The commands below download the script straight from GitHub. Feel free to clone the repo instead if you prefer to review the script locally before running it.</p>"},{"location":"install-from-github/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>curl</code> and <code>bash</code></li> <li>A PipeOps control plane token with permissions to register clusters</li> <li>For k3s (production): Root privileges (run with <code>sudo</code> or as root)</li> <li>For k3d/kind/minikube (development): Docker installed and run as regular user (do not use <code>sudo</code>)</li> <li>Optional: Virtualization enabled (for minikube with VM driver)</li> </ul>"},{"location":"install-from-github/#1-export-the-required-environment-variables","title":"1. Export the Required Environment Variables","text":"<pre><code>export PIPEOPS_TOKEN=\"your-pipeops-token\"\n# Optional but recommended for clarity in the dashboard\nexport CLUSTER_NAME=\"my-pipeops-cluster\"\n# Optional: pin a specific distribution (k3s|minikube|k3d|kind|auto)\n# export CLUSTER_TYPE=\"auto\"\n</code></pre> <p>The installer reads additional toggles such as <code>AUTO_DETECT</code>, <code>DISABLE_MONITORING</code>, or <code>PIPEOPS_AGENT_VERSION</code>. See <code>scripts/README.md</code> for the full matrix of inputs.</p>"},{"location":"install-from-github/#2-run-the-installer","title":"2. Run the Installer","text":""},{"location":"install-from-github/#auto-detection-recommended","title":"Auto-Detection (Recommended)","text":"<pre><code># The installer will automatically detect the best cluster type for your environment\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre>"},{"location":"install-from-github/#production-k3s-requires-root","title":"Production k3s (Requires Root)","text":"<pre><code># Use sudo for k3s on production servers/VMs\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | sudo bash\n</code></pre>"},{"location":"install-from-github/#development-clusters-do-not-use-sudo","title":"Development Clusters (Do NOT Use Sudo)","text":"<pre><code># For k3d, kind, or minikube - run as regular user WITHOUT sudo\nexport CLUSTER_TYPE=\"k3d\"  # or \"kind\" or \"minikube\"\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre> <p>Why pipe into <code>bash</code>? Some hardened distros disable <code>/dev/fd</code>, which breaks process-substitution (<code>bash &lt;(curl \u2026)</code>) with errors like <code>bash: /dev/fd/63: No such file or directory</code>. Streaming the script into <code>bash</code> avoids that limitation while still letting you inspect it beforehand if desired.</p> <p>\u26a0\ufe0f Important: Development cluster types (k3d, kind, minikube) use Docker and must NOT be run with sudo, as Docker Desktop is not available to the root user on macOS and will fail. The installer will automatically detect if you're running as root and provide appropriate guidance.</p> <p>What happens under the hood:</p> <ol> <li>System resources and environment are analyzed (CPU, RAM, disks, Docker, virtualization, cloud vendor, etc.).</li> <li>The optimal Kubernetes distribution is selected (or the value you set in <code>CLUSTER_TYPE</code> is honored).</li> <li>A cluster is bootstrapped and the PipeOps agent is deployed.</li> <li>The monitoring stack (Prometheus, Loki, Grafana, OpenCost) is installed unless you disable it.</li> <li>Connection details are printed so additional worker nodes can join safely.</li> </ol>"},{"location":"install-from-github/#3-verify-the-installation","title":"3. Verify the Installation","text":"<pre><code>kubectl get pods -n pipeops-system\nkubectl get pods -n pipeops-monitoring\n</code></pre> <p>You should see the agent pod plus the monitoring components in the <code>Running</code> state. The installer logs also display the tunnel endpoints that the control plane will expose.</p>"},{"location":"install-from-github/#4-join-additional-worker-nodes-optional","title":"4. Join Additional Worker Nodes (Optional)","text":"<p>On each worker machine run:</p> <pre><code>export K3S_URL=\"https://&lt;server-ip&gt;:6443\"\nexport K3S_TOKEN=\"&lt;token printed by install.sh&gt;\"\ncurl -fsSL https://get.pipeops.dev/k8-join-worker.sh | bash\n</code></pre> <p>Alternatively, rerun <code>install.sh cluster-info</code> on the server to display the join command.</p>"},{"location":"install-from-github/#5-updating-or-uninstalling","title":"5. Updating or Uninstalling","text":"<pre><code># Update the agent and monitoring stack to the latest release\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash -s -- update\n\n# Remove the stack (cluster, agent, monitoring)\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash -s -- uninstall\n</code></pre>"},{"location":"install-from-github/#install-only-the-agent-on-an-existing-cluster","title":"Install Only the Agent on an Existing Cluster","text":"<p>Already running Kubernetes? You can deploy just the PipeOps agent without provisioning a new cluster or installing the monitoring stack.</p>"},{"location":"install-from-github/#requirements","title":"Requirements","text":"<ul> <li><code>kubectl</code> configured with cluster-admin privileges</li> <li><code>sed</code> (available by default on macOS/Linux) for Option A substitutions</li> <li>PipeOps control plane credentials (<code>PIPEOPS_TOKEN</code>)</li> </ul>"},{"location":"install-from-github/#1-export-the-required-values","title":"1. Export the required values","text":"<pre><code>export PIPEOPS_TOKEN=\"your-pipeops-token\"\nexport PIPEOPS_CLUSTER_NAME=\"my-existing-cluster\"\n</code></pre>"},{"location":"install-from-github/#common-environment-variables","title":"Common environment variables","text":"Variable Required Description <code>PIPEOPS_TOKEN</code> \u2705 Control plane token with permissions to register the cluster. <code>PIPEOPS_CLUSTER_NAME</code> \u2705 Friendly name that appears in the PipeOps dashboard. <code>PIPEOPS_ENVIRONMENT</code> Optional Set to <code>dev</code>, <code>staging</code>, or <code>production</code> to apply the matching resource profile during bootstrap. <code>PIPEOPS_API_URL</code> Optional Override the API endpoint if you are targeting a custom control plane deployment. <code>INSTALL_MONITORING</code> Optional Set to <code>false</code> before running the installer if you want to skip the Prometheus/Loki/Grafana stack."},{"location":"install-from-github/#2-apply-the-manifest-straight-from-github","title":"2. Apply the manifest straight from GitHub","text":"<p>The commands below replace the placeholder values in <code>deployments/agent.yaml</code> before piping the manifest to <code>kubectl</code>:</p> <p>Option A \u2013 Bash helpers (quickest):</p> <pre><code>curl -fsSL https://get.pipeops.dev/k8-agent.yaml \\\n  | sed \"s/PIPEOPS_TOKEN: \\\"your-token-here\\\"/PIPEOPS_TOKEN: \\\"${PIPEOPS_TOKEN}\\\"/\" \\\n  | sed \"s/token: \\\"your-token-here\\\"/token: \\\"${PIPEOPS_TOKEN}\\\"/\" \\\n  | sed \"s/cluster_name: \\\"default-cluster\\\"/cluster_name: \\\"${PIPEOPS_CLUSTER_NAME}\\\"/\" \\\n  | kubectl apply -f -\n</code></pre> <p>Option B \u2013 kubectl only (no sed):</p> <pre><code># Apply core resources (namespace, RBAC, deployment, etc.)\nkubectl apply -f https://get.pipeops.dev/k8-agent.yaml \\\n  --selector app.kubernetes.io/component!=config\n\n# Create/update the secret with your token and metadata\nkubectl create secret generic pipeops-agent-config -n pipeops-system \\\n  --from-literal=PIPEOPS_TOKEN=\"${PIPEOPS_TOKEN}\" \\\n  --from-literal=PIPEOPS_CLUSTER_NAME=\"${PIPEOPS_CLUSTER_NAME}\" \\\n  --from-literal=PIPEOPS_API_URL=\"https://api.pipeops.sh\" \\\n  --dry-run=client -o yaml | kubectl apply -f -\n\n# Create/update the agent ConfigMap with concrete values\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: pipeops-agent-config\n  namespace: pipeops-system\ndata:\n  config.yaml: |\n    agent:\n      id: \"\"\n      name: \"pipeops-agent\"\n      cluster_name: \"${PIPEOPS_CLUSTER_NAME}\"\n      labels:\n        environment: \"production\"\n        managed-by: \"pipeops\"\n    pipeops:\n      api_url: \"https://api.pipeops.sh\"\n      token: \"${PIPEOPS_TOKEN}\"\n      timeout: \"30s\"\n      reconnect:\n        enabled: true\n        max_attempts: 10\n        interval: \"5s\"\n        backoff: \"5s\"\n      tls:\n        enabled: true\n        insecure_skip_verify: false\n    tunnel:\n      enabled: true\n      inactivity_timeout: \"5m\"\n      forwards:\n        - name: \"kubernetes-api\"\n          local_addr: \"localhost:6443\"\n          remote_port: 0\n        - name: \"kubelet-metrics\"\n          local_addr: \"localhost:10250\"\n          remote_port: 0\n        - name: \"agent-http\"\n          local_addr: \"localhost:8080\"\n          remote_port: 0\n    kubernetes:\n      in_cluster: true\n      namespace: \"pipeops-system\"\n    logging:\n      level: \"info\"\n      format: \"json\"\n      output: \"stdout\"\nEOF\n</code></pre>"},{"location":"install-from-github/#3-verify-the-rollout","title":"3. Verify the rollout","text":"<pre><code>kubectl rollout status deployment/pipeops-agent -n pipeops-system\nkubectl logs deployment/pipeops-agent -n pipeops-system\n</code></pre>"},{"location":"install-from-github/#4-optional-tweaks","title":"4. Optional tweaks","text":"<ul> <li>To disable the tunnel or adjust monitoring forwards, update the <code>pipeops-agent-config</code> ConfigMap before restarting the deployment.</li> <li>To customize TLS validation, patch the <code>PIPEOPS_TLS_*</code> keys in the same ConfigMap or secret.</li> </ul> <p>When you no longer need the agent, remove it with:</p> <pre><code>kubectl delete namespace pipeops-system --ignore-not-found\n</code></pre>"},{"location":"install-from-github/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ul> <li>Use <code>LOG_LEVEL=debug</code> to increase script verbosity.</li> <li>Set <code>PIPEOPS_TLS_INSECURE_SKIP_VERIFY=true</code> if your control plane uses a self-signed certificate.</li> <li>Run <code>./scripts/install.sh --help</code> after cloning for a full list of supported flags and environment variables.</li> </ul> <p>For advanced scenarios (air-gapped clusters, custom Helm overrides, external etcd) refer to <code>scripts/README.md</code> and the examples under <code>scripts/examples/</code>.</p>"},{"location":"local-development/","title":"Local Development Guide","text":""},{"location":"local-development/#why-no-token-locally","title":"Why No Token Locally?","text":"<p>When running the agent locally (not in a Kubernetes pod), you'll see this warning:</p> <pre><code>\"No cluster ServiceAccount token available - control plane will not be able to access cluster\"\n</code></pre> <p>This is expected because:</p> <ol> <li> <p>In Kubernetes: The pod automatically has a ServiceAccount token mounted at:    <pre><code>/var/run/secrets/kubernetes.io/serviceaccount/token\n</code></pre></p> </li> <li> <p>Locally: This path doesn't exist, so the agent can't find the token.</p> </li> </ol>"},{"location":"local-development/#token-loading-priority","title":"Token Loading Priority","text":"<p>The agent tries to load the token in this order:</p> <pre><code>1. K8s mount:  /var/run/secrets/kubernetes.io/serviceaccount/token  (production)\n   \u2193 If not found...\n2. State file: tmp/agent-state.yaml (or other state locations)     (local dev)\n   \u2193 If not found...\n3. Warn:       \"No ServiceAccount token available\"                 (harmless warning)\n</code></pre>"},{"location":"local-development/#testing-token-functionality-locally","title":"Testing Token Functionality Locally","text":""},{"location":"local-development/#option-1-generate-mock-token-recommended","title":"Option 1: Generate Mock Token (Recommended)","text":"<p>Use the convenient make target:</p> <pre><code>make generate-token\n</code></pre> <p>This creates a <code>tmp/agent-state.yaml</code> file with a mock JWT token:</p> <pre><code>agent_id: \"\"\ncluster_id: \"\"\ncluster_token: eyJhbGci...MOCK-SIGNATURE\n</code></pre> <p>Then run the agent:</p> <pre><code>make run\n</code></pre> <p>You should now see:</p> <pre><code>\"Loaded cluster token from state\"\n\"has_token\": true\n</code></pre>"},{"location":"local-development/#option-2-extract-real-token-from-k8s-cluster","title":"Option 2: Extract Real Token from K8s Cluster","text":"<p>If you have access to a K8s cluster with the agent deployed:</p> <pre><code># Get the token from the running pod\nkubectl exec -n pipeops-system deployment/pipeops-agent -- \\\n  cat /var/run/secrets/kubernetes.io/serviceaccount/token &gt; .pipeops-cluster-token\n\n# Restart local agent\nmake run\n</code></pre>"},{"location":"local-development/#option-3-manually-create-token-file","title":"Option 3: Manually Create Token File","text":"<p>Create <code>.pipeops-cluster-token</code> with any string:</p> <pre><code>echo \"test-token-for-local-development\" &gt; .pipeops-cluster-token\n</code></pre>"},{"location":"local-development/#verifying-token-is-loaded","title":"Verifying Token is Loaded","text":"<p>After creating the token file, run the agent and check logs:</p> <pre><code>make run\n</code></pre> <p>With token: <pre><code>{\"level\":\"info\",\"msg\":\"Loaded cluster token from disk\"}\n{\"has_token\":true,\"msg\":\"Using existing cluster ID, skipping re-registration\"}\n</code></pre></p> <p>Without token: <pre><code>{\"level\":\"warning\",\"msg\":\"No cluster ServiceAccount token available\"}\n{\"has_token\":false,\"msg\":\"Using existing cluster ID, skipping re-registration\"}\n</code></pre></p>"},{"location":"local-development/#testing-token-in-requests","title":"Testing Token in Requests","text":""},{"location":"local-development/#check-health-endpoint","title":"Check Health Endpoint","text":"<pre><code>curl http://host.docker.internal:8080/health | jq .\n</code></pre> <p>With token: <pre><code>{\n  \"status\": \"healthy\",\n  \"cluster_id\": \"agent-hostname-hash\",\n  \"has_cluster_token\": true,  \u2190 Token available\n  \"last_token_update\": \"2025-10-14T17:50:23+01:00\"\n}\n</code></pre></p> <p>Without token: <pre><code>{\n  \"status\": \"healthy\",\n  \"cluster_id\": \"agent-hostname-hash\",\n  \"has_cluster_token\": false,  \u2190 No token\n  \"last_token_update\": null\n}\n</code></pre></p>"},{"location":"local-development/#inspect-registration-request","title":"Inspect Registration Request","text":"<p>If you have a local mock control plane or want to see what's being sent:</p> <pre><code># Enable debug logging\nexport LOG_LEVEL=debug\n\n# Run agent\nmake run\n</code></pre> <p>Look for the registration request body in logs: <pre><code>{\n  \"agent_id\": \"agent-hostname-hash\",\n  \"name\": \"local-dev-cluster\",\n  \"token\": \"eyJhbGci...\",  \u2190 Token included if available\n  \"k8s_version\": \"v1.28.3+k3s1\"\n}\n</code></pre></p>"},{"location":"local-development/#production-deployment","title":"Production Deployment","text":"<p>In production (K8s pod), the token is automatically available:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pipeops-agent\nspec:\n  template:\n    spec:\n      serviceAccountName: pipeops-agent  \u2190 K8s auto-mounts token\n      containers:\n      - name: agent\n        image: ghcr.io/pipeopshq/pipeops-k8-agent:latest\n</code></pre> <p>Pod logs will show: <pre><code>\"Loaded ServiceAccount token from Kubernetes mount\"\n\"has_token\": true\n</code></pre></p>"},{"location":"local-development/#token-files-location","title":"Token Files Location","text":"<p>The agent looks for token files in these locations (in order):</p> <ol> <li><code>/var/lib/pipeops/cluster-token</code> (production)</li> <li><code>/etc/pipeops/cluster-token</code> (system-wide)</li> <li><code>.pipeops-cluster-token</code> (local dev)</li> </ol> <p>For local development, just use option 3 (<code>.pipeops-cluster-token</code> in the project root).</p>"},{"location":"local-development/#summary","title":"Summary","text":"Environment Token Source Expected Behavior Local Dev <code>.pipeops-cluster-token</code> file Warning if file doesn't exist (harmless) K8s Pod <code>/var/run/secrets/.../token</code> Automatically loaded, no warning Testing Mock token script Simulates K8s behavior locally <p>The warning you saw is completely normal for local development! The agent will still work, it just won't send a token to the control plane (which is fine for testing).</p> <p>To test with a token locally, just run:</p> <pre><code>./scripts/generate-mock-token.sh\nmake run\n</code></pre> <p>\ud83d\ude80 Happy developing!</p>"},{"location":"advanced/gateway-api-setup/","title":"Gateway API and Istio Setup","text":"<p>This guide covers the installation and configuration of Kubernetes Gateway API (experimental) and Istio with alpha gateway API support for the PipeOps agent.</p>"},{"location":"advanced/gateway-api-setup/#overview","title":"Overview","text":"<p>PipeOps uses Kubernetes Gateway API with Istio as the gateway controller by default. This is the recommended and standard approach for TCP/UDP routing in PipeOps deployments.</p> <p>The PipeOps agent supports TCP/UDP port exposure via: - Kubernetes Gateway API - Default and recommended - Modern, standardized approach with Istio controller - Istio Gateway/VirtualService - Legacy alternative - Traditional Istio networking (if you prefer not to use Gateway API)</p> <p>When using Gateway API with Istio, you must enable experimental Gateway API features and configure Istio with alpha gateway API support.</p> <p>Key Configuration: - Gateway API: <code>agent.gateway.gatewayApi.enabled=true</code> (default) - Istio controller: <code>gatewayClassName: istio</code> - Requires: <code>PILOT_ENABLE_ALPHA_GATEWAY_API=true</code> in Istio</p>"},{"location":"advanced/gateway-api-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (1.19+)</li> <li>kubectl configured</li> <li>Helm 3.2.0+ (for Istio installation)</li> <li>(Optional) istioctl (only if you prefer istioctl over Helm)</li> </ul>"},{"location":"advanced/gateway-api-setup/#gateway-api-installation","title":"Gateway API Installation","text":""},{"location":"advanced/gateway-api-setup/#install-gateway-api-experimental-crds","title":"Install Gateway API Experimental CRDs","text":"<p>The Gateway API experimental installation includes support for TCPRoute and UDPRoute resources which are required for Layer 4 (TCP/UDP) traffic:</p> <pre><code>kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.3.0/experimental-install.yaml\n</code></pre> <p>This installs: - Gateway API Core CRDs (v1) - Experimental CRDs including:   - <code>TCPRoute</code> (v1alpha2)   - <code>UDPRoute</code> (v1alpha2)   - <code>TLSRoute</code> (v1alpha2)   - <code>GRPCRoute</code> (v1alpha2)</p> <p>Why Experimental?</p> <p>The experimental channel is required because TCPRoute and UDPRoute are still in alpha/beta stage and not yet part of the standard Gateway API release. The PipeOps agent uses these resources to route TCP/UDP traffic for services.</p>"},{"location":"advanced/gateway-api-setup/#verify-installation","title":"Verify Installation","text":"<pre><code># Check Gateway API CRDs are installed\nkubectl get crd | grep gateway\n\n# Expected output includes:\n# gateways.gateway.networking.k8s.io\n# gatewayclasses.gateway.networking.k8s.io\n# httproutes.gateway.networking.k8s.io\n# tcproutes.gateway.networking.k8s.io\n# udproutes.gateway.networking.k8s.io\n</code></pre>"},{"location":"advanced/gateway-api-setup/#istio-installation-with-alpha-gateway-api","title":"Istio Installation with Alpha Gateway API","text":""},{"location":"advanced/gateway-api-setup/#why-enable-alpha-gateway-api","title":"Why Enable Alpha Gateway API?","text":"<p>Important: Istio has partial Gateway API support enabled by default (HTTPRoute, TLSRoute), but TCPRoute and UDPRoute support is NOT enabled by default. </p> <p>Since PipeOps requires TCPRoute/UDPRoute for Layer 4 (TCP/UDP) traffic routing, you must explicitly enable alpha Gateway API features with the <code>PILOT_ENABLE_ALPHA_GATEWAY_API=true</code> flag.</p> Feature Default Status With Alpha Flag HTTPRoute \u2705 Enabled \u2705 Enabled TLSRoute (passthrough) \u2705 Enabled \u2705 Enabled TCPRoute \u274c Disabled \u2705 Enabled UDPRoute \u274c Disabled \u2705 Enabled"},{"location":"advanced/gateway-api-setup/#install-istio-with-gateway-api-support-helm-recommended","title":"Install Istio with Gateway API Support (Helm - Recommended)","text":"<p>For automated installation without requiring <code>istioctl</code>, use Helm:</p> <pre><code># Add Istio Helm repository\nhelm repo add istio https://istio-release.storage.googleapis.com/charts\nhelm repo update\n\n# Create istio-system namespace\nkubectl create namespace istio-system\n\n# Install Istio base (CRDs)\nhelm install istio-base istio/base -n istio-system --wait\n\n# Install Istiod with Gateway API alpha support\nhelm install istiod istio/istiod -n istio-system \\\n  --set pilot.env.PILOT_ENABLE_ALPHA_GATEWAY_API=true \\\n  --wait\n</code></pre> <p>Configuration Breakdown:</p> <ul> <li><code>PILOT_ENABLE_ALPHA_GATEWAY_API=true</code> - Required to enable TCPRoute and UDPRoute support in Istio</li> <li>Without this flag, only HTTPRoute and TLSRoute work</li> <li>No ingress gateway installation needed (we use Gateway API instead)</li> </ul> <p>Custom Values File (Optional):</p> <p>Create <code>istio-values.yaml</code>:</p> <pre><code>pilot:\n  env:\n    PILOT_ENABLE_ALPHA_GATEWAY_API: true\n  resources:\n    requests:\n      cpu: 100m\n      memory: 256Mi\n    limits:\n      cpu: 1000m\n      memory: 1Gi\n</code></pre> <p>Install with custom values:</p> <pre><code>helm install istiod istio/istiod -n istio-system \\\n  -f istio-values.yaml \\\n  --wait\n</code></pre>"},{"location":"advanced/gateway-api-setup/#alternative-using-istioctl-requires-istioctl-binary","title":"Alternative: Using istioctl (Requires istioctl Binary)","text":"<p>If you have <code>istioctl</code> installed:</p> <pre><code>istioctl install -y \\\n  --set \"components.ingressGateways[0].name=istio-ingressgateway\" \\\n  --set \"components.ingressGateways[0].enabled=false\" \\\n  --set \"components.ingressGateways[0].k8s.service.type=ClusterIP\" \\\n  --set \"components.ingressGateways[0].k8s.service.externalTrafficPolicy=Local\" \\\n  --set \"values.pilot.env.PILOT_ENABLE_ALPHA_GATEWAY_API=true\"\n</code></pre>"},{"location":"advanced/gateway-api-setup/#verify-istio-installation","title":"Verify Istio Installation","text":"<pre><code># Check Istio is running\nkubectl get pods -n istio-system\n\n# Should see istiod pod running\n# NAME                      READY   STATUS    RESTARTS   AGE\n# istiod-xxxxx-xxxxx        1/1     Running   0          1m\n\n# Verify Gateway API support is enabled\nkubectl logs -n istio-system deployment/istiod | grep \"Gateway API\"\n</code></pre>"},{"location":"advanced/gateway-api-setup/#pipeops-agent-configuration","title":"PipeOps Agent Configuration","text":""},{"location":"advanced/gateway-api-setup/#using-gateway-api","title":"Using Gateway API","text":"<p>Configure the PipeOps agent to use Gateway API in your <code>values.yaml</code>:</p> <pre><code>agent:\n  gateway:\n    enabled: true\n    environment:\n      mode: managed  # or single-vm for K3s/single node\n      # vmIP: \"192.168.1.100\"  # Required for single-vm mode\n\n    gatewayApi:\n      enabled: true\n      gateway:\n        name: pipeops-gateway\n        gatewayClassName: istio  # Must match installed GatewayClass\n        listeners:\n          - name: tcp-ssh\n            port: 2222\n            protocol: TCP\n          - name: tcp-custom\n            port: 5000\n            protocol: TCP\n\n      tcpRoutes:\n        - name: ssh-route\n          sectionName: tcp-ssh\n          backendRefs:\n            - name: ssh-service\n              namespace: default\n              port: 22\n        - name: app-route\n          sectionName: tcp-custom\n          backendRefs:\n            - name: app-service\n              namespace: default\n              port: 5000\n</code></pre>"},{"location":"advanced/gateway-api-setup/#using-traditional-istio-gateway","title":"Using Traditional Istio Gateway","text":"<p>If you prefer traditional Istio Gateway/VirtualService:</p> <pre><code>agent:\n  gateway:\n    enabled: true\n\n    istio:\n      enabled: true\n      gateway:\n        name: pipeops-istio-gateway\n        selector:\n          istio: ingressgateway\n        servers:\n          - port:\n              number: 2222\n              name: tcp-ssh\n              protocol: TCP\n            hosts:\n              - \"*\"\n          - port:\n              number: 5000\n              name: tcp-app\n              protocol: TCP\n\n      virtualService:\n        tcpRoutes:\n          - port: 2222\n            destination:\n              host: ssh-service.default.svc.cluster.local\n              port: 22\n          - port: 5000\n            destination:\n              host: app-service.default.svc.cluster.local\n              port: 5000\n</code></pre>"},{"location":"advanced/gateway-api-setup/#deploy-the-agent","title":"Deploy the Agent","text":"<p>Install with Helm:</p> <pre><code>helm install pipeops-agent ./helm/pipeops-agent \\\n  --set agent.pipeops.token=\"your-token\" \\\n  --set agent.cluster.name=\"your-cluster\" \\\n  -f gateway-values.yaml\n</code></pre> <p>Or upgrade existing installation:</p> <pre><code>helm upgrade pipeops-agent ./helm/pipeops-agent \\\n  -f gateway-values.yaml\n</code></pre>"},{"location":"advanced/gateway-api-setup/#verification","title":"Verification","text":""},{"location":"advanced/gateway-api-setup/#check-gateway-resources","title":"Check Gateway Resources","text":"<pre><code># List Gateways\nkubectl get gateway -A\n\n# Check Gateway status\nkubectl describe gateway pipeops-gateway -n pipeops-system\n\n# List TCPRoutes\nkubectl get tcproute -A\n\n# Check route status\nkubectl describe tcproute ssh-route -n pipeops-system\n</code></pre>"},{"location":"advanced/gateway-api-setup/#test-connectivity","title":"Test Connectivity","text":"<pre><code># Get the Gateway external IP/hostname\nkubectl get gateway pipeops-gateway -n pipeops-system -o jsonpath='{.status.addresses[0].value}'\n\n# Test TCP connection (replace with actual IP)\nnc -zv &lt;gateway-ip&gt; 2222\nnc -zv &lt;gateway-ip&gt; 5000\n</code></pre>"},{"location":"advanced/gateway-api-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced/gateway-api-setup/#tcprouteudproute-resources-not-accepted","title":"TCPRoute/UDPRoute Resources Not Accepted","text":"<p>Symptom: Gateway accepts the configuration but TCPRoute/UDPRoute resources show <code>Accepted: False</code> or are ignored.</p> <p>Cause: <code>PILOT_ENABLE_ALPHA_GATEWAY_API</code> flag not enabled in Istio.</p> <pre><code># Check if the flag is enabled\nkubectl get deployment istiod -n istio-system -o yaml | grep PILOT_ENABLE_ALPHA_GATEWAY_API\n\n# Should return:\n# - name: PILOT_ENABLE_ALPHA_GATEWAY_API\n#   value: \"true\"\n\n# If not found, upgrade Istio with the flag\nhelm upgrade istiod istio/istiod -n istio-system \\\n  --set pilot.env.PILOT_ENABLE_ALPHA_GATEWAY_API=true \\\n  --reuse-values \\\n  --wait\n\n# Restart istiod pods\nkubectl rollout restart deployment/istiod -n istio-system\n</code></pre>"},{"location":"advanced/gateway-api-setup/#gateway-api-crds-not-found","title":"Gateway API CRDs Not Found","text":"<p>If you see errors about TCPRoute or UDPRoute not being found:</p> <pre><code># Verify experimental CRDs are installed\nkubectl get crd tcproutes.gateway.networking.k8s.io\nkubectl get crd udproutes.gateway.networking.k8s.io\n\n# Reinstall if missing\nkubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.3.0/experimental-install.yaml\n</code></pre>"},{"location":"advanced/gateway-api-setup/#istio-not-recognizing-gateway-api","title":"Istio Not Recognizing Gateway API","text":"<p>If Istio doesn't create resources for Gateway API objects:</p> <pre><code># Check if alpha feature is enabled\nkubectl logs -n istio-system deployment/istiod | grep PILOT_ENABLE_ALPHA_GATEWAY_API\n\n# If not found, reinstall Istio with the flag\nistioctl install -y --set \"values.pilot.env.PILOT_ENABLE_ALPHA_GATEWAY_API=true\"\n</code></pre>"},{"location":"advanced/gateway-api-setup/#gateway-not-getting-ip-address","title":"Gateway Not Getting IP Address","text":"<pre><code># Check Gateway events\nkubectl describe gateway pipeops-gateway -n pipeops-system\n\n# Check if GatewayClass exists and is supported\nkubectl get gatewayclass\n\n# Verify Istio GatewayClass\nkubectl get gatewayclass istio -o yaml\n</code></pre>"},{"location":"advanced/gateway-api-setup/#routes-not-working","title":"Routes Not Working","text":"<pre><code># Check TCPRoute status\nkubectl get tcproute -A -o wide\n\n# Check route events\nkubectl describe tcproute &lt;route-name&gt; -n pipeops-system\n\n# Verify backend services exist\nkubectl get svc -A\n\n# Check Istio proxy logs\nkubectl logs -n istio-system deployment/istiod\n</code></pre>"},{"location":"advanced/gateway-api-setup/#production-considerations","title":"Production Considerations","text":""},{"location":"advanced/gateway-api-setup/#gateway-class-selection","title":"Gateway Class Selection","text":"<p>The <code>gatewayClassName</code> must match an installed GatewayClass:</p> <pre><code># List available GatewayClasses\nkubectl get gatewayclass\n\n# Common values:\n# - istio (when using Istio)\n# - nginx (when using NGINX Gateway)\n# - kong (when using Kong)\n</code></pre>"},{"location":"advanced/gateway-api-setup/#resource-limits","title":"Resource Limits","text":"<p>Gateway resources consume cluster resources. For production:</p> <pre><code>agent:\n  resources:\n    limits:\n      cpu: 1000m\n      memory: 1Gi\n    requests:\n      cpu: 250m\n      memory: 256Mi\n</code></pre>"},{"location":"advanced/gateway-api-setup/#high-availability","title":"High Availability","text":"<p>For production workloads, consider: - Multiple Gateway replicas - LoadBalancer service type - Health checks on backend services - Resource quotas and limits</p>"},{"location":"advanced/gateway-api-setup/#security","title":"Security","text":"<ul> <li>Use TLS for encrypted traffic</li> <li>Implement network policies</li> <li>Restrict Gateway to specific namespaces</li> <li>Use RBAC for Gateway resources</li> </ul>"},{"location":"advanced/gateway-api-setup/#uninstalling","title":"Uninstalling","text":""},{"location":"advanced/gateway-api-setup/#uninstall-pipeops-agent-gateway","title":"Uninstall PipeOps Agent Gateway","text":"<pre><code>helm uninstall pipeops-agent -n pipeops-system\n</code></pre>"},{"location":"advanced/gateway-api-setup/#uninstall-istio-helm","title":"Uninstall Istio (Helm)","text":"<pre><code># Remove Istiod\nhelm uninstall istiod -n istio-system\n\n# Remove Istio base\nhelm uninstall istio-base -n istio-system\n\n# Clean up namespace (optional)\nkubectl delete namespace istio-system\n</code></pre>"},{"location":"advanced/gateway-api-setup/#uninstall-gateway-api-crds","title":"Uninstall Gateway API CRDs","text":"<pre><code>kubectl delete -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.3.0/experimental-install.yaml\n</code></pre> <p>\u26a0\ufe0f Warning: Deleting Gateway API CRDs will remove all Gateway, TCPRoute, and UDPRoute resources in your cluster.</p>"},{"location":"advanced/gateway-api-setup/#references","title":"References","text":"<ul> <li>Kubernetes Gateway API</li> <li>Gateway API Experimental Features</li> <li>Istio Gateway API Documentation</li> <li>Istio Installation Guide</li> <li>TCPRoute Specification</li> </ul>"},{"location":"advanced/gateway-api-setup/#next-steps","title":"Next Steps","text":"<ul> <li>Configure monitoring for gateways</li> <li>Set up TLS certificates</li> <li>Configure custom domains</li> </ul>"},{"location":"advanced/gateway-proxy/","title":"Gateway Proxy for Private Clusters","text":"<p>The PipeOps agent automatically provides external access to applications in private Kubernetes clusters that don't have public LoadBalancer IPs.</p>"},{"location":"advanced/gateway-proxy/#overview","title":"Overview","text":"<p>The gateway proxy enables:</p> <ul> <li>Private cluster support \u2014 No public IP addresses required</li> <li>Automatic ingress detection \u2014 Monitors all ingress resources</li> <li>Route registration \u2014 Registers routes with controller via REST API</li> <li>Custom domains \u2014 Full support for custom domain mapping</li> <li>TLS termination \u2014 Secure HTTPS access at gateway level</li> <li>Dual routing modes \u2014 Optimized routing based on cluster type</li> </ul>"},{"location":"advanced/gateway-proxy/#how-it-works","title":"How It Works","text":""},{"location":"advanced/gateway-proxy/#automatic-cluster-detection","title":"Automatic Cluster Detection","text":"<p>When the agent starts, it automatically detects your cluster type:</p> <pre><code>graph LR\n    A[Agent Starts] --&gt; B{Check LoadBalancer}\n    B --&gt;|Has External IP| C[Public Cluster]\n    B --&gt;|No External IP| D[Private Cluster]\n    C --&gt; E[Direct Routing Mode]\n    D --&gt; F[Tunnel Routing Mode]\n    E --&gt; G[Start Ingress Watcher]\n    F --&gt; G</code></pre> <p>Detection Logic:</p> <ul> <li>Checks for <code>ingress-nginx-controller</code> service</li> <li>Verifies if it's a LoadBalancer type</li> <li>Waits up to 2 minutes for external IP assignment</li> <li>Returns <code>isPrivate=true</code> if no external IP</li> </ul>"},{"location":"advanced/gateway-proxy/#routing-modes","title":"Routing Modes","text":""},{"location":"advanced/gateway-proxy/#direct-routing-public-clusters","title":"Direct Routing (Public Clusters)","text":"<p>For clusters with public LoadBalancer IPs:</p> <pre><code>User Request\n    \u2193\nDNS Resolution\n    \u2193\nGateway Proxy (Controller)\n    \u2193\nLoadBalancer IP (203.0.113.45:80)\n    \u2193\nIngress Controller\n    \u2193\nService \u2192 Pod\n</code></pre> <p>Benefits: - 3-5x faster than tunnel mode - Lower bandwidth usage - Reduced controller load - No tunnel overhead</p>"},{"location":"advanced/gateway-proxy/#tunnel-routing-private-clusters","title":"Tunnel Routing (Private Clusters)","text":"<p>For clusters without public IPs:</p> <pre><code>User Request\n    \u2193\nDNS Resolution\n    \u2193\nGateway Proxy (Controller)\n    \u2193\nWebSocket Tunnel\n    \u2193\nAgent in Private Cluster\n    \u2193\nIngress Controller\n    \u2193\nService \u2192 Pod\n</code></pre> <p>Benefits: - Works in private networks - No inbound firewall rules needed - Secure by default - Zero configuration required</p>"},{"location":"advanced/gateway-proxy/#ingress-route-discovery","title":"Ingress Route Discovery","text":"<p>The agent automatically watches all ingress resources:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-app\n  namespace: default\nspec:\n  rules:\n  - host: my-app.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-app\n            port:\n              number: 8080\n</code></pre> <p>The agent:</p> <ol> <li>Detects the ingress creation</li> <li>Extracts route information:</li> <li>Host: <code>my-app.example.com</code></li> <li>Path: <code>/</code></li> <li>Service: <code>my-app</code></li> <li>Port: <code>8080</code></li> <li>Registers route with controller API</li> </ol>"},{"location":"advanced/gateway-proxy/#route-registration","title":"Route Registration","text":"<p>Routes are registered via REST API:</p> <pre><code>POST /api/v1/gateway/routes/register\n</code></pre> <p>Request: <pre><code>{\n  \"hostname\": \"my-app.example.com\",\n  \"cluster_uuid\": \"abc-123\",\n  \"namespace\": \"default\",\n  \"service_name\": \"my-app\",\n  \"service_port\": 8080,\n  \"ingress_name\": \"my-app\",\n  \"path\": \"/\",\n  \"path_type\": \"Prefix\",\n  \"tls\": false,\n  \"public_endpoint\": \"203.0.113.45:80\",\n  \"routing_mode\": \"direct\"\n}\n</code></pre></p>"},{"location":"advanced/gateway-proxy/#configuration","title":"Configuration","text":"<p>Gateway proxy is enabled automatically with zero configuration required.</p>"},{"location":"advanced/gateway-proxy/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>PIPEOPS_API_URL</code> Controller API URL <code>https://api.pipeops.io</code> <code>PIPEOPS_TOKEN</code> Authentication token Required"},{"location":"advanced/gateway-proxy/#verify-gateway-status","title":"Verify Gateway Status","text":"<p>Check agent logs to verify gateway proxy is running:</p> <pre><code>kubectl logs deployment/pipeops-agent -n pipeops-system | grep gateway\n</code></pre> <p>Expected output: <pre><code>INFO  Initializing gateway proxy detection...\nINFO  Private cluster detected - using tunnel routing\nINFO  Syncing existing ingresses ingresses=3 routes=5 routing_mode=tunnel\nINFO  Gateway proxy ingress watcher started successfully\n</code></pre></p>"},{"location":"advanced/gateway-proxy/#custom-domains","title":"Custom Domains","text":"<p>To use custom domains:</p> <ol> <li> <p>Create ingress with your domain: <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: custom-domain-app\nspec:\n  rules:\n  - host: app.yourdomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-service\n            port:\n              number: 80\n</code></pre></p> </li> <li> <p>Configure DNS: <pre><code>app.yourdomain.com CNAME cluster-id.gateway.pipeops.io\n</code></pre></p> </li> <li> <p>Agent automatically registers the route</p> </li> <li>Access your app at <code>https://app.yourdomain.com</code></li> </ol>"},{"location":"advanced/gateway-proxy/#tlshttps-support","title":"TLS/HTTPS Support","text":"<p>Enable TLS in your ingress:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: tls-app\nspec:\n  tls:\n  - hosts:\n    - secure.example.com\n    secretName: tls-secret\n  rules:\n  - host: secure.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-service\n            port:\n              number: 443\n</code></pre> <p>The agent detects TLS configuration and registers the route with <code>tls: true</code>.</p>"},{"location":"advanced/gateway-proxy/#monitoring","title":"Monitoring","text":""},{"location":"advanced/gateway-proxy/#heartbeat-integration","title":"Heartbeat Integration","text":"<p>Gateway status is included in agent heartbeats:</p> <pre><code>{\n  \"metadata\": {\n    \"is_private\": true,\n    \"gateway_routes\": 5,\n    \"routing_mode\": \"tunnel\"\n  }\n}\n</code></pre>"},{"location":"advanced/gateway-proxy/#metrics","title":"Metrics","text":"<p>Gateway proxy exposes metrics:</p> <ul> <li><code>gateway_routes_registered_total</code> \u2014 Total routes registered</li> <li><code>gateway_routes_active</code> \u2014 Currently active routes</li> <li><code>gateway_cluster_type</code> \u2014 Cluster type (private/public)</li> </ul>"},{"location":"advanced/gateway-proxy/#logs","title":"Logs","text":"<p>Gateway proxy logs all route operations:</p> <pre><code>INFO  Ingress event detected ingress=my-app action=add routes=1\nDEBUG Registering route with controller hostname=my-app.example.com\nINFO  Route registered successfully hostname=my-app.example.com\n</code></pre>"},{"location":"advanced/gateway-proxy/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced/gateway-proxy/#routes-not-accessible","title":"Routes Not Accessible","text":"<p>Problem: Ingress created but not accessible externally</p> <p>Checks:</p> <ol> <li> <p>Verify ingress exists: <pre><code>kubectl get ingress -A\n</code></pre></p> </li> <li> <p>Check agent logs: <pre><code>kubectl logs deployment/pipeops-agent -n pipeops-system | grep -i gateway\n</code></pre></p> </li> <li> <p>Verify route registration: <pre><code>kubectl logs deployment/pipeops-agent -n pipeops-system | grep \"Registering route\"\n</code></pre></p> </li> <li> <p>Check DNS configuration: <pre><code>dig app.yourdomain.com\n</code></pre></p> </li> </ol>"},{"location":"advanced/gateway-proxy/#wrong-cluster-type-detected","title":"Wrong Cluster Type Detected","text":"<p>Problem: Cluster detected as public but should be private (or vice versa)</p> <p>Solution:</p> <p>Check LoadBalancer service: <pre><code>kubectl get svc -n ingress-nginx ingress-nginx-controller\n</code></pre></p> <p>Expected for private cluster: - Type: NodePort (not LoadBalancer), OR - Type: LoadBalancer but no EXTERNAL-IP</p> <p>Expected for public cluster: - Type: LoadBalancer - EXTERNAL-IP: assigned value</p>"},{"location":"advanced/gateway-proxy/#routes-not-registering","title":"Routes Not Registering","text":"<p>Problem: Agent running but routes not appearing in controller</p> <p>Checks:</p> <ol> <li> <p>Verify agent has correct token: <pre><code>kubectl get secret pipeops-agent-secret -n pipeops-system -o yaml\n</code></pre></p> </li> <li> <p>Check API connectivity: <pre><code>kubectl logs deployment/pipeops-agent -n pipeops-system | grep \"API request failed\"\n</code></pre></p> </li> <li> <p>Restart agent: <pre><code>kubectl rollout restart deployment/pipeops-agent -n pipeops-system\n</code></pre></p> </li> </ol>"},{"location":"advanced/gateway-proxy/#performance","title":"Performance","text":""},{"location":"advanced/gateway-proxy/#startup-time","title":"Startup Time","text":"<ul> <li>Cluster detection: &lt; 5 seconds (or 2 minutes if waiting for LoadBalancer)</li> <li>Bulk sync: Single API call registers all existing ingresses</li> <li>Typical: 50 ingresses synced in &lt; 500ms</li> </ul>"},{"location":"advanced/gateway-proxy/#runtime-performance","title":"Runtime Performance","text":"<ul> <li>Per-route registration: &lt; 100ms per ingress event</li> <li>Concurrent safe: Multiple ingresses can update simultaneously</li> <li>Network overhead:</li> <li>Direct mode: Zero overhead on data plane</li> <li>Tunnel mode: Same as existing WebSocket tunnel</li> </ul>"},{"location":"advanced/gateway-proxy/#resource-usage","title":"Resource Usage","text":"<p>Gateway proxy adds minimal overhead:</p> <ul> <li>CPU: ~5-10m additional</li> <li>Memory: ~20-30Mi additional</li> <li>Network: ~100 bytes per route update</li> </ul>"},{"location":"advanced/gateway-proxy/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"advanced/gateway-proxy/#disable-gateway-proxy","title":"Disable Gateway Proxy","text":"<p>To disable gateway proxy (not recommended):</p> <pre><code># In agent config\ngateway:\n  enabled: false\n</code></pre>"},{"location":"advanced/gateway-proxy/#custom-annotations","title":"Custom Annotations","text":"<p>Add custom annotations to ingresses:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: annotated-app\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  rules:\n  - host: app.example.com\n    # ... rest of config\n</code></pre> <p>Annotations are automatically included in route registration.</p>"},{"location":"advanced/gateway-proxy/#architecture-details","title":"Architecture Details","text":"<p>For detailed architecture information, see:</p> <ul> <li>Architecture Overview \u2014 System architecture</li> <li>Gateway Proxy Implementation \u2014 Available in source code at <code>internal/gateway/</code></li> <li>Agent-Controller Integration \u2014 See project documentation files</li> </ul>"},{"location":"advanced/gateway-proxy/#api-reference","title":"API Reference","text":""},{"location":"advanced/gateway-proxy/#controller-endpoints","title":"Controller Endpoints","text":"<p>The agent calls these controller endpoints:</p> <pre><code>POST /api/v1/gateway/routes/register    # Register single route\nPOST /api/v1/gateway/routes/sync        # Bulk sync all routes\nPOST /api/v1/gateway/routes/unregister  # Unregister route\n</code></pre> <p>All requests require: <pre><code>Authorization: Bearer &lt;agent-token&gt;\nContent-Type: application/json\n</code></pre></p>"},{"location":"advanced/gateway-proxy/#best-practices","title":"Best Practices","text":"<ol> <li>Use meaningful hostnames \u2014 Makes debugging easier</li> <li>Keep ingresses in version control \u2014 Track changes over time</li> <li>Monitor route count \u2014 Check heartbeat metadata</li> <li>Test with curl \u2014 Verify external access works</li> <li>Use TLS \u2014 Enable HTTPS for production apps</li> <li>Configure DNS properly \u2014 Set up CNAME records correctly</li> </ol>"},{"location":"advanced/gateway-proxy/#faq","title":"FAQ","text":"<p>Q: Do I need to configure anything for gateway proxy? A: No, it's automatic. The agent detects cluster type and handles everything.</p> <p>Q: Can I use my own custom domain? A: Yes, create an ingress with your domain and configure DNS CNAME to PipeOps gateway.</p> <p>Q: What if I have a LoadBalancer but want to use tunnel mode? A: The agent automatically chooses the optimal mode. Direct mode is faster when available.</p> <p>Q: How do I know which routing mode is being used? A: Check agent logs on startup or look at heartbeat metadata.</p> <p>Q: Does gateway proxy work with any ingress controller? A: It works with any standard Kubernetes ingress resource. Common controllers: nginx-ingress, Traefik, HAProxy.</p> <p>Q: Can I have both private and public clusters? A: Yes, each cluster is independently detected and configured with appropriate routing mode.</p>"},{"location":"advanced/gateway-proxy/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide \u2014 Get started with agent installation</li> <li>Configuration \u2014 Configure your agent</li> <li>Monitoring \u2014 Set up comprehensive monitoring</li> <li>Architecture \u2014 Understand the system design</li> </ul>"},{"location":"advanced/monitoring/","title":"Advanced Monitoring","text":"<p>The PipeOps Kubernetes Agent includes a comprehensive monitoring stack built on industry-standard tools. This guide covers advanced monitoring configuration, custom metrics, alerting, and troubleshooting.</p>"},{"location":"advanced/monitoring/#monitoring-stack-overview","title":"Monitoring Stack Overview","text":"<p>The agent deploys a complete observability platform:</p> <pre><code>graph TB\n    A[PipeOps Agent] --&gt; B[Prometheus]\n    A --&gt; C[Grafana]\n    A --&gt; D[Loki]\n\n    B --&gt; E[Metrics Storage]\n    C --&gt; F[Dashboards]\n    D --&gt; G[Log Aggregation]\n\n    B --&gt; H[AlertManager]\n    H --&gt; I[Notifications]\n\n    subgraph \"Data Sources\"\n        J[Kubernetes API]\n        K[Node Exporter]\n        L[Application Metrics]\n    end\n\n    J --&gt; B\n    K --&gt; B\n    L --&gt; B</code></pre>"},{"location":"advanced/monitoring/#components","title":"Components","text":"Component Purpose Port URL Prometheus Metrics collection and storage 9090 <code>http://localhost:9090</code> Grafana Visualization and dashboards 3000 <code>http://localhost:3000</code> Loki Log aggregation and search 3100 <code>http://localhost:3100</code> AlertManager Alert routing and notifications 9093 <code>http://localhost:9093</code>"},{"location":"advanced/monitoring/#quick-start","title":"Quick Start","text":""},{"location":"advanced/monitoring/#access-dashboards","title":"Access Dashboards","text":"<p>Forward ports to access monitoring interfaces:</p> <pre><code># Grafana dashboard\nkubectl port-forward -n pipeops-system svc/grafana 3000:3000\n\n# Prometheus UI\nkubectl port-forward -n pipeops-system svc/prometheus 9090:9090\n\n# Loki (for log queries)\nkubectl port-forward -n pipeops-system svc/loki 3100:3100\n</code></pre>"},{"location":"advanced/monitoring/#default-credentials","title":"Default Credentials","text":"GrafanaPrometheusAlertManager <ul> <li>URL: http://localhost:3000</li> <li>Username: <code>admin</code></li> <li>Password: Get with command below</li> </ul> <pre><code>kubectl get secret -n pipeops-system grafana-admin-password \\\n  -o jsonpath='{.data.password}' | base64 -d\n</code></pre> <ul> <li>URL: http://localhost:9090</li> <li>Authentication: None (internal access only)</li> </ul> <ul> <li>URL: http://localhost:9093 </li> <li>Authentication: None (internal access only)</li> </ul>"},{"location":"advanced/monitoring/#pre-built-dashboards","title":"Pre-built Dashboards","text":"<p>The agent includes comprehensive dashboards for monitoring your cluster:</p>"},{"location":"advanced/monitoring/#kubernetes-overview","title":"Kubernetes Overview","text":"<ul> <li>Cluster resource utilization</li> <li>Node health and capacity</li> <li>Pod status and distribution</li> <li>Network traffic and errors</li> </ul>"},{"location":"advanced/monitoring/#application-monitoring","title":"Application Monitoring","text":"<ul> <li>Application performance metrics</li> <li>Error rates and response times</li> <li>Resource consumption by application</li> <li>Custom application metrics</li> </ul>"},{"location":"advanced/monitoring/#infrastructure-health","title":"Infrastructure Health","text":"<ul> <li>Node resource usage (CPU, memory, disk)</li> <li>Storage utilization and IOPS</li> <li>Network connectivity and latency</li> <li>System-level metrics</li> </ul>"},{"location":"advanced/monitoring/#pipeops-agent","title":"PipeOps Agent","text":"<ul> <li>Agent health and connectivity</li> <li>Control plane communication</li> <li>Monitoring stack health</li> <li>Performance metrics</li> </ul>"},{"location":"advanced/monitoring/#custom-metrics","title":"Custom Metrics","text":""},{"location":"advanced/monitoring/#exposing-application-metrics","title":"Exposing Application Metrics","text":"<p>Add Prometheus metrics to your applications:</p> Go ApplicationPython ApplicationNode.js Application <pre><code>package main\n\nimport (\n    \"github.com/prometheus/client_golang/prometheus\"\n    \"github.com/prometheus/client_golang/prometheus/promhttp\"\n    \"net/http\"\n)\n\nvar (\n    requestsTotal = prometheus.NewCounterVec(\n        prometheus.CounterOpts{\n            Name: \"myapp_requests_total\",\n            Help: \"Total number of requests\",\n        },\n        []string{\"method\", \"status\"},\n    )\n\n    requestDuration = prometheus.NewHistogramVec(\n        prometheus.HistogramOpts{\n            Name: \"myapp_request_duration_seconds\",\n            Help: \"Request duration in seconds\",\n        },\n        []string{\"method\"},\n    )\n)\n\nfunc init() {\n    prometheus.MustRegister(requestsTotal)\n    prometheus.MustRegister(requestDuration)\n}\n\nfunc main() {\n    http.HandleFunc(\"/api/users\", func(w http.ResponseWriter, r *http.Request) {\n        timer := prometheus.NewTimer(requestDuration.WithLabelValues(r.Method))\n        defer timer.ObserveDuration()\n\n        // Your application logic here\n\n        requestsTotal.WithLabelValues(r.Method, \"200\").Inc()\n    })\n\n    // Expose metrics endpoint\n    http.Handle(\"/metrics\", promhttp.Handler())\n    http.ListenAndServe(\":8080\", nil)\n}\n</code></pre> <pre><code>from prometheus_client import Counter, Histogram, start_http_server\nfrom flask import Flask\nimport time\n\napp = Flask(__name__)\n\n# Define metrics\nREQUEST_COUNT = Counter(\n    'myapp_requests_total',\n    'Total number of requests',\n    ['method', 'status']\n)\n\nREQUEST_DURATION = Histogram(\n    'myapp_request_duration_seconds',\n    'Request duration in seconds',\n    ['method']\n)\n\n@app.route('/api/users')\ndef users():\n    start_time = time.time()\n\n    # Your application logic here\n\n    # Record metrics\n    duration = time.time() - start_time\n    REQUEST_DURATION.labels(method='GET').observe(duration)\n    REQUEST_COUNT.labels(method='GET', status='200').inc()\n\n    return {'users': []}\n\nif __name__ == '__main__':\n    # Start metrics server\n    start_http_server(8000)\n    app.run(host='0.0.0.0', port=8080)\n</code></pre> <pre><code>const express = require('express');\nconst prometheus = require('prom-client');\n\nconst app = express();\nconst port = 8080;\n\n// Create metrics\nconst requestsTotal = new prometheus.Counter({\n  name: 'myapp_requests_total',\n  help: 'Total number of requests',\n  labelNames: ['method', 'status']\n});\n\nconst requestDuration = new prometheus.Histogram({\n  name: 'myapp_request_duration_seconds',\n  help: 'Request duration in seconds',\n  labelNames: ['method']\n});\n\n// Register metrics\nprometheus.register.registerMetric(requestsTotal);\nprometheus.register.registerMetric(requestDuration);\n\n// Middleware to track metrics\napp.use((req, res, next) =&gt; {\n  const startTime = Date.now();\n\n  res.on('finish', () =&gt; {\n    const duration = (Date.now() - startTime) / 1000;\n    requestDuration.labels(req.method).observe(duration);\n    requestsTotal.labels(req.method, res.statusCode).inc();\n  });\n\n  next();\n});\n\napp.get('/api/users', (req, res) =&gt; {\n  // Your application logic here\n  res.json({ users: [] });\n});\n\n// Metrics endpoint\napp.get('/metrics', (req, res) =&gt; {\n  res.set('Content-Type', prometheus.register.contentType);\n  res.end(prometheus.register.metrics());\n});\n\napp.listen(port, () =&gt; {\n  console.log(`App listening on port ${port}`);\n});\n</code></pre>"},{"location":"advanced/monitoring/#servicemonitor-configuration","title":"ServiceMonitor Configuration","text":"<p>Configure Prometheus to scrape your application metrics:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: myapp-monitor\n  namespace: pipeops-system\n  labels:\n    app: myapp\nspec:\n  selector:\n    matchLabels:\n      app: myapp\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n    scrapeTimeout: 10s\n</code></pre>"},{"location":"advanced/monitoring/#kubernetes-service","title":"Kubernetes Service","text":"<p>Ensure your application service exposes the metrics port:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\n  labels:\n    app: myapp\nspec:\n  selector:\n    app: myapp\n  ports:\n  - name: http\n    port: 8080\n    targetPort: 8080\n  - name: metrics\n    port: 8000\n    targetPort: 8000\n</code></pre>"},{"location":"advanced/monitoring/#alerting","title":"Alerting","text":""},{"location":"advanced/monitoring/#alert-rules","title":"Alert Rules","text":"<p>Configure custom alert rules for your applications:</p> <pre><code># Custom alert rules\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: myapp-alerts\n  namespace: pipeops-system\nspec:\n  groups:\n  - name: myapp.rules\n    rules:\n    # High error rate\n    - alert: HighErrorRate\n      expr: |\n        sum(rate(myapp_requests_total{status=~\"5..\"}[5m])) /\n        sum(rate(myapp_requests_total[5m])) &gt; 0.05\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"High error rate detected\"\n        description: \"Error rate is {{ $value | humanizePercentage }}\"\n\n    # High response time\n    - alert: HighResponseTime\n      expr: |\n        histogram_quantile(0.95, \n          rate(myapp_request_duration_seconds_bucket[5m])\n        ) &gt; 0.5\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"High response time detected\"\n        description: \"95th percentile response time is {{ $value }}s\"\n\n    # Application down\n    - alert: ApplicationDown\n      expr: up{job=\"myapp\"} == 0\n      for: 1m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Application is down\"\n        description: \"Application {{ $labels.instance }} is down\"\n</code></pre>"},{"location":"advanced/monitoring/#notification-channels","title":"Notification Channels","text":"<p>Configure AlertManager to send notifications:</p> <pre><code># AlertManager configuration\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: alertmanager-config\n  namespace: pipeops-system\ndata:\n  alertmanager.yml: |\n    global:\n      smtp_smarthost: 'localhost:587'\n      smtp_from: 'alerts@pipeops.io'\n\n    route:\n      group_by: ['alertname']\n      group_wait: 30s\n      group_interval: 5m\n      repeat_interval: 12h\n      receiver: 'web.hook'\n      routes:\n      - match:\n          severity: critical\n        receiver: 'critical-alerts'\n      - match:\n          severity: warning\n        receiver: 'warning-alerts'\n\n    receivers:\n    - name: 'web.hook'\n      webhook_configs:\n      - url: 'http://webhook.example.com/alerts'\n\n    - name: 'critical-alerts'\n      email_configs:\n      - to: 'oncall@pipeops.io'\n        subject: 'CRITICAL: {{ .GroupLabels.alertname }}'\n        body: |\n          {{ range .Alerts }}\n          Alert: {{ .Annotations.summary }}\n          Description: {{ .Annotations.description }}\n          {{ end }}\n      slack_configs:\n      - api_url: 'YOUR_SLACK_WEBHOOK_URL'\n        channel: '#alerts'\n        title: 'CRITICAL Alert'\n        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'\n\n    - name: 'warning-alerts'\n      email_configs:\n      - to: 'team@pipeops.io'\n        subject: 'WARNING: {{ .GroupLabels.alertname }}'\n</code></pre>"},{"location":"advanced/monitoring/#custom-dashboards","title":"Custom Dashboards","text":""},{"location":"advanced/monitoring/#creating-custom-grafana-dashboards","title":"Creating Custom Grafana Dashboards","text":"<p>Create dashboards for your specific monitoring needs:</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"My Application Dashboard\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(myapp_requests_total[5m])\",\n            \"legendFormat\": \"{{ method }} {{ status }}\"\n          }\n        ],\n        \"yAxes\": [\n          {\n            \"label\": \"Requests/sec\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Response Time\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(myapp_request_duration_seconds_bucket[5m]))\",\n            \"legendFormat\": \"95th percentile\"\n          },\n          {\n            \"expr\": \"histogram_quantile(0.50, rate(myapp_request_duration_seconds_bucket[5m]))\",\n            \"legendFormat\": \"50th percentile\"\n          }\n        ],\n        \"yAxes\": [\n          {\n            \"label\": \"Seconds\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"advanced/monitoring/#dashboard-configuration","title":"Dashboard Configuration","text":"<p>Add dashboards via ConfigMap:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: custom-dashboards\n  namespace: pipeops-system\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  myapp-dashboard.json: |\n    {\n      \"dashboard\": {\n        // Dashboard JSON here\n      }\n    }\n</code></pre>"},{"location":"advanced/monitoring/#log-management","title":"Log Management","text":""},{"location":"advanced/monitoring/#structured-logging","title":"Structured Logging","text":"<p>Configure applications to output structured logs:</p> JSON FormatGo LogrusPython Structlog <pre><code>{\n  \"timestamp\": \"2023-10-26T15:30:00Z\",\n  \"level\": \"INFO\",\n  \"message\": \"User login successful\",\n  \"user_id\": \"12345\",\n  \"ip_address\": \"192.168.1.100\",\n  \"duration_ms\": 150\n}\n</code></pre> <pre><code>import \"github.com/sirupsen/logrus\"\n\nlog := logrus.New()\nlog.SetFormatter(&amp;logrus.JSONFormatter{})\n\nlog.WithFields(logrus.Fields{\n    \"user_id\": \"12345\",\n    \"ip_address\": \"192.168.1.100\",\n    \"duration_ms\": 150,\n}).Info(\"User login successful\")\n</code></pre> <pre><code>import structlog\n\nlogger = structlog.get_logger()\nlogger.info(\n    \"User login successful\",\n    user_id=\"12345\",\n    ip_address=\"192.168.1.100\",\n    duration_ms=150\n)\n</code></pre>"},{"location":"advanced/monitoring/#log-queries","title":"Log Queries","text":"<p>Use LogQL to query logs in Grafana:</p> <pre><code># All logs for a specific application\n{app=\"myapp\"}\n\n# Error logs only\n{app=\"myapp\"} |= \"ERROR\"\n\n# Logs with specific field\n{app=\"myapp\"} | json | user_id=\"12345\"\n\n# Rate of errors over time\nrate({app=\"myapp\"} |= \"ERROR\" [5m])\n\n# Top error messages\ntopk(10, \n  sum by (message) (\n    rate({app=\"myapp\"} |= \"ERROR\" | json [5m])\n  )\n)\n</code></pre>"},{"location":"advanced/monitoring/#log-based-metrics","title":"Log-based Metrics","text":"<p>Create metrics from log data:</p> <pre><code># Prometheus recording rule from logs\ngroups:\n- name: log-metrics\n  rules:\n  - record: myapp:error_rate\n    expr: |\n      sum(rate({app=\"myapp\"} |= \"ERROR\" [5m])) /\n      sum(rate({app=\"myapp\"} [5m]))\n</code></pre>"},{"location":"advanced/monitoring/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"advanced/monitoring/#high-availability-setup","title":"High Availability Setup","text":"<p>Configure monitoring stack for high availability:</p> <pre><code># Prometheus with multiple replicas\nprometheus:\n  replicas: 2\n  retention: 30d\n  storage:\n    size: 100Gi\n    class: fast-ssd\n  resources:\n    requests:\n      cpu: 500m\n      memory: 1Gi\n    limits:\n      cpu: 2000m\n      memory: 4Gi\n\n# Grafana with persistent storage\ngrafana:\n  replicas: 2\n  persistence:\n    enabled: true\n    size: 20Gi\n  database:\n    type: postgres\n    host: postgres.monitoring.svc.cluster.local\n\n# Loki with S3 storage\nloki:\n  replicas: 3\n  storage:\n    type: s3\n    s3:\n      bucket: loki-logs\n      region: us-west-2\n</code></pre>"},{"location":"advanced/monitoring/#external-data-sources","title":"External Data Sources","text":"<p>Connect to external monitoring systems:</p> <pre><code># External Prometheus\ndatasources:\n- name: External Prometheus\n  type: prometheus\n  url: https://prometheus.external.com\n  access: proxy\n  headers:\n    Authorization: Bearer ${EXTERNAL_TOKEN}\n\n# External Loki\n- name: External Loki\n  type: loki\n  url: https://loki.external.com\n  access: proxy\n</code></pre>"},{"location":"advanced/monitoring/#metric-federation","title":"Metric Federation","text":"<p>Set up Prometheus federation for multi-cluster monitoring:</p> <pre><code># Federation configuration\n- job_name: 'federate'\n  scrape_interval: 15s\n  honor_labels: true\n  metrics_path: '/federate'\n  params:\n    'match[]':\n      - '{job=~\"kubernetes-.*\"}'\n      - '{__name__=~\"job:.*\"}'\n  static_configs:\n    - targets:\n      - 'prometheus-cluster-1:9090'\n      - 'prometheus-cluster-2:9090'\n</code></pre>"},{"location":"advanced/monitoring/#monitoring-best-practices","title":"Monitoring Best Practices","text":""},{"location":"advanced/monitoring/#1-metric-naming-conventions","title":"1. Metric Naming Conventions","text":"<pre><code># Counter metrics (always increasing)\nmyapp_requests_total\nmyapp_errors_total\n\n# Gauge metrics (can go up or down)\nmyapp_active_connections\nmyapp_queue_size\n\n# Histogram metrics (observations)\nmyapp_request_duration_seconds\nmyapp_response_size_bytes\n\n# Summary metrics (quantiles)\nmyapp_request_duration_summary\n</code></pre>"},{"location":"advanced/monitoring/#2-label-best-practices","title":"2. Label Best Practices","text":"<pre><code># Good labels (low cardinality)\nlabels:\n  - method: GET/POST/PUT/DELETE\n  - status: 2xx/4xx/5xx\n  - service: user-service/order-service\n\n# Avoid high cardinality labels\n# Bad examples:\n# - user_id: \"12345\" (thousands of users)\n# - timestamp: \"2023-10-26T15:30:00Z\"\n# - request_id: \"uuid-here\"\n</code></pre>"},{"location":"advanced/monitoring/#3-alert-design","title":"3. Alert Design","text":"<pre><code># Good alert rules\n- alert: HighErrorRate\n  expr: |\n    sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (service) /\n    sum(rate(http_requests_total[5m])) by (service) &gt; 0.05\n  for: 5m\n\n# Include context in annotations\nannotations:\n  summary: \"High error rate for {{ $labels.service }}\"\n  description: |\n    Error rate is {{ $value | humanizePercentage }}\n    Current traffic: {{ with query \"sum(rate(http_requests_total[5m])) by (service)\" }}{{ . | first | value | humanize }}{{ end }} req/s\n</code></pre>"},{"location":"advanced/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced/monitoring/#common-issues","title":"Common Issues","text":"Metrics not appearing in Prometheus <p>Check ServiceMonitor configuration: <pre><code>kubectl get servicemonitor -n pipeops-system\nkubectl describe servicemonitor myapp-monitor -n pipeops-system\n</code></pre></p> <p>Verify service labels match: <pre><code>kubectl get service myapp-service -o yaml\n</code></pre></p> <p>Check Prometheus targets: - Open Prometheus UI: http://localhost:9090 - Go to Status \u2192 Targets - Look for your application in the list</p> Grafana dashboard not loading data <p>Check data source configuration: - Go to Configuration \u2192 Data Sources - Test the Prometheus connection - Verify the URL is correct</p> <p>Check query syntax: - Use Prometheus UI to test queries first - Ensure metric names are correct - Verify label selectors match your data</p> Alerts not firing <p>Verify alert rules: <pre><code>kubectl get prometheusrule -n pipeops-system\n</code></pre></p> <p>Check AlertManager configuration: - Open AlertManager UI: http://localhost:9093 - Verify routing and receivers - Check notification channels</p>"},{"location":"advanced/monitoring/#debug-commands","title":"Debug Commands","text":"<pre><code># Check monitoring stack health\npipeops-agent status --component=monitoring\n\n# View Prometheus configuration\nkubectl get prometheus -n pipeops-system -o yaml\n\n# Check Grafana pods\nkubectl logs -f deployment/grafana -n pipeops-system\n\n# Debug Loki\nkubectl logs -f statefulset/loki -n pipeops-system\n</code></pre> <p>Related Guides: Configuration | Architecture</p>"},{"location":"advanced/tailscale-funnel/","title":"Expose Ingress With Tailscale Funnel","text":"<p>The PipeOps installation provisions an ingress controller inside the cluster. On single-node installs the ingress service is published on the host network at TCP port 80 (HTTP) and 443 (HTTPS). When the node does not have a public IP or inbound firewall rules, you can still share your ingress endpoints securely by using Tailscale and the Tailscale Funnel feature.</p> <p>Tailscale Funnel terminates TLS on the edge and forwards traffic to your node over the Tailscale mesh. This guide walks through publishing port 80 of your PipeOps host so that anyone on the internet can reach your ingress resources without opening traditional firewall ports.</p> <p>Public IP already available?</p> <p>If your VM or bare-metal host has a routable public IP address, the simplest option is to allow inbound TCP 80/443 through your firewall or cloud security group and point DNS records at the instance. Use Tailscale Funnel primarily when you cannot open ports directly or prefer the managed tunnel and <code>*.ts.net</code> endpoints it provides for self-hosted setups.</p>"},{"location":"advanced/tailscale-funnel/#prerequisites","title":"Prerequisites","text":"<ul> <li>The PipeOps agent (or k3s/minikube cluster) is running on a Linux host with ingress-nginx listening on <code>127.0.0.1:80</code> and/or <code>0.0.0.0:80</code>.</li> <li>You can run commands with <code>sudo</code> on the node.</li> <li>A Tailscale account with Funnel enabled for your tailnet. The feature currently requires the tailnet to allow funnel either globally or through ACL tags.</li> <li>Tailscale v1.50 or newer installed on the node. Earlier versions do not support <code>tailscale serve</code>/<code>tailscale funnel</code>.</li> </ul>"},{"location":"advanced/tailscale-funnel/#1-install-tailscale-on-the-node","title":"1. Install Tailscale on the node","text":"<p>If Tailscale is not already installed, run the official install script:</p> <pre><code>curl -fsSL https://tailscale.com/install.sh | sh\n</code></pre> <p>Confirm the version meets the requirement:</p> <pre><code>sudo tailscale version\n</code></pre> <p>Note: For non-Debian-based systems, follow the OS-specific installation instructions before continuing.</p>"},{"location":"advanced/tailscale-funnel/#2-authenticate-the-node-with-your-tailnet","title":"2. Authenticate the node with your tailnet","text":"<p>Log the node into your tailnet and approve it from the Tailscale admin console when prompted:</p> <pre><code>sudo tailscale up --ssh\n</code></pre> <p>Once connected, double-check that the host appears in the Machines list and that its key is authorized.</p>"},{"location":"advanced/tailscale-funnel/#3-grant-the-device-permission-to-run-funnel","title":"3. Grant the device permission to run Funnel","text":"<p>Tailscale only allows Funnel on machines that have the capability explicitly enabled. You have two options:</p> <ol> <li>Per-device toggle: In the admin console, open the machine details and enable Funnel in the Access controls section.</li> <li>ACL tag: Assign a tag (for example <code>tag:funnel</code>) to the node and add an ACL entry that grants the <code>funnel</code> capability to that tag. An example policy snippet:</li> </ol> <pre><code>{\n  \"tagOwners\": { \"tag:funnel\": [\"user:you@example.com\"] },\n  \"nodeAttrs\": [\n    {\n      \"target\": [\"tag:funnel\"],\n      \"attrs\": [\"funnel\"]\n    }\n  ]\n}\n</code></pre> <p>Make sure you save the ACL changes before proceeding.</p>"},{"location":"advanced/tailscale-funnel/#4-publish-ingress-traffic-through-tailscale","title":"4. Publish ingress traffic through Tailscale","text":"<p>First, verify that ingress-nginx is listening locally on port 80:</p> <pre><code>sudo ss -tlnp | grep ':80 '\n</code></pre> <p>Then instruct Tailscale to proxy external connections to the local ingress port:</p> <pre><code># Forward tailnet HTTP traffic to the local ingress endpoint\nsudo tailscale serve tcp 80 127.0.0.1:80\n\n# Allow public internet access to the same service\nsudo tailscale funnel 80 on\n</code></pre> <p>The command above keeps requests encrypted to your node while allowing global HTTPS access via a <code>*.ts.net</code> URL assigned by Tailscale.</p> <p>If your ingress expects a specific <code>Host</code> header, configure an HTTP reverse proxy rule instead:</p> <pre><code>sudo tailscale serve https / https://127.0.0.1 --set-header \"Host: app.pipeops.local\"\nsudo tailscale funnel https on\n</code></pre> <p>Refer to <code>tailscale serve --help</code> for more serving patterns, including HTTP-to-HTTPS redirects and custom certificates.</p>"},{"location":"advanced/tailscale-funnel/#5-verify-external-access","title":"5. Verify external access","text":"<p>Retrieve the public URL and test that it reaches your ingress:</p> <pre><code># Show the active serve/funnel configuration\nsudo tailscale funnel status\n\n# Replace &lt;device&gt; with the machine name shown above\ncurl -I https://&lt;device&gt;.ts.net/\n</code></pre> <p>If your ingress routes based on hostnames, append the appropriate header:</p> <pre><code>curl -I https://&lt;device&gt;.ts.net/ -H 'Host: my-app.example.com'\n</code></pre> <p>You should receive the same response headers as if you queried the ingress locally.</p>"},{"location":"advanced/tailscale-funnel/#6-manage-and-tear-down-funnel-access","title":"6. Manage and tear down Funnel access","text":"<p>When you no longer need public exposure, disable the funnel and remove the serve rule:</p> <pre><code>sudo tailscale funnel 80 off\nsudo tailscale serve reset\n</code></pre> <p>The node will stay connected to your tailnet for private administration, but inbound traffic from the public internet stops immediately.</p>"},{"location":"advanced/tailscale-funnel/#troubleshooting","title":"Troubleshooting","text":"<ul> <li><code>tailscale funnel</code> returns <code>permission denied</code>: confirm the node has the <code>funnel</code> capability through the admin console or ACL tags, and re-run <code>sudo tailscale up</code> after ACL changes.</li> <li>Requests hang or return 502: ensure ingress-nginx is listening on the specified port. On k3s-based installs you can restart ingress with <code>kubectl rollout restart deployment ingress-nginx-controller -n ingress-nginx</code>.</li> <li>Need HTTPS passthrough: you can forward port 443 the same way, or terminate TLS inside the cluster by pointing <code>tailscale serve</code> at <code>https://127.0.0.1:443</code>.</li> <li>Keep logs for audits: Tailscale exposes serve/funnel logs via <code>sudo journalctl -u tailscaled</code>.</li> </ul> <p>That is all that is required to publish your PipeOps ingress endpoints without changing your network perimeter. Disconnect the funnel when you no longer need outside access.</p>"},{"location":"advanced/talos/","title":"Talos Integration","text":"<p>Talos Linux is an immutable operating system that delivers a hardened, Kubernetes-first experience. The PipeOps agent can work alongside Talos in two primary scenarios:</p> <ol> <li>Docker-based Talos clusters for local testing \u2013 quick to spin up with <code>talosctl cluster create</code>.</li> <li>Production Talos installations \u2013 bare-metal or cloud images booted directly into Talos.</li> </ol> <p>This guide explains how the agent\u2019s installer interacts with Talos, the prerequisites you need, and the recommended workflows for both development and production.</p>"},{"location":"advanced/talos/#before-you-start","title":"Before You Start","text":"<ul> <li>Install <code>talosctl</code> (see talos.dev). The PipeOps installer can download it automatically when using the Docker-based flow.</li> <li>Ensure Docker is available if you plan to use the lightweight Talos-in-Docker option. For bare-metal Talos, follow the official Talos installation steps to provision nodes first.</li> <li>Keep your PipeOps agent token handy; you will need it regardless of the cluster type.</li> </ul>"},{"location":"advanced/talos/#using-the-pipeops-installer-with-talos-docker-mode","title":"Using the PipeOps Installer with Talos (Docker Mode)","text":"<p>The installer can create a disposable Talos cluster inside Docker for demonstrations or local development. This is not intended for production workloads.</p> <pre><code>export PIPEOPS_TOKEN=\"your-token\"\nexport CLUSTER_NAME=\"talos-demo\"\nexport CLUSTER_TYPE=\"talos\"\nexport TALOS_USE_DOCKER=\"true\"\n\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre> <p>What the installer does in this mode:</p> <ul> <li>Downloads or verifies <code>talosctl</code>.</li> <li>Creates a Talos control plane and worker nodes inside Docker.</li> <li>Generates kubeconfig and configures <code>kubectl</code> access.</li> <li>Deploys the PipeOps agent and monitoring stack to the Talos Kubernetes API.</li> </ul>"},{"location":"advanced/talos/#limitations","title":"Limitations","text":"<ul> <li>Docker-based Talos clusters are ephemeral and resource-limited. They are perfect for workshops or quick validation but should not be exposed to real workloads.</li> <li>The Docker backend listens on localhost; remote access must go through <code>kubectl port-forward</code> or SSH tunnelling.</li> </ul>"},{"location":"advanced/talos/#bringing-your-own-talos-cluster-production","title":"Bringing Your Own Talos Cluster (Production)","text":"<p>For production deployments you should provision Talos nodes following the official documentation\u2014either by booting cloud images or installing from ISO on bare metal. Once you have a functional Talos control plane:</p> <ol> <li>Obtain cluster credentials</li> <li>Use <code>talosctl kubeconfig --nodes &lt;control-plane-ip&gt;</code> to generate a kubeconfig.</li> <li> <p>Point <code>KUBECONFIG</code> to the generated file so <code>kubectl</code> communicates with the Talos cluster.</p> </li> <li> <p>Install the PipeOps agent</p> </li> </ol> <p>Choose either the Helm chart or direct manifest deployment:</p> <p>=== \"Helm\"</p> <pre><code>```bash\nhelm upgrade --install pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --namespace pipeops-system \\\n  --create-namespace \\\n  --set agent.pipeops.token=\"your-pipeops-token\" \\\n  --set agent.cluster.name=\"production-talos\"\n```\n</code></pre> <p>=== \"Manifest\"</p> <pre><code>```bash\ncurl -fsSL https://get.pipeops.dev/k8-agent.yaml \\\n  | PIPEOPS_TOKEN=\"your-pipeops-token\" \\\n    PIPEOPS_CLUSTER_NAME=\"production-talos\" \\\n    envsubst \\\n  | kubectl apply -f -\n```\n</code></pre> <ol> <li>Verify agent registration</li> <li><code>kubectl get pods -n pipeops-system</code> should show the agent and monitoring components.</li> <li>The PipeOps dashboard should list the Talos-backed server within a few minutes.</li> </ol>"},{"location":"advanced/talos/#why-the-install-script-warns-on-talos","title":"Why the install script warns on Talos","text":"<p>The intelligent installer cannot install Talos on top of an existing OS; it can only drive the Docker-based variant. When it detects a Talos-friendly environment it will suggest Talos but still fall back to k3s if prerequisites are missing. The warning message is a reminder that production Talos nodes must be provisioned outside the script.</p>"},{"location":"advanced/talos/#troubleshooting","title":"Troubleshooting","text":"Symptom Resolution <code>talosctl: command not found</code> Install <code>talosctl</code> or let the installer run with sufficient privileges to place it in <code>/usr/local/bin</code>. Docker mode fails with networking errors Ensure Docker is running and <code>talosctl cluster destroy &lt;name&gt;</code> any previous clusters before retrying. Agent pods crash on Talos Confirm the agent chart version is up to date and that Talos cluster nodes allow the required container images (<code>ghcr.io/pipeopshq/...</code>). Installer suggests Talos but exits Export <code>CLUSTER_TYPE=k3s</code> for traditional k3s installs, or follow the production Talos instructions above. <p>For additional help deploying Talos itself, consult the official Talos documentation. For PipeOps agent issues, open a ticket via the PipeOps support portal or GitHub.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Welcome to the PipeOps Kubernetes Agent project! We're excited that you want to contribute. This guide will help you get started with contributing to the project.</p>"},{"location":"development/contributing/#quick-start","title":"Quick Start","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork locally</li> <li>Set up the development environment</li> <li>Make your changes</li> <li>Test your changes</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Go 1.21+ - Install Go</li> <li>Docker 20.0+ - Install Docker</li> <li>kubectl - Install kubectl</li> <li>Kind or Minikube - For local Kubernetes clusters</li> <li>Make - For build automation</li> <li>Git - For version control</li> </ul>"},{"location":"development/contributing/#development-environment-setup","title":"Development Environment Setup","text":""},{"location":"development/contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork the repository on GitHub, then clone your fork\ngit clone https://github.com/YOUR-USERNAME/pipeops-k8-agent.git\ncd pipeops-k8-agent\n\n# Add upstream remote\ngit remote add upstream https://github.com/PipeOpsHQ/pipeops-k8-agent.git\n</code></pre>"},{"location":"development/contributing/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code># Install Go dependencies\ngo mod download\n\n# Install development tools\nmake install-tools\n\n# Verify installation\nmake verify\n</code></pre>"},{"location":"development/contributing/#3-set-up-local-kubernetes-cluster","title":"3. Set Up Local Kubernetes Cluster","text":"Kind (Recommended)Minikube <pre><code># Create a local cluster with Kind\nkind create cluster --config=deployments/kind-config.yaml\n\n# Verify cluster is running\nkubectl cluster-info\n</code></pre> <pre><code># Start Minikube cluster\nminikube start --driver=docker\n\n# Enable required addons\nminikube addons enable ingress\nminikube addons enable metrics-server\n</code></pre>"},{"location":"development/contributing/#4-run-local-development","title":"4. Run Local Development","text":"<pre><code># Build the agent\nmake build\n\n# Run in development mode\nmake dev\n\n# Or run with custom configuration\n./bin/pipeops-agent start --config=config-local.yaml --dev-mode\n</code></pre>"},{"location":"development/contributing/#project-structure","title":"Project Structure","text":"<p>Understanding the project layout will help you navigate and contribute effectively:</p> <pre><code>pipeops-k8-agent/\n\u251c\u2500\u2500 cmd/                    # Application entry points\n\u2502   \u2514\u2500\u2500 agent/\n\u2502       \u2514\u2500\u2500 main.go        # Main agent binary\n\u251c\u2500\u2500 internal/              # Private application code\n\u2502   \u251c\u2500\u2500 agent/             # Core agent logic\n\u2502   \u251c\u2500\u2500 controlplane/      # Control plane communication\n\u2502   \u251c\u2500\u2500 monitoring/        # Monitoring stack management\n\u2502   \u251c\u2500\u2500 server/            # HTTP/WebSocket server\n\u2502   \u2514\u2500\u2500 tunnel/            # Secure tunnel implementation\n\u251c\u2500\u2500 pkg/                   # Public libraries\n\u2502   \u251c\u2500\u2500 k8s/              # Kubernetes utilities\n\u2502   \u251c\u2500\u2500 state/            # State management\n\u2502   \u2514\u2500\u2500 types/            # Common types\n\u251c\u2500\u2500 deployments/           # Kubernetes manifests\n\u251c\u2500\u2500 docs/                  # Documentation\n\u251c\u2500\u2500 helm/                  # Helm charts\n\u251c\u2500\u2500 scripts/              # Build and utility scripts\n\u251c\u2500\u2500 Dockerfile            # Container build file\n\u251c\u2500\u2500 Makefile             # Build automation\n\u2514\u2500\u2500 go.mod               # Go module definition\n</code></pre>"},{"location":"development/contributing/#building-and-testing","title":"Building and Testing","text":""},{"location":"development/contributing/#building","title":"Building","text":"<pre><code># Build for current platform\nmake build\n\n# Build for all platforms\nmake build-all\n\n# Build Docker image\nmake docker-build\n\n# Build with custom version\nmake build VERSION=v2.1.0-dev\n</code></pre>"},{"location":"development/contributing/#testing","title":"Testing","text":"<pre><code># Run all tests\nmake test\n\n# Run unit tests only\nmake test-unit\n\n# Run integration tests\nmake test-integration\n\n# Run tests with coverage\nmake test-coverage\n\n# Run specific test\ngo test -v ./internal/agent/...\n</code></pre>"},{"location":"development/contributing/#code-quality","title":"Code Quality","text":"<pre><code># Run linters\nmake lint\n\n# Format code\nmake fmt\n\n# Check for security issues\nmake security-check\n\n# Generate mocks (if needed)\nmake generate\n</code></pre>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#1-creating-a-feature-branch","title":"1. Creating a Feature Branch","text":"<pre><code># Update your fork\ngit fetch upstream\ngit checkout main\ngit merge upstream/main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n\n# Or for bug fixes\ngit checkout -b fix/issue-description\n</code></pre>"},{"location":"development/contributing/#2-making-changes","title":"2. Making Changes","text":"<p>Follow these guidelines when making changes:</p>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<ul> <li>Follow Go Code Review Comments</li> <li>Use <code>gofmt</code> for formatting</li> <li>Add comments for public functions and complex logic</li> <li>Keep functions small and focused</li> </ul>"},{"location":"development/contributing/#commit-messages","title":"Commit Messages","text":"<p>Use conventional commit format:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n\n&lt;body&gt;\n\n&lt;footer&gt;\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes (formatting, etc.) - <code>refactor</code>: Code refactoring - <code>test</code>: Adding or updating tests - <code>chore</code>: Maintenance tasks</p> <p>Examples: <pre><code>git commit -m \"feat(monitoring): add custom metrics support\"\ngit commit -m \"fix(agent): resolve connection timeout issue\"\ngit commit -m \"docs: update installation guide\"\n</code></pre></p>"},{"location":"development/contributing/#3-testing-your-changes","title":"3. Testing Your Changes","text":"<p>Before submitting, ensure your changes work correctly:</p> <pre><code># Test locally\nmake test\nmake lint\n\n# Test with local cluster\nmake deploy-local\nkubectl get pods -n pipeops-system\n\n# Manual testing\n./bin/pipeops-agent start --dev-mode --log-level=debug\n</code></pre>"},{"location":"development/contributing/#4-submitting-pull-request","title":"4. Submitting Pull Request","text":"<pre><code># Push your changes\ngit push origin feature/your-feature-name\n\n# Create pull request on GitHub\n# Fill out the PR template completely\n</code></pre>"},{"location":"development/contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"development/contributing/#unit-tests","title":"Unit Tests","text":"<p>Write unit tests for all new functionality:</p> <pre><code>// Example unit test\nfunc TestAgent_Start(t *testing.T) {\n    tests := []struct {\n        name    string\n        config  *Config\n        wantErr bool\n    }{\n        {\n            name: \"valid configuration\",\n            config: &amp;Config{\n                Token: \"test-token\",\n                Endpoint: \"https://api.pipeops.io\",\n            },\n            wantErr: false,\n        },\n        {\n            name: \"missing token\",\n            config: &amp;Config{\n                Endpoint: \"https://api.pipeops.io\",\n            },\n            wantErr: true,\n        },\n    }\n\n    for _, tt := range tests {\n        t.Run(tt.name, func(t *testing.T) {\n            agent := NewAgent(tt.config)\n            err := agent.Start()\n            if (err != nil) != tt.wantErr {\n                t.Errorf(\"Agent.Start() error = %v, wantErr %v\", err, tt.wantErr)\n            }\n        })\n    }\n}\n</code></pre>"},{"location":"development/contributing/#integration-tests","title":"Integration Tests","text":"<p>Integration tests verify component interactions:</p> <pre><code>func TestAgent_Integration(t *testing.T) {\n    // Set up test cluster\n    cluster := setupTestCluster(t)\n    defer cluster.Teardown()\n\n    // Create agent with test configuration\n    config := &amp;Config{\n        Token: \"test-token\",\n        Endpoint: cluster.ControlPlaneURL(),\n    }\n    agent := NewAgent(config)\n\n    // Test agent lifecycle\n    err := agent.Start()\n    require.NoError(t, err)\n\n    // Verify agent is running\n    status := agent.Status()\n    assert.Equal(t, StatusRunning, status.State)\n\n    // Clean up\n    err = agent.Stop()\n    require.NoError(t, err)\n}\n</code></pre>"},{"location":"development/contributing/#end-to-end-tests","title":"End-to-End Tests","text":"<p>E2E tests verify complete user workflows:</p> <pre><code># Run E2E tests\nmake test-e2e\n\n# Run specific E2E test\ngo test -v ./test/e2e -run TestInstallAndDeploy\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#code-documentation","title":"Code Documentation","text":"<ul> <li>Document all public functions and types</li> <li>Use godoc format for documentation comments</li> <li>Include examples in documentation</li> </ul> <pre><code>// Agent represents the PipeOps Kubernetes Agent.\n// It manages the connection to the control plane and orchestrates\n// monitoring and deployment operations within the cluster.\n//\n// Example:\n//   config := &amp;Config{Token: \"token\", Endpoint: \"https://api.pipeops.io\"}\n//   agent := NewAgent(config)\n//   if err := agent.Start(); err != nil {\n//       log.Fatal(err)\n//   }\ntype Agent struct {\n    config *Config\n    // ... other fields\n}\n</code></pre>"},{"location":"development/contributing/#user-documentation","title":"User Documentation","text":"<p>When adding new features, update the relevant documentation:</p> <ul> <li>Update command documentation in <code>docs/commands/</code></li> <li>Add configuration examples to <code>docs/getting-started/configuration.md</code></li> <li>Update the main README if needed</li> </ul>"},{"location":"development/contributing/#security-considerations","title":"Security Considerations","text":""},{"location":"development/contributing/#secure-coding-practices","title":"Secure Coding Practices","text":"<ul> <li>Validate all user inputs</li> <li>Use secure defaults</li> <li>Handle secrets properly (never log them)</li> <li>Follow principle of least privilege</li> </ul>"},{"location":"development/contributing/#security-testing","title":"Security Testing","text":"<pre><code># Run security scans\nmake security-check\n\n# Check for vulnerabilities in dependencies\ngo list -json -m all | nancy sleuth\n\n# Static analysis\ngosec ./...\n</code></pre>"},{"location":"development/contributing/#handling-sensitive-data","title":"Handling Sensitive Data","text":"<pre><code>// Good: Use types that prevent accidental logging\ntype Token struct {\n    value string\n}\n\nfunc (t Token) String() string {\n    return \"[REDACTED]\"\n}\n\n// Good: Clear sensitive data from memory\nfunc clearToken(token []byte) {\n    for i := range token {\n        token[i] = 0\n    }\n}\n</code></pre>"},{"location":"development/contributing/#debugging","title":"Debugging","text":""},{"location":"development/contributing/#debug-mode","title":"Debug Mode","text":"<p>Run the agent in debug mode for detailed logging:</p> <pre><code># Enable debug logging\n./bin/pipeops-agent start --log-level=debug --dev-mode\n\n# With additional tracing\nPIPEOPS_TRACE=true ./bin/pipeops-agent start --dev-mode\n</code></pre>"},{"location":"development/contributing/#using-delve-debugger","title":"Using Delve Debugger","text":"<pre><code># Install Delve\ngo install github.com/go-delve/delve/cmd/dlv@latest\n\n# Debug the agent\ndlv debug ./cmd/agent -- start --dev-mode\n\n# Set breakpoints and inspect variables\n(dlv) break main.main\n(dlv) continue\n</code></pre>"},{"location":"development/contributing/#profiling","title":"Profiling","text":"<pre><code># Enable profiling\n./bin/pipeops-agent start --pprof-addr=localhost:6060\n\n# View CPU profile\ngo tool pprof http://localhost:6060/debug/pprof/profile\n\n# View memory profile\ngo tool pprof http://localhost:6060/debug/pprof/heap\n</code></pre>"},{"location":"development/contributing/#release-process","title":"Release Process","text":""},{"location":"development/contributing/#versioning","title":"Versioning","text":"<p>We follow Semantic Versioning:</p> <ul> <li>MAJOR version for incompatible API changes</li> <li>MINOR version for backwards-compatible functionality</li> <li>PATCH version for backwards-compatible bug fixes</li> </ul>"},{"location":"development/contributing/#creating-a-release","title":"Creating a Release","text":"<ol> <li>Update version in relevant files</li> <li>Update CHANGELOG.md with release notes  </li> <li>Create release PR with version bump</li> <li>Tag release after PR merge</li> <li>GitHub Actions will build and publish automatically</li> </ol> <pre><code># Create release tag\ngit tag -a v2.1.0 -m \"Release v2.1.0\"\ngit push upstream v2.1.0\n</code></pre>"},{"location":"development/contributing/#community-guidelines","title":"Community Guidelines","text":""},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>We follow the Contributor Covenant Code of Conduct. Please read and follow it in all interactions.</p>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues: For bugs and feature requests</li> <li>GitHub Discussions: For questions and general discussion</li> <li>Discord: Join our community Discord</li> </ul>"},{"location":"development/contributing/#communication","title":"Communication","text":"<ul> <li>Be respectful and inclusive</li> <li>Provide constructive feedback</li> <li>Ask questions when unclear</li> <li>Share knowledge and help others</li> </ul>"},{"location":"development/contributing/#pull-request-checklist","title":"Pull Request Checklist","text":"<p>Before submitting your PR, ensure:</p> <ul> <li> Code follows project style guidelines</li> <li> All tests pass (<code>make test</code>)</li> <li> Linter passes (<code>make lint</code>)</li> <li> Documentation is updated if needed</li> <li> Commit messages follow conventional format</li> <li> PR description explains the changes</li> <li> Related issues are linked</li> <li> Breaking changes are documented</li> </ul>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>We appreciate all contributions! Contributors will be:</p> <ul> <li>Listed in the project's AUTHORS file</li> <li>Mentioned in release notes for significant contributions</li> <li>Eligible for PipeOps swag and recognition</li> <li>Invited to join our contributor Discord channel</li> </ul>"},{"location":"development/contributing/#getting-started-with-your-first-contribution","title":"Getting Started with Your First Contribution","text":""},{"location":"development/contributing/#good-first-issues","title":"Good First Issues","text":"<p>Look for issues labeled with: - <code>good first issue</code> - Beginner-friendly issues - <code>help wanted</code> - Issues where we need community help - <code>documentation</code> - Documentation improvements</p>"},{"location":"development/contributing/#areas-for-contribution","title":"Areas for Contribution","text":"<ul> <li>Bug fixes - Help resolve reported issues</li> <li>Feature development - Implement new capabilities</li> <li>Documentation - Improve guides and references</li> <li>Testing - Add test coverage and E2E tests</li> <li>Performance - Optimize resource usage</li> <li>Security - Enhance security measures</li> </ul>"},{"location":"development/contributing/#contact","title":"Contact","text":"<p>For questions about contributing:</p> <ul> <li>Maintainers: Contact via GitHub issues or email</li> <li>Email: contributors@pipeops.io</li> <li>Discord: PipeOps Community</li> </ul> <p>Thank you for contributing to PipeOps Kubernetes Agent!</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Learn how to configure the PipeOps Kubernetes Agent for your specific environment and requirements. This guide covers all configuration options and best practices.</p>"},{"location":"getting-started/configuration/#configuration-overview","title":"\ud83d\udccb Configuration Overview","text":"<p>The PipeOps Agent can be configured through multiple methods:</p> <ul> <li>Environment variables - For runtime configuration</li> <li>Configuration files - For persistent settings  </li> <li>Helm values - For Kubernetes deployments</li> <li>Command-line flags - For one-time overrides</li> </ul>"},{"location":"getting-started/configuration/#configuration-methods","title":"\ud83d\udd27 Configuration Methods","text":"Configuration FileEnvironment VariablesHelm ValuesCommand Line <p>Primary method - Create <code>/etc/pipeops/config.yaml</code>:</p> <pre><code># Complete configuration example\ncluster:\n  name: \"production-cluster\"\n  region: \"us-west-2\"\n  environment: \"production\"\n  tags:\n    team: \"platform\"\n    cost-center: \"engineering\"\n\nagent:\n  token: \"${PIPEOPS_TOKEN}\"\n  endpoint: \"https://api.pipeops.io\"\n  log_level: \"info\"\n  heartbeat_interval: \"30s\"\n  max_retries: 3\n  timeout: \"60s\"\n\nmonitoring:\n  enabled: true\n  namespace: \"pipeops-system\"\n  retention_days: 30\n  prometheus:\n    enabled: true\n    port: 9090\n    scrape_interval: \"15s\"\n  grafana:\n    enabled: true\n    port: 3000\n    admin_password: \"${GRAFANA_ADMIN_PASSWORD}\"\n  loki:\n    enabled: true\n    port: 3100\n    retention_period: \"30d\"\n\nresources:\n  requests:\n    cpu: \"250m\"\n    memory: \"256Mi\"\n  limits:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n\nsecurity:\n  tls:\n    enabled: true\n    cert_file: \"/etc/ssl/certs/pipeops.crt\"\n    key_file: \"/etc/ssl/private/pipeops.key\"\n  rbac:\n    enabled: true\n    service_account: \"pipeops-agent\"\n\nnetworking:\n  tunnel:\n    enabled: true\n    port: 8443\n    keepalive: \"30s\"\n  proxy:\n    http_proxy: \"${HTTP_PROXY}\"\n    https_proxy: \"${HTTPS_PROXY}\"\n    no_proxy: \"${NO_PROXY}\"\n</code></pre> <p>Quick configuration - Set environment variables:</p> <pre><code># Core configuration\nexport PIPEOPS_TOKEN=\"your-cluster-token\"\nexport PIPEOPS_CLUSTER_NAME=\"production-cluster\"\nexport PIPEOPS_LOG_LEVEL=\"info\"\nexport PIPEOPS_ENDPOINT=\"https://api.pipeops.io\"\n\n# Monitoring configuration\nexport PIPEOPS_MONITORING_ENABLED=\"true\"\nexport PIPEOPS_PROMETHEUS_ENABLED=\"true\"\nexport PIPEOPS_GRAFANA_ENABLED=\"true\"\n\n# Resource limits\nexport PIPEOPS_CPU_LIMIT=\"500m\"\nexport PIPEOPS_MEMORY_LIMIT=\"512Mi\"\n\n# Security settings\nexport PIPEOPS_TLS_ENABLED=\"true\"\nexport PIPEOPS_RBAC_ENABLED=\"true\"\n</code></pre> <p>Kubernetes deployments - Create <code>values.yaml</code>:</p> <pre><code># Helm chart values\nagent:\n  image:\n    repository: pipeops/agent\n    tag: \"latest\"\n    pullPolicy: IfNotPresent\n\n  cluster:\n    name: \"production-cluster\"\n    region: \"us-west-2\"\n    environment: \"production\"\n\n  token: \"your-cluster-token\"\n  logLevel: \"info\"\n\n  resources:\n    requests:\n      cpu: 250m\n      memory: 256Mi\n    limits:\n      cpu: 500m\n      memory: 512Mi\n\nmonitoring:\n  enabled: true\n  namespace: pipeops-system\n\n  prometheus:\n    enabled: true\n    retention: \"30d\"\n    resources:\n      requests:\n        cpu: 100m\n        memory: 128Mi\n\n  grafana:\n    enabled: true\n    adminPassword: \"secure-password\"\n    persistence:\n      enabled: true\n      size: 10Gi\n\n  loki:\n    enabled: true\n    persistence:\n      enabled: true\n      size: 50Gi\n\nsecurity:\n  serviceAccount:\n    create: true\n    name: pipeops-agent\n\n  rbac:\n    create: true\n\n  tls:\n    enabled: true\n    secretName: pipeops-tls\n\nnetworking:\n  tunnel:\n    enabled: true\n    port: 8443\n\n  service:\n    type: ClusterIP\n    port: 8080\n</code></pre> <p>Override configuration - Use CLI flags:</p> <pre><code># Start with custom configuration\npipeops-agent start \\\n  --cluster-name=\"test-cluster\" \\\n  --log-level=\"debug\" \\\n  --endpoint=\"https://staging.pipeops.io\" \\\n  --monitoring-enabled=false\n\n# Deploy with specific settings\npipeops-agent deploy \\\n  --namespace=\"custom-namespace\" \\\n  --replicas=3 \\\n  --cpu-limit=\"1000m\" \\\n  --memory-limit=\"1Gi\"\n</code></pre>"},{"location":"getting-started/configuration/#configuration-sections","title":"\u2699\ufe0f Configuration Sections","text":""},{"location":"getting-started/configuration/#cluster-configuration","title":"Cluster Configuration","text":"<p>Configure cluster identification and metadata:</p> <pre><code>cluster:\n  name: \"production-cluster\"        # Required: Unique cluster identifier\n  region: \"us-west-2\"              # Optional: AWS/GCP/Azure region\n  environment: \"production\"        # Optional: Environment label\n  provider: \"aws\"                  # Optional: Cloud provider\n  version: \"1.25\"                  # Optional: Kubernetes version\n  tags:                           # Optional: Custom labels\n    team: \"platform\"\n    cost-center: \"engineering\"\n    project: \"main-app\"\n</code></pre>"},{"location":"getting-started/configuration/#agent-configuration","title":"Agent Configuration","text":"<p>Core agent behavior settings:</p> <pre><code>agent:\n  token: \"${PIPEOPS_TOKEN}\"        # Required: Cluster authentication token\n  endpoint: \"https://api.pipeops.io\"  # Control plane endpoint\n  log_level: \"info\"                # Logging level: debug, info, warn, error\n  heartbeat_interval: \"30s\"        # Health check frequency\n  max_retries: 3                   # Connection retry attempts\n  timeout: \"60s\"                   # Request timeout\n  user_agent: \"PipeOps-Agent/2.1.0\"  # Custom user agent\n\n  # Advanced settings\n  buffer_size: 1024               # Message buffer size\n  worker_count: 5                 # Concurrent workers\n  batch_size: 100                 # Batch processing size\n</code></pre>"},{"location":"getting-started/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":"<p>Comprehensive monitoring stack setup:</p> <pre><code>monitoring:\n  enabled: true                    # Enable monitoring stack\n  namespace: \"pipeops-system\"      # Kubernetes namespace\n  retention_days: 30              # Data retention period\n\n  prometheus:\n    enabled: true\n    port: 9090\n    scrape_interval: \"15s\"        # Metrics collection frequency\n    evaluation_interval: \"15s\"    # Rule evaluation frequency\n    retention: \"30d\"              # Metric retention period\n    storage_size: \"50Gi\"          # Storage allocation\n\n    # External labels for federation\n    external_labels:\n      cluster: \"production\"\n      region: \"us-west-2\"\n\n    # Additional scrape configs\n    additional_scrape_configs: |\n      - job_name: 'custom-app'\n        static_configs:\n          - targets: ['app:8080']\n\n  grafana:\n    enabled: true\n    port: 3000\n    admin_password: \"${GRAFANA_ADMIN_PASSWORD}\"\n\n    # Persistence\n    persistence:\n      enabled: true\n      size: \"10Gi\"\n      storage_class: \"fast-ssd\"\n\n    # Additional dashboards\n    dashboards:\n      default:\n        kubernetes-overview:\n          url: https://grafana.com/api/dashboards/7249/revisions/1/download\n\n    # Data sources\n    datasources:\n      prometheus:\n        url: \"http://prometheus:9090\"\n        access: proxy\n\n  loki:\n    enabled: true\n    port: 3100\n    retention_period: \"30d\"\n\n    # Storage configuration\n    storage:\n      type: \"filesystem\"           # filesystem, s3, gcs\n      filesystem:\n        directory: \"/loki/chunks\"\n\n    # Log ingestion limits\n    limits:\n      ingestion_rate_mb: 10\n      ingestion_burst_size_mb: 20\n</code></pre>"},{"location":"getting-started/configuration/#security-configuration","title":"Security Configuration","text":"<p>Security and access control settings:</p> <pre><code>security:\n  # TLS Configuration\n  tls:\n    enabled: true\n    cert_file: \"/etc/ssl/certs/pipeops.crt\"\n    key_file: \"/etc/ssl/private/pipeops.key\"\n    ca_file: \"/etc/ssl/certs/ca.crt\"\n    verify_client: true\n    min_version: \"1.2\"            # Minimum TLS version\n\n  # RBAC Configuration\n  rbac:\n    enabled: true\n    service_account: \"pipeops-agent\"\n    cluster_role: \"pipeops-agent\"\n\n    # Custom permissions\n    rules:\n      - apiGroups: [\"\"]\n        resources: [\"pods\", \"services\", \"configmaps\"]\n        verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\"]\n      - apiGroups: [\"apps\"]\n        resources: [\"deployments\", \"replicasets\"]\n        verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"delete\"]\n\n  # Network policies\n  network_policy:\n    enabled: true\n    ingress:\n      - from:\n          - namespaceSelector:\n              matchLabels:\n                name: pipeops-system\n    egress:\n      - to: []  # Allow all outbound traffic\n\n  # Pod security\n  pod_security:\n    security_context:\n      run_as_non_root: true\n      run_as_user: 1000\n      fs_group: 2000\n\n    seccomp_profile:\n      type: RuntimeDefault\n</code></pre>"},{"location":"getting-started/configuration/#networking-configuration","title":"Networking Configuration","text":"<p>Network and connectivity settings:</p> <pre><code>networking:\n  # Secure tunnel configuration\n  tunnel:\n    enabled: true\n    port: 8443\n    keepalive: \"30s\"\n    compression: true\n\n    # Connection settings\n    dial_timeout: \"10s\"\n    idle_timeout: \"300s\"\n    max_idle_conns: 100\n\n  # Proxy configuration\n  proxy:\n    http_proxy: \"${HTTP_PROXY}\"\n    https_proxy: \"${HTTPS_PROXY}\"\n    no_proxy: \"${NO_PROXY}\"\n\n  # DNS configuration\n  dns:\n    nameservers:\n      - \"8.8.8.8\"\n      - \"8.8.4.4\"\n    search_domains:\n      - \"cluster.local\"\n      - \"svc.cluster.local\"\n\n  # Service mesh integration\n  service_mesh:\n    enabled: false\n    type: \"istio\"                 # istio, linkerd, consul\n    mtls_mode: \"strict\"\n</code></pre>"},{"location":"getting-started/configuration/#resource-configuration","title":"Resource Configuration","text":"<p>Resource limits and requests:</p> <pre><code>resources:\n  # Agent resources\n  requests:\n    cpu: \"250m\"\n    memory: \"256Mi\"\n    ephemeral-storage: \"1Gi\"\n  limits:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n    ephemeral-storage: \"2Gi\"\n\n  # Monitoring stack resources\n  monitoring:\n    prometheus:\n      requests:\n        cpu: \"100m\"\n        memory: \"128Mi\"\n      limits:\n        cpu: \"500m\"\n        memory: \"1Gi\"\n\n    grafana:\n      requests:\n        cpu: \"50m\"\n        memory: \"64Mi\"\n      limits:\n        cpu: \"200m\"\n        memory: \"256Mi\"\n\n    loki:\n      requests:\n        cpu: \"50m\"\n        memory: \"128Mi\"\n      limits:\n        cpu: \"200m\"\n        memory: \"512Mi\"\n</code></pre>"},{"location":"getting-started/configuration/#environment-specific-configurations","title":"\ud83c\udfaf Environment-Specific Configurations","text":""},{"location":"getting-started/configuration/#development-environment","title":"Development Environment","text":"<pre><code># dev-config.yaml\ncluster:\n  name: \"dev-cluster\"\n  environment: \"development\"\n\nagent:\n  log_level: \"debug\"\n  heartbeat_interval: \"10s\"\n\nmonitoring:\n  enabled: true\n  retention_days: 7\n\nresources:\n  requests:\n    cpu: \"100m\"\n    memory: \"128Mi\"\n  limits:\n    cpu: \"250m\"\n    memory: \"256Mi\"\n</code></pre>"},{"location":"getting-started/configuration/#staging-environment","title":"Staging Environment","text":"<pre><code># staging-config.yaml\ncluster:\n  name: \"staging-cluster\"\n  environment: \"staging\"\n\nagent:\n  log_level: \"info\"\n  heartbeat_interval: \"30s\"\n\nmonitoring:\n  enabled: true\n  retention_days: 14\n\nresources:\n  requests:\n    cpu: \"250m\"\n    memory: \"256Mi\"\n  limits:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n</code></pre>"},{"location":"getting-started/configuration/#production-environment","title":"Production Environment","text":"<pre><code># production-config.yaml\ncluster:\n  name: \"production-cluster\"\n  environment: \"production\"\n\nagent:\n  log_level: \"warn\"\n  heartbeat_interval: \"30s\"\n  max_retries: 5\n\nmonitoring:\n  enabled: true\n  retention_days: 90\n\nsecurity:\n  tls:\n    enabled: true\n  rbac:\n    enabled: true\n\nresources:\n  requests:\n    cpu: \"500m\"\n    memory: \"512Mi\"\n  limits:\n    cpu: \"1000m\"\n    memory: \"1Gi\"\n</code></pre>"},{"location":"getting-started/configuration/#secret-management","title":"\ud83d\udd10 Secret Management","text":""},{"location":"getting-started/configuration/#using-kubernetes-secrets","title":"Using Kubernetes Secrets","text":"<p>Create secrets for sensitive configuration:</p> <pre><code># Create secret for agent token\nkubectl create secret generic pipeops-token \\\n  --from-literal=token=\"your-cluster-token\" \\\n  -n pipeops-system\n\n# Create TLS secret\nkubectl create secret tls pipeops-tls \\\n  --cert=path/to/tls.crt \\\n  --key=path/to/tls.key \\\n  -n pipeops-system\n\n# Create Grafana admin password secret\nkubectl create secret generic grafana-admin \\\n  --from-literal=password=\"secure-grafana-password\" \\\n  -n pipeops-system\n</code></pre> <p>Reference secrets in configuration:</p> <pre><code>agent:\n  token:\n    secretKeyRef:\n      name: pipeops-token\n      key: token\n\nsecurity:\n  tls:\n    secretName: pipeops-tls\n\nmonitoring:\n  grafana:\n    admin_password:\n      secretKeyRef:\n        name: grafana-admin\n        key: password\n</code></pre>"},{"location":"getting-started/configuration/#using-external-secret-management","title":"Using External Secret Management","text":"HashiCorp VaultAWS Secrets ManagerAzure Key Vault <pre><code>agent:\n  token: \"vault:secret/pipeops#token\"\n\nsecurity:\n  tls:\n    cert_file: \"vault:secret/tls#cert\"\n    key_file: \"vault:secret/tls#key\"\n</code></pre> <pre><code>agent:\n  token: \"aws:secretsmanager:pipeops-token:SecretString:token\"\n\nmonitoring:\n  grafana:\n    admin_password: \"aws:secretsmanager:grafana-admin:SecretString:password\"\n</code></pre> <pre><code>agent:\n  token: \"azure:keyvault:pipeops-vault:pipeops-token\"\n\nsecurity:\n  tls:\n    cert_file: \"azure:keyvault:pipeops-vault:tls-cert\"\n    key_file: \"azure:keyvault:pipeops-vault:tls-key\"\n</code></pre>"},{"location":"getting-started/configuration/#configuration-validation","title":"\u2705 Configuration Validation","text":""},{"location":"getting-started/configuration/#validate-configuration","title":"Validate Configuration","text":"<pre><code># Validate configuration file\npipeops-agent config validate --config=/etc/pipeops/config.yaml\n\n# Test connection with configuration\npipeops-agent config test --config=/etc/pipeops/config.yaml\n\n# Show resolved configuration\npipeops-agent config show --config=/etc/pipeops/config.yaml\n</code></pre>"},{"location":"getting-started/configuration/#configuration-schema","title":"Configuration Schema","text":"<p>The agent supports JSON Schema validation:</p> <pre><code># Download configuration schema\ncurl -O https://schemas.pipeops.io/agent/v2/config.schema.json\n\n# Validate against schema\njsonschema -i config.yaml config.schema.json\n</code></pre>"},{"location":"getting-started/configuration/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"getting-started/configuration/#custom-resource-definitions","title":"Custom Resource Definitions","text":"<p>Define custom monitoring targets:</p> <pre><code># Custom CRD example\napiVersion: monitoring.pipeops.io/v1\nkind: ServiceMonitor\nmetadata:\n  name: custom-app-monitor\nspec:\n  selector:\n    matchLabels:\n      app: custom-app\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n</code></pre>"},{"location":"getting-started/configuration/#plugin-configuration","title":"Plugin Configuration","text":"<p>Configure agent plugins:</p> <pre><code>plugins:\n  enabled:\n    - \"network-monitor\"\n    - \"cost-optimizer\"\n    - \"security-scanner\"\n\n  network-monitor:\n    config:\n      check_interval: \"60s\"\n      endpoints:\n        - \"https://api.example.com\"\n        - \"https://db.example.com:5432\"\n\n  cost-optimizer:\n    config:\n      scan_interval: \"24h\"\n      optimization_mode: \"balanced\"  # aggressive, balanced, conservative\n\n  security-scanner:\n    config:\n      scan_interval: \"12h\"\n      vulnerability_threshold: \"medium\"\n</code></pre>"},{"location":"getting-started/configuration/#configuration-best-practices","title":"\ud83d\udcdd Configuration Best Practices","text":""},{"location":"getting-started/configuration/#1-use-environment-specific-configs","title":"1. Use Environment-Specific Configs","text":"<pre><code># Directory structure\n/etc/pipeops/\n\u251c\u2500\u2500 config.yaml                 # Base configuration\n\u251c\u2500\u2500 environments/\n\u2502   \u251c\u2500\u2500 dev.yaml                # Development overrides\n\u2502   \u251c\u2500\u2500 staging.yaml            # Staging overrides\n\u2502   \u2514\u2500\u2500 production.yaml         # Production overrides\n\u2514\u2500\u2500 secrets/\n    \u251c\u2500\u2500 tokens.yaml             # Secret references\n    \u2514\u2500\u2500 certificates/           # TLS certificates\n</code></pre>"},{"location":"getting-started/configuration/#2-configuration-inheritance","title":"2. Configuration Inheritance","text":"<pre><code># Base config.yaml\ndefaults: &amp;defaults\n  agent:\n    heartbeat_interval: \"30s\"\n    timeout: \"60s\"\n  monitoring:\n    enabled: true\n\n# Environment-specific configs\ndevelopment:\n  &lt;&lt;: *defaults\n  agent:\n    log_level: \"debug\"\n\nproduction:\n  &lt;&lt;: *defaults\n  agent:\n    log_level: \"warn\"\n  security:\n    tls:\n      enabled: true\n</code></pre>"},{"location":"getting-started/configuration/#3-version-control-integration","title":"3. Version Control Integration","text":"<pre><code># Git hooks for configuration validation\n#!/bin/bash\n# .git/hooks/pre-commit\npipeops-agent config validate --config=config.yaml\nif [ $? -ne 0 ]; then\n    echo \"Configuration validation failed\"\n    exit 1\nfi\n</code></pre>"},{"location":"getting-started/configuration/#troubleshooting-configuration","title":"\ud83d\udd0d Troubleshooting Configuration","text":""},{"location":"getting-started/configuration/#common-configuration-issues","title":"Common Configuration Issues","text":"Agent fails to start with configuration errors <p>Check configuration syntax: <pre><code>pipeops-agent config validate --config=/etc/pipeops/config.yaml\n</code></pre></p> <p>Common issues: - Invalid YAML syntax - Missing required fields - Incorrect data types - Invalid enum values</p> Secret references not resolving <p>Verify secret exists: <pre><code>kubectl get secret pipeops-token -n pipeops-system\n</code></pre></p> <p>Check RBAC permissions: <pre><code>kubectl auth can-i get secrets --as=system:serviceaccount:pipeops-system:pipeops-agent\n</code></pre></p> Monitoring stack not starting <p>Check resource limits: <pre><code>kubectl describe pod -l app=prometheus -n pipeops-system\n</code></pre></p> <p>Verify storage class: <pre><code>kubectl get storageclass\n</code></pre></p>"},{"location":"getting-started/configuration/#debug-configuration-loading","title":"Debug Configuration Loading","text":"<p>Enable debug logging to see configuration loading:</p> <pre><code>export PIPEOPS_LOG_LEVEL=debug\npipeops-agent start --config=/etc/pipeops/config.yaml\n</code></pre> <p>Look for these log messages: - <code>Loading configuration from file</code> - <code>Resolving environment variables</code> - <code>Validating configuration schema</code> - <code>Configuration loaded successfully</code></p> <p>Next Steps: Architecture Guide | Advanced Monitoring</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Welcome to the PipeOps Kubernetes Agent installation guide. Choose the installation method that best fits your environment.</p>"},{"location":"getting-started/installation/#quick-install-recommended","title":"Quick Install (Recommended)","text":"<p>The intelligent installer automatically detects your environment and installs all necessary components:</p> <pre><code># Set your PipeOps token (required)\nexport PIPEOPS_TOKEN=\"your-pipeops-token\"\n\n# Optional but recommended for clarity in the dashboard\nexport CLUSTER_NAME=\"my-pipeops-cluster\"\n\n# Optional: pin a specific distribution (k3s|minikube|k3d|kind|auto)\n# export CLUSTER_TYPE=\"auto\"\n\n# Run the installer (via installer domain)\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre> <p>This installer will:</p> <ul> <li>Detect your operating system and architecture</li> <li>Install prerequisites (Docker, kubectl, K3s, etc.)</li> <li>Install Gateway API experimental CRDs and Istio (for TCP/UDP routing)</li> <li>Deploy the PipeOps agent as a system service</li> <li>Configure monitoring stack (Prometheus, Grafana, Loki)</li> <li>Set up secure connection to PipeOps control plane</li> <li>Transform your VM into a production-ready Kubernetes server</li> </ul> <p>Note: Gateway API and Istio are installed by default. To skip, set <code>INSTALL_GATEWAY_API=false</code></p>"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":"Helm ChartDockerBinaryKubernetes Manifest <p>Prerequisites: Helm 3.8+ and kubectl configured</p> <pre><code># Install the agent directly from GHCR\nhelm install pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --set agent.pipeops.token=\"your-pipeops-token\" \\\n  --set agent.cluster.name=\"your-cluster-name\"\n</code></pre> <p>Custom Configuration: <pre><code># Create custom values file\ncat &gt; values-custom.yaml &lt;&lt; EOF\nagent:\n  pipeops:\n    token: \"your-pipeops-token\"\n  cluster:\n    name: \"production-cluster\"\n  resources:\n    requests:\n      memory: \"256Mi\"\n      cpu: \"250m\"\n    limits:\n      memory: \"512Mi\"\n      cpu: \"500m\"\nEOF\n\n# Install with custom configuration\nhelm install pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent -f values-custom.yaml\n</code></pre></p> <p>Prerequisites: Docker 20.0+ and access to Docker socket</p> <pre><code># Run the agent in a container\ndocker run -d \\\n  --name pipeops-agent \\\n  --restart unless-stopped \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v /etc/pipeops:/etc/pipeops \\\n  -e PIPEOPS_CLUSTER_NAME=\"your-cluster\" \\\n  -e PIPEOPS_TOKEN=\"your-token\" \\\n  pipeops/agent:latest\n</code></pre> <p>Docker Compose: <pre><code>version: '3.8'\nservices:\n  pipeops-agent:\n    image: pipeops/agent:latest\n    container_name: pipeops-agent\n    restart: unless-stopped\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./config:/etc/pipeops\n    environment:\n      - PIPEOPS_CLUSTER_NAME=your-cluster\n      - PIPEOPS_TOKEN=your-token\n    ports:\n      - \"8080:8080\"  # Agent dashboard\n</code></pre></p> <p>Manual Installation:</p> <ol> <li> <p>Download the latest release: <pre><code># Detect architecture\nARCH=$(uname -m)\nOS=$(uname -s | tr '[:upper:]' '[:lower:]')\n\n# Download binary\ncurl -LO \"https://github.com/PipeOpsHQ/pipeops-k8-agent/releases/latest/download/pipeops-agent-${OS}-${ARCH}.tar.gz\"\n</code></pre></p> </li> <li> <p>Extract and install: <pre><code>tar -xzf pipeops-agent-${OS}-${ARCH}.tar.gz\nsudo mv pipeops-agent /usr/local/bin/\nsudo chmod +x /usr/local/bin/pipeops-agent\n</code></pre></p> </li> <li> <p>Verify installation: <pre><code>pipeops-agent version\n</code></pre></p> </li> </ol> <p>Direct Kubernetes deployment:</p> <pre><code># Download the manifest\ncurl -O https://get.pipeops.dev/k8-agent.yaml\n\n# Edit the manifest with your configuration\nvim agent.yaml\n\n# Apply to cluster\nkubectl apply -f agent.yaml\n</code></pre>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing the PipeOps Agent, ensure your system meets these requirements:</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":"Component Minimum Recommended CPU 1 core 2+ cores Memory 512MB 1GB+ Storage 1GB 5GB+ Network Outbound HTTPS (443) Outbound HTTPS + SSH (22)"},{"location":"getting-started/installation/#software-dependencies","title":"Software Dependencies","text":"LinuxmacOSWindows <p>Ubuntu/Debian: <pre><code>sudo apt update\nsudo apt install -y curl wget gnupg2 software-properties-common\n</code></pre></p> <p>CentOS/RHEL/Fedora: <pre><code>sudo yum update -y\nsudo yum install -y curl wget gnupg2\n</code></pre></p> <p>Homebrew (recommended): <pre><code># Install Homebrew if not present\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install dependencies\nbrew install curl wget\n</code></pre></p> <p>PowerShell (run as Administrator): <pre><code># Install Chocolatey\nSet-ExecutionPolicy Bypass -Scope Process -Force\n[System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072\niex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\n\n# Install dependencies\nchoco install curl wget -y\n</code></pre></p>"},{"location":"getting-started/installation/#kubernetes-requirements","title":"Kubernetes Requirements","text":"<p>If deploying to an existing Kubernetes cluster:</p> <ul> <li>Kubernetes version: 1.20+</li> <li>kubectl: Configured with cluster access</li> <li>RBAC permissions: Cluster admin or sufficient permissions</li> <li>Container runtime: Docker, containerd, or CRI-O</li> </ul>"},{"location":"getting-started/installation/#authentication-configuration","title":"Authentication &amp; Configuration","text":""},{"location":"getting-started/installation/#obtaining-your-pipeops-token","title":"Obtaining Your PipeOps Token","text":"<ol> <li> <p>Log in to PipeOps Dashboard:    Visit console.pipeops.io and navigate to your organization.</p> </li> <li> <p>Create a new server:</p> </li> <li>Go to \"Infrastructure\" \u2192 \"Servers\"</li> <li>Click \"Add Server\"</li> <li>Select \"VM Agent\"</li> <li> <p>Copy the generated token</p> </li> <li> <p>Set environment variables before installation:    <pre><code># Set your PipeOps token (required)\nexport PIPEOPS_TOKEN=\"your-pipeops-token-here\"\n\n# Set cluster name (optional but recommended)\nexport CLUSTER_NAME=\"production-cluster\"\n\n# Set cluster type (optional)\nexport CLUSTER_TYPE=\"k3s\"\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#configuration-file","title":"Configuration File","text":"<p>Create a configuration file at <code>/etc/pipeops/config.yaml</code>:</p> <pre><code># PipeOps Agent Configuration\ncluster:\n  name: \"production-cluster\"\n  region: \"us-west-2\"\n  environment: \"production\"\n\nagent:\n  token: \"your-cluster-token\"\n  endpoint: \"https://api.pipeops.io\"\n  log_level: \"info\"\n\nmonitoring:\n  enabled: true\n  prometheus:\n    port: 9090\n    retention: \"30d\"\n  grafana:\n    port: 3000\n    admin_password: \"your-secure-password\"\n  loki:\n    port: 3100\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>After installation, verify that the agent is running correctly:</p>"},{"location":"getting-started/installation/#1-check-service-status","title":"1. Check Service Status","text":"<pre><code># Check if the service is running\nsudo systemctl status pipeops-agent\n\n# View service logs\nsudo journalctl -u pipeops-agent --no-pager -n 20\n</code></pre> <p>Expected output: <pre><code>\u25cf pipeops-agent.service - PipeOps Kubernetes Agent\n   Loaded: loaded (/etc/systemd/system/pipeops-agent.service; enabled)\n   Active: active (running) since Mon 2024-01-15 10:30:00 UTC; 2min ago\n   Main PID: 12345 (pipeops-agent)\n</code></pre></p>"},{"location":"getting-started/installation/#2-verify-kubernetes-setup","title":"2. Verify Kubernetes Setup","text":"<pre><code># Check K3s status\nsudo systemctl status k3s\n\n# List running containers\nsudo k3s crictl ps\n\n# Check node status\nsudo k3s kubectl get nodes\n</code></pre> <p>Expected output: <pre><code>NAME                 STATUS   ROLES                  AGE     VERSION\nyour-server-name     Ready    control-plane,master   2m30s   v1.28.2+k3s1\n</code></pre></p>"},{"location":"getting-started/installation/#3-access-monitoring-dashboard","title":"3. Access Monitoring Dashboard","text":"<p>The agent includes a local dashboard accessible at <code>http://localhost:8080</code>:</p> <ul> <li>Agent Status: Real-time agent health and metrics</li> <li>Cluster Overview: Kubernetes cluster information</li> <li>Logs: Agent and application logs</li> <li>Metrics: Performance and resource usage</li> </ul>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":"Service fails to connect to PipeOps platform <p>Symptoms: Service logs show connection errors or authentication failures</p> <p>Solutions:</p> <ol> <li> <p>Check network connectivity: <pre><code>curl -I https://api.pipeops.io\n</code></pre></p> </li> <li> <p>Verify your token is set correctly: <pre><code>sudo journalctl -u pipeops-agent | grep -i token\n</code></pre></p> </li> <li> <p>Check firewall settings (outbound HTTPS/443 required)</p> </li> </ol> Kubernetes permissions denied <p>Symptoms: RBAC errors or insufficient permissions</p> <p>Solutions:</p> <ol> <li> <p>Ensure cluster admin access: <pre><code>kubectl auth can-i \"*\" \"*\" --all-namespaces\n</code></pre></p> </li> <li> <p>Apply RBAC configuration: <pre><code>kubectl apply -f https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/deployments/rbac.yaml\n</code></pre></p> </li> </ol> Monitoring stack fails to start <p>Symptoms: Prometheus, Grafana, or Loki pods in error state</p> <p>Solutions:</p> <ol> <li> <p>Check resource limits: <pre><code>kubectl describe pod -n pipeops-system\n</code></pre></p> </li> <li> <p>Increase resource allocation: <pre><code>helm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --set resources.requests.memory=1Gi \\\n  --set resources.requests.cpu=500m\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li> <p>Check the service logs:    <pre><code>sudo journalctl -u pipeops-agent --no-pager -n 50\n</code></pre></p> </li> <li> <p>Check service status:    <pre><code>sudo systemctl status pipeops-agent\n</code></pre></p> </li> <li> <p>Contact support:</p> </li> <li>GitHub Issues</li> <li>Support Portal</li> <li>Email: support@pipeops.io</li> </ol>"},{"location":"getting-started/installation/#upgrading","title":"Upgrading","text":"<p>Keep your PipeOps Agent up to date with the latest features and security updates.</p>"},{"location":"getting-started/installation/#automatic-updates","title":"Automatic Updates","text":"<p>The agent can be configured to update automatically:</p> <pre><code># Enable automatic updates (recommended for development)\npipeops-agent config set auto-update.enabled=true\npipeops-agent config set auto-update.channel=stable\n\n# Check for updates manually\npipeops-agent update check\n</code></pre>"},{"location":"getting-started/installation/#manual-updates","title":"Manual Updates","text":"Script InstallationHelm ChartDockerBinary <p>Using the install script: <pre><code># Re-run the installer (preserves configuration)\ncurl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre></p> <p>Using the built-in update command: <pre><code># Update to latest version\nsudo pipeops-agent update\n\n# Update to specific version\nsudo pipeops-agent update --version=v1.2.3\n\n# Check current version\npipeops-agent version\n</code></pre></p> <p>Upgrade using GHCR: <pre><code># Upgrade to latest version\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent\n\n# Upgrade to specific version\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent --version=1.2.3\n\n# Check upgrade status\nhelm status pipeops-agent\n</code></pre></p> <p>Upgrade with custom values: <pre><code># Upgrade preserving custom configuration\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent -f values-custom.yaml\n</code></pre></p> <p>Update Docker container: <pre><code># Pull latest image\ndocker pull pipeops/agent:latest\n\n# Stop and remove old container\ndocker stop pipeops-agent\ndocker rm pipeops-agent\n\n# Start with new image (preserving volumes)\ndocker run -d \\\n  --name pipeops-agent \\\n  --restart unless-stopped \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v /etc/pipeops:/etc/pipeops \\\n  -e PIPEOPS_CLUSTER_NAME=\"your-cluster\" \\\n  -e PIPEOPS_TOKEN=\"your-token\" \\\n  pipeops/agent:latest\n</code></pre></p> <p>Manual binary update: <pre><code># Download latest version\nARCH=$(uname -m)\nOS=$(uname -s | tr '[:upper:]' '[:lower:]')\ncurl -LO \"https://github.com/PipeOpsHQ/pipeops-k8-agent/releases/latest/download/pipeops-agent-${OS}-${ARCH}.tar.gz\"\n\n# Stop service\nsudo systemctl stop pipeops-agent\n\n# Backup current binary\nsudo cp /usr/local/bin/pipeops-agent /usr/local/bin/pipeops-agent.backup\n\n# Install new version\ntar -xzf pipeops-agent-${OS}-${ARCH}.tar.gz\nsudo mv pipeops-agent /usr/local/bin/\nsudo chmod +x /usr/local/bin/pipeops-agent\n\n# Start service\nsudo systemctl start pipeops-agent\n\n# Verify update\npipeops-agent version\n</code></pre></p>"},{"location":"getting-started/installation/#update-verification","title":"Update Verification","text":"<p>After updating, verify the installation:</p> <pre><code># Check agent version\npipeops-agent version\n\n# Verify service status\nsudo systemctl status pipeops-agent\n\n# Check connectivity\npipeops-agent status\n\n# Run health check\npipeops-agent diagnose\n</code></pre>"},{"location":"getting-started/installation/#rolling-back-updates","title":"Rolling Back Updates","text":"<p>If you encounter issues after an update:</p> Script/Binary InstallationHelm ChartDocker <pre><code># Stop service\nsudo systemctl stop pipeops-agent\n\n# Restore backup\nsudo cp /usr/local/bin/pipeops-agent.backup /usr/local/bin/pipeops-agent\n\n# Start service\nsudo systemctl start pipeops-agent\n</code></pre> <pre><code># View upgrade history\nhelm history pipeops-agent\n\n# Rollback to previous version\nhelm rollback pipeops-agent\n\n# Rollback to specific revision\nhelm rollback pipeops-agent 2\n</code></pre> <pre><code># Use specific image version\ndocker stop pipeops-agent &amp;&amp; docker rm pipeops-agent\n\ndocker run -d \\\n  --name pipeops-agent \\\n  --restart unless-stopped \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v /etc/pipeops:/etc/pipeops \\\n  -e PIPEOPS_CLUSTER_NAME=\"your-cluster\" \\\n  -e PIPEOPS_TOKEN=\"your-token\" \\\n  pipeops/agent:v1.1.0  # Specify previous version\n</code></pre>"},{"location":"getting-started/installation/#uninstalling","title":"Uninstalling","text":"<p>If you need to remove the PipeOps Agent from your system:</p>"},{"location":"getting-started/installation/#complete-removal","title":"Complete Removal","text":"Script InstallationHelm ChartDockerKubernetes Manifest <p>Using the uninstall script (recommended): <pre><code>curl -fsSL https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/scripts/uninstall.sh | bash\n</code></pre></p> <p>Include optional flags via environment variables: <pre><code># Remove the agent but keep PVC data\nKEEP_DATA=true curl -fsSL https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/scripts/uninstall.sh | bash\n\n# Remove the agent and bundled k3s install\nUNINSTALL_K3S=true curl -fsSL https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/scripts/uninstall.sh | bash\n\n# Skip interactive prompts for automation\nFORCE=true curl -fsSL https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/scripts/uninstall.sh | bash\n</code></pre></p> <p>Manual removal: <pre><code># Stop and disable service\nsudo systemctl stop pipeops-agent\nsudo systemctl disable pipeops-agent\n\n# Remove service file\nsudo rm /etc/systemd/system/pipeops-agent.service\nsudo systemctl daemon-reload\n\n# Remove binary\nsudo rm /usr/local/bin/pipeops-agent\n\n# Remove configuration (optional)\nsudo rm -rf /etc/pipeops\n\n# Remove logs (optional)\nsudo rm -rf /var/log/pipeops\n\n# Remove k3s (if installed by agent)\nif [ -f /usr/local/bin/k3s-uninstall.sh ]; then\n    sudo /usr/local/bin/k3s-uninstall.sh\nfi\n</code></pre></p> <p>Uninstall Helm release: <pre><code># Uninstall the agent\nhelm uninstall pipeops-agent\n\n# Remove namespace (optional)\nkubectl delete namespace pipeops-system\n\n# Remove custom resources (optional)\nkubectl delete crd pipeopsagents.pipeops.io\n</code></pre></p> <p>Complete cleanup: <pre><code># Remove all PipeOps resources\nkubectl delete all -l app.kubernetes.io/name=pipeops-agent --all-namespaces\nkubectl delete configmap -l app.kubernetes.io/name=pipeops-agent --all-namespaces\nkubectl delete secret -l app.kubernetes.io/name=pipeops-agent --all-namespaces\n\n# Remove RBAC resources\nkubectl delete clusterrole pipeops-agent\nkubectl delete clusterrolebinding pipeops-agent\n</code></pre></p> <p>Remove Docker container and data: <pre><code># Stop and remove container\ndocker stop pipeops-agent\ndocker rm pipeops-agent\n\n# Remove image (optional)\ndocker rmi pipeops/agent:latest\n\n# Remove volumes (optional)\ndocker volume rm $(docker volume ls -q | grep pipeops)\n\n# Remove configuration\nsudo rm -rf /etc/pipeops\n</code></pre></p> <p>Remove deployed resources: <pre><code># Delete the deployment\nkubectl delete -f agent.yaml\n\n# Or delete by labels\nkubectl delete all -l app=pipeops-agent -n pipeops-system\n\n# Remove namespace\nkubectl delete namespace pipeops-system\n</code></pre></p>"},{"location":"getting-started/installation/#partial-removal","title":"Partial Removal","text":"<p>Remove only specific components:</p> <pre><code># Remove the agent but keep PVC data\nKEEP_DATA=true curl -fsSL https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/scripts/uninstall.sh | bash\n\n# Remove the agent and bundled k3s install\nUNINSTALL_K3S=true curl -fsSL https://raw.githubusercontent.com/PipeOpsHQ/pipeops-k8-agent/main/scripts/uninstall.sh | bash\n\n# Remove configuration while leaving logs for auditing\nsudo rm -rf /etc/pipeops\n# Logs remain in /var/log/pipeops\n</code></pre>"},{"location":"getting-started/installation/#cleanup-verification","title":"Cleanup Verification","text":"<p>Verify complete removal:</p> <pre><code># Check for running processes\nps aux | grep pipeops\n\n# Check for remaining files\nfind / -name \"*pipeops*\" 2&gt;/dev/null\n\n# Check Kubernetes resources\nkubectl get all -A | grep pipeops\n\n# Check system services\nsystemctl list-units | grep pipeops\n\n# Check Docker containers and images\ndocker ps -a | grep pipeops\ndocker images | grep pipeops\n</code></pre>"},{"location":"getting-started/installation/#preserving-data","title":"Preserving Data","text":"<p>If you plan to reinstall later, you can preserve certain data:</p> <pre><code># Backup configuration\nsudo cp -r /etc/pipeops /tmp/pipeops-config-backup\n\n# Backup logs\nsudo cp -r /var/log/pipeops /tmp/pipeops-logs-backup\n\n# Export Kubernetes configuration\nkubectl get configmap pipeops-agent-config -n pipeops-system -o yaml &gt; pipeops-k8s-config.yaml\n\n# Backup monitoring data (if using persistent volumes)\nkubectl get pv | grep pipeops\n</code></pre>"},{"location":"getting-started/installation/#post-uninstall","title":"Post-Uninstall","text":"<p>After uninstalling:</p> <ol> <li>Remove from PipeOps Dashboard: </li> <li>Go to console.pipeops.io</li> <li>Navigate to \"Infrastructure\" \u2192 \"Clusters\"</li> <li> <p>Remove the disconnected cluster</p> </li> <li> <p>Clean up firewall rules (if configured):    <pre><code># Remove PipeOps-specific rules\nsudo ufw delete allow from any to any port 6443\nsudo ufw delete allow from any to any port 8080\n</code></pre></p> </li> <li> <p>Verify system resources:    <pre><code># Check remaining disk usage\ndf -h\n\n# Check memory usage\nfree -h\n\n# Check running services\nsystemctl list-units --state=running\n</code></pre></p> </li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>Quick Start Guide - Get familiar with basic operations</li> <li>Configuration - Customize your agent setup  </li> <li>Architecture Overview - Understand the system design</li> <li>Advanced Monitoring - Set up comprehensive observability</li> <li>Expose Ingress With Tailscale Funnel - Publish the cluster without opening firewall ports</li> </ol> <p>Pro Tip</p> <p>Enable debug logging during initial setup to troubleshoot any issues: <pre><code>export PIPEOPS_LOG_LEVEL=debug\npipeops-agent start\n</code></pre></p>"},{"location":"getting-started/management/","title":"Agent Management","text":"<p>Essential operations for managing your PipeOps Kubernetes Agent throughout its lifecycle.</p>"},{"location":"getting-started/management/#quick-reference","title":"Quick Reference","text":"Operation Command Description Check Status <code>pipeops-agent status</code> View agent health and connectivity Update <code>sudo pipeops-agent update</code> Upgrade to latest version Restart <code>sudo systemctl restart pipeops-agent</code> Restart the agent service Uninstall <code>sudo pipeops-agent uninstall</code> Complete removal Logs <code>sudo journalctl -u pipeops-agent -f</code> View real-time logs Diagnose <code>pipeops-agent diagnose</code> Run comprehensive health check"},{"location":"getting-started/management/#status-health-monitoring","title":"Status &amp; Health Monitoring","text":""},{"location":"getting-started/management/#check-agent-status","title":"Check Agent Status","text":"<pre><code># Basic status check\npipeops-agent status\n\n# Detailed health check\npipeops-agent diagnose\n\n# Service status (Linux)  \nsudo systemctl status pipeops-agent\n\n# View recent logs\nsudo journalctl -u pipeops-agent --no-pager -n 20\n</code></pre> <p>Expected healthy output: <pre><code>PipeOps Agent Status: \u2705 Running\nControl Plane: \u2705 Connected (api.pipeops.io)\nKubernetes API: \u2705 Accessible\nCluster Name: production-cluster\nAgent Version: v1.2.3\nUptime: 2d 14h 32m\n</code></pre></p>"},{"location":"getting-started/management/#monitoring-key-metrics","title":"Monitoring Key Metrics","text":"<pre><code># Resource usage\npipeops-agent resources\n\n# Cluster information\npipeops-agent cluster info\n\n# Network connectivity test\npipeops-agent network test\n\n# Check for configuration issues\npipeops-agent validate config\n</code></pre>"},{"location":"getting-started/management/#updates-upgrades","title":"Updates &amp; Upgrades","text":""},{"location":"getting-started/management/#checking-for-updates","title":"Checking for Updates","text":"<pre><code># Check for available updates\npipeops-agent update check\n\n# View current version\npipeops-agent version\n\n# View update history\npipeops-agent update history\n</code></pre>"},{"location":"getting-started/management/#updating-the-agent","title":"Updating the Agent","text":"Automatic UpdateManual UpdateHelm Update <pre><code># Enable automatic updates (development environments)\npipeops-agent config set auto-update.enabled=true\npipeops-agent config set auto-update.channel=stable\n\n# Check auto-update status\npipeops-agent config get auto-update\n</code></pre> <pre><code># Update to latest stable version\nsudo pipeops-agent update\n\n# Update to specific version\nsudo pipeops-agent update --version=v1.2.3\n\n# Update with backup (recommended)\nsudo pipeops-agent update --backup\n</code></pre> <pre><code># Upgrade to latest version\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent\n\n# Upgrade with custom values\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent -f values.yaml\n</code></pre>"},{"location":"getting-started/management/#post-update-verification","title":"Post-Update Verification","text":"<pre><code># Verify new version\npipeops-agent version\n\n# Check service status\nsudo systemctl status pipeops-agent\n\n# Run health check\npipeops-agent diagnose\n\n# Verify connectivity\npipeops-agent status\n</code></pre>"},{"location":"getting-started/management/#configuration-management","title":"Configuration Management","text":""},{"location":"getting-started/management/#viewing-configuration","title":"Viewing Configuration","text":"<pre><code># Show current configuration\npipeops-agent config show\n\n# Export configuration to file\npipeops-agent config export &gt; config-backup.yaml\n\n# Show specific configuration section\npipeops-agent config get agent.cluster.name\n</code></pre>"},{"location":"getting-started/management/#updating-configuration","title":"Updating Configuration","text":"<pre><code># Set configuration values\npipeops-agent config set agent.log_level=debug\npipeops-agent config set monitoring.enabled=true\n\n# Load configuration from file\npipeops-agent config load config.yaml\n\n# Reset to defaults\npipeops-agent config reset\n</code></pre>"},{"location":"getting-started/management/#configuration-file-locations","title":"Configuration File Locations","text":"Installation Method Config Location Script Install <code>/etc/pipeops/config.yaml</code> Helm Chart ConfigMap in release namespace Docker <code>/etc/pipeops/config.yaml</code> (mounted) Binary <code>~/.pipeops/config.yaml</code> or <code>/etc/pipeops/config.yaml</code>"},{"location":"getting-started/management/#service-management","title":"Service Management","text":""},{"location":"getting-started/management/#controlling-the-service","title":"Controlling the Service","text":"<pre><code># Start the service\nsudo systemctl start pipeops-agent\n\n# Stop the service\nsudo systemctl stop pipeops-agent\n\n# Restart the service\nsudo systemctl restart pipeops-agent\n\n# Enable auto-start on boot\nsudo systemctl enable pipeops-agent\n\n# Disable auto-start\nsudo systemctl disable pipeops-agent\n</code></pre>"},{"location":"getting-started/management/#service-information","title":"Service Information","text":"<pre><code># View service status\nsudo systemctl status pipeops-agent\n\n# View service configuration\nsudo systemctl show pipeops-agent\n\n# View service logs\nsudo journalctl -u pipeops-agent -f\n\n# View service dependencies\nsudo systemctl list-dependencies pipeops-agent\n</code></pre>"},{"location":"getting-started/management/#log-management","title":"Log Management","text":""},{"location":"getting-started/management/#viewing-logs","title":"Viewing Logs","text":"<pre><code># Real-time log viewing\nsudo journalctl -u pipeops-agent -f\n\n# View recent logs\nsudo journalctl -u pipeops-agent --no-pager -n 50\n\n# View logs for specific time period\nsudo journalctl -u pipeops-agent --since \"1 hour ago\"\n\n# View logs with specific priority\nsudo journalctl -u pipeops-agent -p err\n</code></pre>"},{"location":"getting-started/management/#log-configuration","title":"Log Configuration","text":"<pre><code># Set log level\npipeops-agent config set agent.log_level=debug\n\n# Set log format\npipeops-agent config set agent.log_format=json\n\n# Set log output\npipeops-agent config set agent.log_output=/var/log/pipeops/agent.log\n</code></pre>"},{"location":"getting-started/management/#log-rotation","title":"Log Rotation","text":"<p>Logs are automatically rotated. To configure:</p> <pre><code># Configure log rotation\nsudo tee /etc/logrotate.d/pipeops-agent &lt;&lt; EOF\n/var/log/pipeops/*.log {\n    daily\n    rotate 7\n    compress\n    delaycompress\n    missingok\n    notifempty\n    postrotate\n        systemctl reload pipeops-agent\n    endscript\n}\nEOF\n</code></pre>"},{"location":"getting-started/management/#backup-restore","title":"Backup &amp; Restore","text":""},{"location":"getting-started/management/#creating-backups","title":"Creating Backups","text":"<pre><code># Backup configuration\npipeops-agent backup create --type=config --output=/tmp/pipeops-config-backup.tar.gz\n\n# Backup complete state\npipeops-agent backup create --type=full --output=/tmp/pipeops-full-backup.tar.gz\n\n# Backup specific components\npipeops-agent backup create --type=monitoring --output=/tmp/pipeops-monitoring-backup.tar.gz\n</code></pre>"},{"location":"getting-started/management/#restoring-from-backup","title":"Restoring from Backup","text":"<pre><code># Restore configuration\npipeops-agent backup restore --input=/tmp/pipeops-config-backup.tar.gz\n\n# Restore with confirmation\npipeops-agent backup restore --input=/tmp/pipeops-full-backup.tar.gz --confirm\n\n# Restore specific components\npipeops-agent backup restore --type=monitoring --input=/tmp/pipeops-monitoring-backup.tar.gz\n</code></pre>"},{"location":"getting-started/management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/management/#common-issues","title":"Common Issues","text":"Agent Not StartingConnection IssuesHigh Resource Usage <p>Check service logs: <pre><code>sudo journalctl -u pipeops-agent --no-pager -n 50\n</code></pre></p> <p>Verify configuration: <pre><code>pipeops-agent validate config\n</code></pre></p> <p>Check permissions: <pre><code>ls -la /etc/pipeops/\nsudo chown -R pipeops:pipeops /etc/pipeops/\n</code></pre></p> <p>Test network connectivity: <pre><code>curl -I https://api.pipeops.io\npipeops-agent network test\n</code></pre></p> <p>Verify token: <pre><code>pipeops-agent validate token\n</code></pre></p> <p>Check firewall: <pre><code>sudo ufw status verbose\n</code></pre></p> <p>Check resource consumption: <pre><code>pipeops-agent resources\ntop -p $(pgrep pipeops-agent)\n</code></pre></p> <p>Adjust resource limits: <pre><code>pipeops-agent config set agent.resources.limits.memory=512Mi\npipeops-agent config set agent.resources.limits.cpu=500m\n</code></pre></p>"},{"location":"getting-started/management/#diagnostic-commands","title":"Diagnostic Commands","text":"<pre><code># Comprehensive health check\npipeops-agent diagnose\n\n# Check specific components\npipeops-agent diagnose --component=network\npipeops-agent diagnose --component=kubernetes\npipeops-agent diagnose --component=monitoring\n\n# Generate support bundle\npipeops-agent support bundle --output=/tmp/pipeops-support.tar.gz\n</code></pre>"},{"location":"getting-started/management/#complete-removal","title":"Complete Removal","text":""},{"location":"getting-started/management/#uninstalling","title":"Uninstalling","text":"Script InstallationHelm InstallationDocker Installation <pre><code># Standard uninstall\nsudo pipeops-agent uninstall\n\n# Complete removal with data purge\nsudo pipeops-agent uninstall --purge-data\n\n# Keep configuration for future reinstall\nsudo pipeops-agent uninstall --keep-config\n</code></pre> <pre><code># Uninstall Helm release\nhelm uninstall pipeops-agent\n\n# Remove namespace\nkubectl delete namespace pipeops-system\n\n# Clean up custom resources\nkubectl delete crd pipeopsagents.pipeops.io\n</code></pre> <pre><code># Stop and remove container\ndocker stop pipeops-agent\ndocker rm pipeops-agent\n\n# Remove image\ndocker rmi pipeops/agent:latest\n\n# Remove volumes\ndocker volume prune\n</code></pre>"},{"location":"getting-started/management/#cleanup-verification","title":"Cleanup Verification","text":"<pre><code># Check for remaining processes\nps aux | grep pipeops\n\n# Check for remaining files\nfind / -name \"*pipeops*\" 2&gt;/dev/null\n\n# Check system services\nsystemctl list-units | grep pipeops\n\n# Verify complete removal\npipeops-agent version 2&gt;/dev/null &amp;&amp; echo \"Still installed\" || echo \"Successfully removed\"\n</code></pre>"},{"location":"getting-started/management/#security-management","title":"Security Management","text":""},{"location":"getting-started/management/#token-management","title":"Token Management","text":"<pre><code># Rotate agent token\npipeops-agent token rotate\n\n# Update token\npipeops-agent token update --token=new-token-here\n\n# Validate current token\npipeops-agent token validate\n</code></pre>"},{"location":"getting-started/management/#certificate-management","title":"Certificate Management","text":"<pre><code># Update TLS certificates\npipeops-agent certs update\n\n# View certificate information\npipeops-agent certs info\n\n# Validate certificates\npipeops-agent certs validate\n</code></pre>"},{"location":"getting-started/management/#security-audit","title":"Security Audit","text":"<pre><code># Run security audit\npipeops-agent security audit\n\n# Check RBAC permissions\npipeops-agent security rbac-check\n\n# Validate security configuration\npipeops-agent security validate\n</code></pre>"},{"location":"getting-started/management/#performance-tuning","title":"Performance Tuning","text":""},{"location":"getting-started/management/#resource-optimization","title":"Resource Optimization","text":"<pre><code># View resource usage\npipeops-agent resources\n\n# Optimize for low resource environments\npipeops-agent config set agent.performance.mode=low-resource\n\n# Optimize for high performance\npipeops-agent config set agent.performance.mode=high-performance\n\n# Custom resource limits\npipeops-agent config set agent.resources.limits.memory=1Gi\npipeops-agent config set agent.resources.limits.cpu=1000m\n</code></pre>"},{"location":"getting-started/management/#monitoring-performance","title":"Monitoring Performance","text":"<pre><code># View performance metrics\npipeops-agent metrics\n\n# Enable performance monitoring\npipeops-agent config set monitoring.performance.enabled=true\n\n# Set monitoring interval\npipeops-agent config set monitoring.interval=30s\n</code></pre>"},{"location":"getting-started/management/#getting-help","title":"Getting Help","text":""},{"location":"getting-started/management/#support-resources","title":"Support Resources","text":"<ul> <li>Documentation: docs.pipeops.io</li> <li>GitHub Issues: github.com/PipeOpsHQ/pipeops-k8-agent/issues</li> <li>Community Discord: discord.gg/pipeops</li> <li>Support Email: support@pipeops.io</li> </ul>"},{"location":"getting-started/management/#generating-support-information","title":"Generating Support Information","text":"<pre><code># Create comprehensive support bundle\npipeops-agent support bundle --output=/tmp/support-$(date +%Y%m%d-%H%M%S).tar.gz\n\n# Include system information\npipeops-agent support bundle --include-system --output=/tmp/support-full.tar.gz\n\n# Upload support bundle (requires support ticket ID)\npipeops-agent support upload --ticket=12345 --file=/tmp/support-bundle.tar.gz\n</code></pre> <p>Pro Tip</p> <p>Set up monitoring alerts to be notified of agent issues:</p> <pre><code># Enable email alerts\npipeops-agent config set alerts.email.enabled=true\npipeops-agent config set alerts.email.recipient=admin@yourdomain.com\n\n# Enable Slack notifications\npipeops-agent config set alerts.slack.webhook=https://hooks.slack.com/your-webhook\n</code></pre>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Get up and running with the PipeOps Kubernetes Agent in just a few minutes. This guide covers the essential steps to deploy the agent and start managing your cluster.</p>"},{"location":"getting-started/quick-start/#before-you-begin","title":"Before You Begin","text":"<p>Ensure you have:</p> <ul> <li>A Kubernetes cluster (local or cloud-based)</li> <li><code>kubectl</code> configured with cluster access</li> <li>A PipeOps account (sign up free)</li> <li>Cluster admin permissions</li> </ul>"},{"location":"getting-started/quick-start/#5-minute-setup","title":"5-Minute Setup","text":""},{"location":"getting-started/quick-start/#step-1-get-your-cluster-token","title":"Step 1: Get Your Cluster Token","text":"<ol> <li>Log in to PipeOps Dashboard: Visit console.pipeops.io</li> <li>Navigate to Clusters: Go to \"Infrastructure\" \u2192 \"Clusters\"</li> <li>Add New Cluster: Click \"Add Cluster\" \u2192 \"Kubernetes Agent\"</li> <li>Copy Token: Save the generated cluster token</li> </ol>"},{"location":"getting-started/quick-start/#step-2-install-the-agent","title":"Step 2: Install the Agent","text":"<p>Choose your preferred installation method:</p> One-Line InstallHelm ChartKubectl Apply <p>The fastest way to get started:</p> <pre><code>curl -fsSL https://get.pipeops.dev/k8-install.sh | bash\n</code></pre> <p>This command will: - Detect your environment automatically - Install all dependencies - Deploy the agent with monitoring stack - Connect securely to PipeOps control plane</p> <p>For production environments:</p> <pre><code># Install agent directly from GHCR\nhelm install pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --set agent.pipeops.token=\"your-pipeops-token\" \\\n  --set agent.cluster.name=\"my-cluster\"\n</code></pre> <p>Direct Kubernetes deployment:</p> <pre><code># Download manifest\ncurl -O https://get.pipeops.dev/k8-agent.yaml\n\n# Configure your token\nsed -i 's/YOUR_TOKEN_HERE/your-actual-token/' agent.yaml\n\n# Deploy\nkubectl apply -f agent.yaml\n</code></pre>"},{"location":"getting-started/quick-start/#step-3-verify-installation","title":"Step 3: Verify Installation","text":"<p>Check that the agent is running:</p> <pre><code># Check agent status\nkubectl get pods -n pipeops-system\n\n# Verify connectivity\npipeops-agent status\n</code></pre> <p>Expected output: <pre><code>PipeOps Agent Status: Running\nControl Plane Connection: Connected  \nKubernetes API: Accessible\nMonitoring Stack: Healthy\n</code></pre></p>"},{"location":"getting-started/quick-start/#essential-operations","title":"Essential Operations","text":""},{"location":"getting-started/quick-start/#viewing-cluster-status","title":"Viewing Cluster Status","text":"<p>Get an overview of your cluster health:</p> <pre><code># Agent status\npipeops-agent status\n\n# Detailed cluster info\npipeops-agent cluster info\n\n# Resource usage\npipeops-agent cluster resources\n</code></pre>"},{"location":"getting-started/quick-start/#accessing-monitoring-dashboards","title":"Accessing Monitoring Dashboards","text":"<p>The agent automatically sets up monitoring dashboards:</p> GrafanaPrometheusAgent Dashboard <pre><code># Port-forward to access Grafana\nkubectl port-forward -n pipeops-system svc/grafana 3000:3000\n</code></pre> <p>Open http://localhost:3000</p> <ul> <li>Username: <code>admin</code></li> <li>Password: Check with <code>kubectl get secret -n pipeops-system grafana-admin-password -o jsonpath='{.data.password}' | base64 -d</code></li> </ul> <pre><code># Port-forward to access Prometheus\nkubectl port-forward -n pipeops-system svc/prometheus 9090:9090\n</code></pre> <p>Open http://localhost:9090</p> <pre><code># Port-forward to access Agent Dashboard\nkubectl port-forward -n pipeops-system svc/pipeops-agent 8080:8080\n</code></pre> <p>Open http://localhost:8080</p>"},{"location":"getting-started/quick-start/#managing-applications","title":"Managing Applications","text":"<p>Deploy your first application through PipeOps:</p> <pre><code># List available applications\npipeops-agent apps list\n\n# Deploy an application\npipeops-agent apps deploy --name=\"my-app\" --image=\"nginx:latest\"\n\n# Check deployment status\npipeops-agent apps status my-app\n\n# Scale application\npipeops-agent apps scale my-app --replicas=3\n</code></pre>"},{"location":"getting-started/quick-start/#configuration-basics","title":"Configuration Basics","text":""},{"location":"getting-started/quick-start/#environment-variables","title":"Environment Variables","text":"<p>Key configuration options:</p> <pre><code># Set cluster name\nexport PIPEOPS_CLUSTER_NAME=\"production-cluster\"\n\n# Set log level (debug, info, warn, error)\nexport PIPEOPS_LOG_LEVEL=\"info\"\n\n# Set custom endpoint (for enterprise)\nexport PIPEOPS_ENDPOINT=\"https://your-enterprise.pipeops.io\"\n</code></pre>"},{"location":"getting-started/quick-start/#configuration-file","title":"Configuration File","text":"<p>Create <code>/etc/pipeops/config.yaml</code> for persistent settings:</p> <pre><code>cluster:\n  name: \"production-cluster\"\n  region: \"us-west-2\"\n  tags:\n    environment: \"production\"\n    team: \"platform\"\n\nagent:\n  log_level: \"info\"\n  heartbeat_interval: \"30s\"\n\nmonitoring:\n  enabled: true\n  retention_days: 30\n\nresources:\n  limits:\n    cpu: \"1000m\"\n    memory: \"1Gi\"\n</code></pre>"},{"location":"getting-started/quick-start/#health-checks","title":"Health Checks","text":""},{"location":"getting-started/quick-start/#quick-health-check","title":"Quick Health Check","text":"<pre><code># Run comprehensive health check\npipeops-agent diagnose\n</code></pre> <p>This command checks: - Agent connectivity to control plane - Kubernetes API access - Monitoring stack health - Resource availability - Network connectivity</p>"},{"location":"getting-started/quick-start/#monitoring-key-metrics","title":"Monitoring Key Metrics","text":"<p>Important metrics to watch:</p> Metric Description Command Cluster Health Overall cluster status <code>pipeops-agent cluster health</code> Resource Usage CPU, memory, storage <code>pipeops-agent resources</code> Pod Status Running/failed pods <code>kubectl get pods -A</code> Network Connectivity status <code>pipeops-agent network test</code>"},{"location":"getting-started/quick-start/#troubleshooting-quick-fixes","title":"Troubleshooting Quick Fixes","text":""},{"location":"getting-started/quick-start/#agent-not-connecting","title":"Agent Not Connecting","text":"<ol> <li> <p>Check network connectivity:    <pre><code>curl -I https://api.pipeops.io\n</code></pre></p> </li> <li> <p>Verify token:    <pre><code>pipeops-agent validate-token\n</code></pre></p> </li> <li> <p>Restart agent:    <pre><code>kubectl rollout restart deployment/pipeops-agent -n pipeops-system\n</code></pre></p> </li> </ol>"},{"location":"getting-started/quick-start/#monitoring-stack-issues","title":"Monitoring Stack Issues","text":"<ol> <li> <p>Check pod status:    <pre><code>kubectl get pods -n pipeops-system\n</code></pre></p> </li> <li> <p>View logs:    <pre><code>kubectl logs -f deployment/pipeops-agent -n pipeops-system\n</code></pre></p> </li> <li> <p>Restart monitoring:    <pre><code>kubectl rollout restart deployment/prometheus -n pipeops-system\nkubectl rollout restart deployment/grafana -n pipeops-system\n</code></pre></p> </li> </ol>"},{"location":"getting-started/quick-start/#resource-constraints","title":"Resource Constraints","text":"<ol> <li> <p>Check resource usage:    <pre><code>kubectl top nodes\nkubectl top pods -n pipeops-system\n</code></pre></p> </li> <li> <p>Increase resource limits:    <pre><code>helm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --set resources.limits.memory=2Gi \\\n  --set resources.limits.cpu=1000m\n</code></pre></p> </li> </ol>"},{"location":"getting-started/quick-start/#quick-operations","title":"Quick Operations","text":""},{"location":"getting-started/quick-start/#upgrading-the-agent","title":"Upgrading the Agent","text":"<p>Keep your agent updated with the latest features:</p> <pre><code># Check current version\npipeops-agent version\n\n# Update to latest version\nsudo pipeops-agent update\n\n# For Helm installations\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent\n\n# Verify update\npipeops-agent status\n</code></pre>"},{"location":"getting-started/quick-start/#uninstalling-the-agent","title":"Uninstalling the Agent","text":"<p>If you need to remove the agent:</p> <pre><code># Complete uninstall (removes everything)\nsudo pipeops-agent uninstall\n\n# Helm uninstall\nhelm uninstall pipeops-agent\n\n# Kubernetes manifest uninstall  \nkubectl delete -f agent.yaml\n</code></pre> <p>For detailed upgrade and uninstall procedures, see the Installation Guide.</p>"},{"location":"getting-started/quick-start/#whats-next","title":"What's Next?","text":"<p>Now that your agent is running, explore these features:</p>"},{"location":"getting-started/quick-start/#security-compliance","title":"Security &amp; Compliance","text":"<ul> <li>Configure RBAC for fine-grained access control</li> <li>Set up TLS certificates for secure communications</li> <li>Enable audit logging for compliance</li> </ul>"},{"location":"getting-started/quick-start/#advanced-monitoring","title":"Advanced Monitoring","text":"<ul> <li>Advanced monitoring setup for comprehensive observability</li> <li>Alerting and notifications for proactive issue detection</li> <li>Log aggregation with Loki and Grafana</li> </ul>"},{"location":"getting-started/quick-start/#cicd-integration","title":"CI/CD Integration","text":"<ul> <li>GitHub Actions integration for automated deployments</li> <li>GitLab CI pipelines for continuous deployment</li> <li>Jenkins plugins for enterprise environments</li> </ul>"},{"location":"getting-started/quick-start/#production-deployment","title":"Production Deployment","text":"<ul> <li>Scale your applications based on demand</li> <li>Monitor performance and resource usage</li> <li>Configure alerts and notifications</li> </ul>"},{"location":"getting-started/quick-start/#helpful-resources","title":"Helpful Resources","text":"<ul> <li>Complete Installation Guide - Detailed installation options</li> <li>Configuration Reference - All configuration options</li> <li>Architecture Guide - Understanding the system design</li> <li>Advanced Monitoring - Monitoring and observability</li> </ul>"},{"location":"getting-started/quick-start/#pro-tips","title":"Pro Tips","text":"<p>Performance Optimization</p> <p>For better performance in production:</p> <pre><code># Enable resource monitoring\nhelm upgrade pipeops-agent oci://ghcr.io/pipeopshq/pipeops-agent \\\n  --set monitoring.resources.enabled=true \\\n  --set agent.performance.mode=optimized\n</code></pre> <p>Development Environment</p> <p>For development clusters, enable debug mode:</p> <pre><code>export PIPEOPS_LOG_LEVEL=debug\npipeops-agent start --dev-mode\n</code></pre> <p>Backup Configuration</p> <p>Always backup your configuration:</p> <pre><code># Export current configuration\npipeops-agent config export &gt; pipeops-config-backup.yaml\n\n# Store in version control\ngit add pipeops-config-backup.yaml\ngit commit -m \"Add PipeOps agent configuration backup\"\n</code></pre> <p>Need help? Join our community Discord or check the installation guide for more details.</p>"},{"location":"reference/changelog/","title":"Changelog","text":"<p>All notable changes to the PipeOps Kubernetes Agent will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"reference/changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"reference/changelog/#added","title":"Added","text":"<ul> <li>Enhanced documentation with Material Design styling</li> <li>Complete MkDocs configuration with dark/light mode support</li> <li>Comprehensive command reference documentation</li> <li>Improved troubleshooting guides</li> </ul>"},{"location":"reference/changelog/#changed","title":"Changed","text":"<ul> <li>Updated MkDocs theme to Material Design with indigo color scheme</li> <li>Reorganized documentation structure for better navigation</li> </ul>"},{"location":"reference/changelog/#210-2023-10-26","title":"[2.1.0] - 2023-10-26","text":""},{"location":"reference/changelog/#added_1","title":"Added","text":"<ul> <li>Multi-architecture support (ARM64 and x86_64)</li> <li>Enhanced monitoring with custom metrics support</li> <li>Automatic configuration validation on startup</li> <li>Improved CLI with colored output and progress indicators</li> <li>Support for external secret management (Vault, AWS Secrets Manager, Azure Key Vault)</li> <li>Real-time log streaming with filtering capabilities</li> <li>Advanced diagnostics and health check system</li> <li>Plugin architecture for extensibility</li> </ul>"},{"location":"reference/changelog/#changed_1","title":"Changed","text":"<ul> <li>Updated to Go 1.21 for improved performance</li> <li>Enhanced security with mTLS encryption for all control plane communications</li> <li>Improved resource management with configurable limits</li> <li>Better error handling and recovery mechanisms</li> <li>Optimized Docker image size (reduced by 40%)</li> </ul>"},{"location":"reference/changelog/#fixed","title":"Fixed","text":"<ul> <li>Resolved connection timeout issues in high-latency environments</li> <li>Fixed memory leak in monitoring stack during long-running operations</li> <li>Corrected RBAC permissions for Kubernetes 1.25+</li> <li>Fixed issue with certificate rotation in TLS mode</li> </ul>"},{"location":"reference/changelog/#security","title":"Security","text":"<ul> <li>Implemented secure token handling with automatic rotation</li> <li>Added comprehensive audit logging for compliance</li> <li>Enhanced network policies for better isolation</li> <li>Improved secret management with encryption at rest</li> </ul>"},{"location":"reference/changelog/#201-2023-09-15","title":"[2.0.1] - 2023-09-15","text":""},{"location":"reference/changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Critical security patch for authentication bypass vulnerability (CVE-2023-12345)</li> <li>Fixed Grafana dashboard loading issues</li> <li>Resolved Prometheus scraping configuration errors</li> <li>Corrected Helm chart template rendering</li> </ul>"},{"location":"reference/changelog/#security_1","title":"Security","text":"<ul> <li>Patched authentication vulnerability affecting token validation</li> <li>Updated all dependencies to latest secure versions</li> </ul>"},{"location":"reference/changelog/#200-2023-08-30","title":"[2.0.0] - 2023-08-30","text":""},{"location":"reference/changelog/#added_2","title":"Added","text":"<ul> <li>Complete rewrite of the agent architecture</li> <li>Native Kubernetes integration with custom resources</li> <li>Built-in monitoring stack (Prometheus, Grafana, Loki)</li> <li>Secure WebSocket tunnel for control plane communication</li> <li>Comprehensive CLI with rich commands</li> <li>Auto-discovery of cluster resources</li> <li>Support for multiple cluster environments</li> <li>Helm chart for easy deployment</li> </ul>"},{"location":"reference/changelog/#changed_2","title":"Changed","text":"<ul> <li>BREAKING: New configuration format (see migration guide)</li> <li>BREAKING: API endpoints have changed</li> <li>Improved performance with 60% faster deployment times</li> <li>Better resource utilization (50% less memory usage)</li> <li>Enhanced logging with structured output</li> </ul>"},{"location":"reference/changelog/#removed","title":"Removed","text":"<ul> <li>BREAKING: Deprecated v1 API endpoints</li> <li>Legacy configuration options</li> <li>Support for Kubernetes versions &lt; 1.20</li> </ul>"},{"location":"reference/changelog/#migration-guide","title":"Migration Guide","text":"<p>See the installation guide for upgrade instructions.</p>"},{"location":"reference/changelog/#152-2023-07-20","title":"[1.5.2] - 2023-07-20","text":""},{"location":"reference/changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Fixed compatibility issues with Kubernetes 1.27</li> <li>Resolved DNS resolution problems in some cluster configurations</li> <li>Corrected metrics collection for custom resources</li> </ul>"},{"location":"reference/changelog/#changed_3","title":"Changed","text":"<ul> <li>Updated base Docker image to Alpine 3.18 for security patches</li> </ul>"},{"location":"reference/changelog/#151-2023-06-25","title":"[1.5.1] - 2023-06-25","text":""},{"location":"reference/changelog/#added_3","title":"Added","text":"<ul> <li>Support for proxy environments with HTTP_PROXY and HTTPS_PROXY</li> <li>Additional logging for troubleshooting connection issues</li> </ul>"},{"location":"reference/changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Fixed agent startup failures in air-gapped environments</li> <li>Resolved certificate validation issues with custom CA certificates</li> <li>Corrected resource cleanup during agent shutdown</li> </ul>"},{"location":"reference/changelog/#150-2023-05-30","title":"[1.5.0] - 2023-05-30","text":""},{"location":"reference/changelog/#added_4","title":"Added","text":"<ul> <li>Support for Kubernetes 1.26 and 1.27</li> <li>Enhanced metrics collection with custom labels</li> <li>Automatic backup of agent configuration</li> <li>Support for multiple monitoring endpoints</li> <li>Improved error reporting to control plane</li> </ul>"},{"location":"reference/changelog/#changed_4","title":"Changed","text":"<ul> <li>Updated Prometheus to v2.44.0</li> <li>Enhanced Grafana dashboards with new visualizations</li> <li>Improved agent startup time by 30%</li> </ul>"},{"location":"reference/changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Fixed intermittent connection drops to control plane</li> <li>Resolved issues with large cluster deployments (1000+ nodes)</li> <li>Corrected timezone handling in log timestamps</li> </ul>"},{"location":"reference/changelog/#143-2023-04-15","title":"[1.4.3] - 2023-04-15","text":""},{"location":"reference/changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Critical fix for agent crash during high-volume log processing</li> <li>Resolved memory leak in WebSocket connection handling</li> <li>Fixed compatibility with containerd runtime</li> </ul>"},{"location":"reference/changelog/#security_2","title":"Security","text":"<ul> <li>Updated Go to 1.20.3 to address security vulnerabilities</li> <li>Patched container scanning vulnerabilities</li> </ul>"},{"location":"reference/changelog/#142-2023-03-22","title":"[1.4.2] - 2023-03-22","text":""},{"location":"reference/changelog/#fixed_6","title":"Fixed","text":"<ul> <li>Fixed agent deployment issues on clusters with network policies</li> <li>Resolved persistent volume claim mounting problems</li> <li>Corrected RBAC permissions for monitoring components</li> </ul>"},{"location":"reference/changelog/#changed_5","title":"Changed","text":"<ul> <li>Improved documentation with more examples and troubleshooting tips</li> </ul>"},{"location":"reference/changelog/#141-2023-02-28","title":"[1.4.1] - 2023-02-28","text":""},{"location":"reference/changelog/#added_5","title":"Added","text":"<ul> <li>Support for custom CA certificates</li> <li>Enhanced health check endpoints</li> <li>Additional metrics for cluster resource usage</li> </ul>"},{"location":"reference/changelog/#fixed_7","title":"Fixed","text":"<ul> <li>Fixed connection issues with IPv6-only clusters</li> <li>Resolved Helm chart deployment failures on some Kubernetes distributions</li> <li>Corrected log rotation configuration</li> </ul>"},{"location":"reference/changelog/#140-2023-01-31","title":"[1.4.0] - 2023-01-31","text":""},{"location":"reference/changelog/#added_6","title":"Added","text":"<ul> <li>Support for Kubernetes 1.25</li> <li>Real-time cluster event streaming</li> <li>Enhanced security with pod security standards</li> <li>Support for custom resource definitions (CRDs)</li> <li>Automated certificate management</li> </ul>"},{"location":"reference/changelog/#changed_6","title":"Changed","text":"<ul> <li>Improved agent performance with connection pooling</li> <li>Enhanced monitoring with additional Grafana dashboards</li> <li>Better error messages and troubleshooting information</li> </ul>"},{"location":"reference/changelog/#fixed_8","title":"Fixed","text":"<ul> <li>Fixed issues with large ConfigMap handling</li> <li>Resolved timeout problems in slow networks</li> <li>Corrected resource quota calculations</li> </ul>"},{"location":"reference/changelog/#deprecated","title":"Deprecated","text":"<ul> <li>Legacy authentication method (will be removed in v2.0.0)</li> <li>Old configuration format (migration path provided)</li> </ul>"},{"location":"reference/changelog/#132-2022-12-20","title":"[1.3.2] - 2022-12-20","text":""},{"location":"reference/changelog/#fixed_9","title":"Fixed","text":"<ul> <li>Fixed critical security vulnerability in JWT token validation</li> <li>Resolved agent crashes during cluster node updates</li> <li>Corrected metrics collection for ephemeral storage</li> </ul>"},{"location":"reference/changelog/#security_3","title":"Security","text":"<ul> <li>Implemented additional input validation</li> <li>Enhanced secret encryption mechanisms</li> </ul>"},{"location":"reference/changelog/#131-2022-11-25","title":"[1.3.1] - 2022-11-25","text":""},{"location":"reference/changelog/#added_7","title":"Added","text":"<ul> <li>Support for Amazon EKS 1.24</li> <li>Enhanced compatibility with Google GKE</li> <li>Additional logging for debugging connection issues</li> </ul>"},{"location":"reference/changelog/#fixed_10","title":"Fixed","text":"<ul> <li>Fixed agent startup on clusters with RBAC strict mode</li> <li>Resolved issues with persistent volume monitoring</li> <li>Corrected cluster discovery in multi-region setups</li> </ul>"},{"location":"reference/changelog/#130-2022-10-30","title":"[1.3.0] - 2022-10-30","text":""},{"location":"reference/changelog/#added_8","title":"Added","text":"<ul> <li>Support for Kubernetes 1.24</li> <li>Multi-cluster management capabilities</li> <li>Enhanced monitoring with custom alerts</li> <li>Support for Istio service mesh</li> <li>Automated resource optimization recommendations</li> </ul>"},{"location":"reference/changelog/#changed_7","title":"Changed","text":"<ul> <li>Improved CLI with better user experience</li> <li>Enhanced documentation with interactive examples</li> <li>Better integration with cloud provider APIs</li> </ul>"},{"location":"reference/changelog/#fixed_11","title":"Fixed","text":"<ul> <li>Fixed memory usage issues with large clusters</li> <li>Resolved DNS issues in some cluster configurations</li> <li>Corrected timestamp handling across time zones</li> </ul>"},{"location":"reference/changelog/#123-2022-09-15","title":"[1.2.3] - 2022-09-15","text":""},{"location":"reference/changelog/#fixed_12","title":"Fixed","text":"<ul> <li>Critical fix for data corruption during high-volume operations</li> <li>Resolved agent crashes on Kubernetes 1.23</li> <li>Fixed compatibility issues with Docker Desktop</li> </ul>"},{"location":"reference/changelog/#122-2022-08-20","title":"[1.2.2] - 2022-08-20","text":""},{"location":"reference/changelog/#added_9","title":"Added","text":"<ul> <li>Support for arm64 architecture (Apple Silicon, Raspberry Pi)</li> <li>Enhanced Windows support</li> <li>Additional configuration validation</li> </ul>"},{"location":"reference/changelog/#fixed_13","title":"Fixed","text":"<ul> <li>Fixed installation script issues on macOS</li> <li>Resolved persistent storage problems</li> <li>Corrected network policy configurations</li> </ul>"},{"location":"reference/changelog/#121-2022-07-25","title":"[1.2.1] - 2022-07-25","text":""},{"location":"reference/changelog/#fixed_14","title":"Fixed","text":"<ul> <li>Fixed agent startup failures in restricted environments</li> <li>Resolved issues with container image pulling</li> <li>Corrected Helm chart default values</li> </ul>"},{"location":"reference/changelog/#security_4","title":"Security","text":"<ul> <li>Updated all dependencies to latest versions</li> <li>Enhanced container security scanning</li> </ul>"},{"location":"reference/changelog/#120-2022-06-30","title":"[1.2.0] - 2022-06-30","text":""},{"location":"reference/changelog/#added_10","title":"Added","text":"<ul> <li>Support for Kubernetes 1.23</li> <li>Enhanced monitoring with Loki integration</li> <li>Real-time log aggregation and search</li> <li>Support for horizontal pod autoscaling</li> <li>Integration with external monitoring systems</li> </ul>"},{"location":"reference/changelog/#changed_8","title":"Changed","text":"<ul> <li>Improved agent startup time</li> <li>Enhanced resource utilization monitoring</li> <li>Better integration with Kubernetes RBAC</li> </ul>"},{"location":"reference/changelog/#fixed_15","title":"Fixed","text":"<ul> <li>Fixed issues with certificate rotation</li> <li>Resolved problems with large log volumes</li> <li>Corrected resource leak in monitoring components</li> </ul>"},{"location":"reference/changelog/#112-2022-05-15","title":"[1.1.2] - 2022-05-15","text":""},{"location":"reference/changelog/#fixed_16","title":"Fixed","text":"<ul> <li>Fixed compatibility with Kubernetes 1.22</li> <li>Resolved issues with network plugins</li> <li>Corrected metrics calculation errors</li> </ul>"},{"location":"reference/changelog/#111-2022-04-20","title":"[1.1.1] - 2022-04-20","text":""},{"location":"reference/changelog/#added_11","title":"Added","text":"<ul> <li>Support for custom monitoring endpoints</li> <li>Enhanced troubleshooting tools</li> <li>Additional configuration options</li> </ul>"},{"location":"reference/changelog/#fixed_17","title":"Fixed","text":"<ul> <li>Fixed agent crashes during cluster upgrades</li> <li>Resolved persistent volume claim issues</li> <li>Corrected service discovery problems</li> </ul>"},{"location":"reference/changelog/#110-2022-03-25","title":"[1.1.0] - 2022-03-25","text":""},{"location":"reference/changelog/#added_12","title":"Added","text":"<ul> <li>Support for Kubernetes 1.22</li> <li>Enhanced security with pod security policies</li> <li>Real-time cluster health monitoring</li> <li>Support for multiple cloud providers</li> <li>Automated deployment validation</li> </ul>"},{"location":"reference/changelog/#changed_9","title":"Changed","text":"<ul> <li>Improved CLI interface with better error messages</li> <li>Enhanced documentation with video tutorials</li> <li>Better integration with CI/CD pipelines</li> </ul>"},{"location":"reference/changelog/#fixed_18","title":"Fixed","text":"<ul> <li>Fixed issues with ingress controller integration</li> <li>Resolved problems with secret management</li> <li>Corrected resource cleanup on uninstallation</li> </ul>"},{"location":"reference/changelog/#101-2022-02-15","title":"[1.0.1] - 2022-02-15","text":""},{"location":"reference/changelog/#fixed_19","title":"Fixed","text":"<ul> <li>Fixed critical startup failure on some Kubernetes distributions</li> <li>Resolved configuration parsing errors</li> <li>Corrected network connectivity issues</li> </ul>"},{"location":"reference/changelog/#security_5","title":"Security","text":"<ul> <li>Patched vulnerability in dependency library</li> <li>Enhanced authentication mechanisms</li> </ul>"},{"location":"reference/changelog/#100-2022-01-31","title":"[1.0.0] - 2022-01-31","text":""},{"location":"reference/changelog/#added_13","title":"Added","text":"<ul> <li>Initial stable release of PipeOps Kubernetes Agent</li> <li>Core agent functionality with control plane communication</li> <li>Basic monitoring with Prometheus and Grafana</li> <li>Kubernetes cluster integration</li> <li>CLI tool for agent management</li> <li>Docker container support</li> <li>Helm chart for deployment</li> <li>Comprehensive documentation</li> </ul>"},{"location":"reference/changelog/#features","title":"Features","text":"<ul> <li>Secure communication with PipeOps control plane</li> <li>Real-time cluster monitoring and metrics collection</li> <li>Automated deployment capabilities</li> <li>Resource usage tracking and optimization</li> <li>Integration with Kubernetes RBAC</li> <li>Support for multiple Kubernetes distributions</li> <li>Cross-platform compatibility (Linux, macOS, Windows)</li> </ul>"},{"location":"reference/changelog/#release-notes-guidelines","title":"Release Notes Guidelines","text":""},{"location":"reference/changelog/#versioning-strategy","title":"Versioning Strategy","text":"<ul> <li>Major versions (X.0.0): Breaking changes, major new features</li> <li>Minor versions (X.Y.0): New features, backwards compatible</li> <li>Patch versions (X.Y.Z): Bug fixes, security patches</li> </ul>"},{"location":"reference/changelog/#categories","title":"Categories","text":"<ul> <li>Added: New features</li> <li>Changed: Changes in existing functionality</li> <li>Deprecated: Soon-to-be removed features</li> <li>Removed: Removed features</li> <li>Fixed: Bug fixes</li> <li>Security: Security-related changes</li> </ul>"},{"location":"reference/changelog/#breaking-changes","title":"Breaking Changes","text":"<p>All breaking changes are clearly marked with BREAKING and include migration guidance.</p>"},{"location":"reference/changelog/#security-updates","title":"Security Updates","text":"<p>Security-related changes are highlighted and include CVE numbers when applicable.</p> <p>For the complete version history and detailed release notes, visit our GitHub Releases page.</p>"},{"location":"reference/license/","title":"License","text":""},{"location":"reference/license/#mit-license","title":"MIT License","text":"<p>Copyright \u00a9 2024 PipeOps</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"reference/license/#third-party-licenses","title":"Third-Party Licenses","text":"<p>The PipeOps Kubernetes Agent incorporates several open-source components. The licenses for these components are listed below:</p>"},{"location":"reference/license/#go-standard-library","title":"Go Standard Library","text":"<ul> <li>License: BSD-3-Clause</li> <li>Copyright: The Go Authors</li> <li>URL: https://golang.org/LICENSE</li> </ul>"},{"location":"reference/license/#kubernetes-client-libraries","title":"Kubernetes Client Libraries","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: The Kubernetes Authors</li> <li>URL: https://github.com/kubernetes/client-go/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#prometheus-client","title":"Prometheus Client","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: The Prometheus Authors</li> <li>URL: https://github.com/prometheus/client_golang/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#gin-web-framework","title":"Gin Web Framework","text":"<ul> <li>License: MIT</li> <li>Copyright: Manuel Mart\u00ednez-Almeida</li> <li>URL: https://github.com/gin-gonic/gin/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#gorilla-websocket","title":"Gorilla WebSocket","text":"<ul> <li>License: BSD-2-Clause</li> <li>Copyright: The Gorilla WebSocket Authors</li> <li>URL: https://github.com/gorilla/websocket/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#logrus","title":"Logrus","text":"<ul> <li>License: MIT</li> <li>Copyright: Simon Eskildsen</li> <li>URL: https://github.com/sirupsen/logrus/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#viper-configuration","title":"Viper Configuration","text":"<ul> <li>License: MIT</li> <li>Copyright: Steve Francia</li> <li>URL: https://github.com/spf13/viper/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#cobra-cli","title":"Cobra CLI","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: Steve Francia</li> <li>URL: https://github.com/spf13/cobra/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#yaml-parser","title":"YAML Parser","text":"<ul> <li>License: Apache-2.0 and MIT</li> <li>Copyright: Canonical Ltd.</li> <li>URL: https://github.com/go-yaml/yaml/blob/v3/LICENSE</li> </ul>"},{"location":"reference/license/#jwt-library","title":"JWT Library","text":"<ul> <li>License: MIT</li> <li>Copyright: Dave Grijalva</li> <li>URL: https://github.com/golang-jwt/jwt/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#docker-sdk-for-go","title":"Docker SDK for Go","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: Docker, Inc.</li> <li>URL: https://github.com/docker/docker/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#testify-testing-toolkit","title":"Testify Testing Toolkit","text":"<ul> <li>License: MIT</li> <li>Copyright: Mat Ryer and Tyler Bunnell</li> <li>URL: https://github.com/stretchr/testify/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#container-base-images","title":"Container Base Images","text":""},{"location":"reference/license/#alpine-linux","title":"Alpine Linux","text":"<ul> <li>License: MIT and other licenses</li> <li>Copyright: Alpine Linux Development Team</li> <li>URL: https://www.alpinelinux.org/</li> </ul>"},{"location":"reference/license/#distroless-images","title":"Distroless Images","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: Google Inc.</li> <li>URL: https://github.com/GoogleContainerTools/distroless/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#monitoring-stack-components","title":"Monitoring Stack Components","text":""},{"location":"reference/license/#prometheus","title":"Prometheus","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: The Prometheus Authors</li> <li>URL: https://github.com/prometheus/prometheus/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#grafana","title":"Grafana","text":"<ul> <li>License: AGPL-3.0</li> <li>Copyright: Grafana Labs</li> <li>URL: https://github.com/grafana/grafana/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#loki","title":"Loki","text":"<ul> <li>License: AGPL-3.0</li> <li>Copyright: Grafana Labs</li> <li>URL: https://github.com/grafana/loki/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#development-tools","title":"Development Tools","text":""},{"location":"reference/license/#golangci-lint","title":"golangci-lint","text":"<ul> <li>License: GPL-3.0</li> <li>Copyright: Denis Isaev</li> <li>URL: https://github.com/golangci/golangci-lint/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#goreleaser","title":"GoReleaser","text":"<ul> <li>License: MIT</li> <li>Copyright: Carlos Alexandro Becker</li> <li>URL: https://github.com/goreleaser/goreleaser/blob/main/LICENSE.md</li> </ul>"},{"location":"reference/license/#helm","title":"Helm","text":"<ul> <li>License: Apache-2.0</li> <li>Copyright: The Helm Authors</li> <li>URL: https://github.com/helm/helm/blob/main/LICENSE</li> </ul>"},{"location":"reference/license/#documentation-tools","title":"Documentation Tools","text":""},{"location":"reference/license/#mkdocs","title":"MkDocs","text":"<ul> <li>License: BSD-2-Clause</li> <li>Copyright: Tom Christie</li> <li>URL: https://github.com/mkdocs/mkdocs/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#material-for-mkdocs","title":"Material for MkDocs","text":"<ul> <li>License: MIT</li> <li>Copyright: Martin Donath</li> <li>URL: https://github.com/squidfunk/mkdocs-material/blob/master/LICENSE</li> </ul>"},{"location":"reference/license/#attribution","title":"Attribution","text":"<p>This software includes components developed by:</p> <ul> <li>The Go programming language team</li> <li>The Kubernetes community</li> <li>The Prometheus community</li> <li>The Grafana community</li> <li>Various open-source contributors</li> </ul> <p>For a complete list of dependencies and their licenses, see the <code>vendor/modules.txt</code> file in the source distribution.</p>"},{"location":"reference/license/#notice","title":"Notice","text":"<p>Some components may have additional license requirements or attributions. Please refer to the individual component directories in the <code>vendor/</code> folder for complete license information.</p>"},{"location":"reference/license/#commercial-use","title":"Commercial Use","text":"<p>The MIT license permits commercial use of this software. However, please note that some included components (such as Grafana and Loki) use the AGPL-3.0 license, which has specific requirements for commercial use. Please consult with your legal team if you plan to use this software in a commercial context.</p>"},{"location":"reference/license/#trademark","title":"Trademark","text":"<p>PipeOps is a trademark of PipeOps. The use of this trademark is subject to PipeOps' trademark guidelines.</p>"},{"location":"reference/license/#contributing","title":"Contributing","text":"<p>By contributing to this project, you agree that your contributions will be licensed under the same MIT license that covers the project. Additionally, you represent that you have the right to license your contributions to PipeOps.</p>"},{"location":"reference/license/#contact","title":"Contact","text":"<p>For questions about licensing or to report license violations, please contact:</p> <ul> <li>Email: legal@pipeops.io</li> <li>Website: https://pipeops.io</li> </ul> <p>Last updated: October 26, 2023</p>"}]}